{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d3d2a1",
   "metadata": {},
   "source": [
    "# (9-6-2021)->optimized-> 11-14-2021\n",
    "## Optimized Setup: Setting Up Current Maps with Sorted Stable Event Lists.  Whose purpose is to collect CURL and MEC data that corresponds with the Event Lists\n",
    "### Sequel to `Event Searching pt2`\n",
    "#### Hector Salinas\n",
    "---\n",
    "\n",
    "#### Eric Mentions:\n",
    "* (9-13-2021)As confirmed by Eric, the components of the curl parameters refer to the coordinate system inputted inot the fgm function( >>fgm(....var_format = * gsm *).  'The output coordinate system should be the same as the input coordinate system (so if you provide the FGM and position data in G\u0010SE coordinates, the output vectors will be in GSE coordinates as well).'\n",
    "* (6-24-21; old email) Yeah, if you return the individual elements of the tuple (instead of the tuple itself), it’ll be:\n",
    "    * `>>> pos_times, pos = get_data('mms1_mec_r_gsm’)`\n",
    "    * `>>> radius of position vector: r = np.sqrt(pos[:, 0]**2+pos[:, 1]**2+pos[:, 2]**2)`\n",
    "    * `pos[:, 0] is the x-component`\n",
    "    * `pos[:, 1] is the y-component`\n",
    "    * `pos[:, 2] is the z-component`\n",
    "***\n",
    "#### Rick Pointers:\n",
    "* Burst data is 128 samples/sec and selected for very specific intervals\n",
    "* Survey data is 16 samples/sec and all through the ROI(region of interest)\n",
    "    * Burst should only be for studying detailed physics of specific events\n",
    "    * For the end-goal Current Maps, survey is all we need. But if there's some interesting periods for follow-up studies, we'll start digging into burst data\n",
    "***\n",
    "### Script-Goals\n",
    "* This script will be used to export dataframes that contain data on the CURL params and correpsonding MEC position necessary for creating Current Maps for the bowshowck-magpause region \n",
    "1. Load up Curlometer data(GSM coord) for corresponding date \n",
    "2. Take the median, mean, and std over the time interval for the desired CURL parameters:\n",
    "    * curlB components and divB in current units\n",
    "3. (9-18-2021)Collect median, mean, and std values for corresponding time frame as datapoints for dataframe that will be used elsewhere\n",
    "\n",
    "\n",
    "***\n",
    "#### pySPEDAS References\n",
    "* Jupyter Notebook Viewer: pySPEDAS routine how-tos:\n",
    "    * https://nbviewer.jupyter.org/github/spedas/mms-examples/blob/master/basic/Fast%20Plasma%20Investigation%20%28FPI%29.ipynb\n",
    "* Github: pySPEDAS tutorial on many features:\n",
    "    * https://github.com/spedas/pyspedas_examples/blob/master/pyspedas_examples/tutorials/pySPEDAS%201.0%20tutorial%20-%20dry%20run%20(1%20May%202020).ipynb\n",
    "    * As indicated by the github tutorial, many tplot variables can be displayed on a single plane using the join_vec() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcdfa479",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize \n",
    "from scipy.signal import find_peaks, find_peaks_cwt #displaying peaks on data\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import copy\n",
    "import pytplot\n",
    "\n",
    "from pyspedas.mms import fgm, fpi, curlometer, mec #import instrument load routines\n",
    "from pyspedas import tinterpol    #to match MEC data to OMNI 5min time stamps\n",
    "\n",
    "import pyspedas\n",
    "from pytplot import tplot, tlimit # plot said tplot variables and specify xrange\n",
    "from pytplot import tplot_names   # list tplot variables loaded\n",
    "from pytplot import get_data      # extract data values from tplot variables\n",
    "from pyspedas import time_string  # convert unix time to string(returns it as 'list object' not numpy array)\n",
    "from pyspedas import time_double  #convert string back to unix time\n",
    "from pytplot import store_data    # creating tplot variables\n",
    "from pytplot import options       # extra tplot features for individial tplots\n",
    "from pytplot import tplot_options # global tplot options for created tplots\n",
    "from pytplot import join_vec      # combine multiple tplot variables into a single one\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fde4a9",
   "metadata": {},
   "source": [
    "# Section 1:\n",
    "## Importing Day and Nightside Stable Event Lists(Yr1 to 5) for Certain IMF Clock Angles and extracting last 10min from each 30minute interval\n",
    "---\n",
    "#### IMF Orientations to Load/Extract Data from:\n",
    "* Southward $B_z$: $\\theta_{avg,IMF} \\geq 135^o$ and $< 225^o$\n",
    "* Positive $B_y$-led: $\\theta_{avg,IMF} \\geq 45^o$ and $< 135^o$\n",
    "* Negative $B_y$-led: $\\theta_{avg,IMF} \\geq 225^o$ and $< 315^o$\n",
    "* Northward $B_z$: $\\theta_{avg,IMF} \\geq 315^o$ and $< 45^o$\n",
    "\n",
    "    * reference to IMF ClockAng Diagram: https://www.sws.bom.gov.au/Category/Solar/Solar%20Conditions/Solar%20Wind%20Clock%20Angle/Solar%20Wind%20Clock%20Angle.php\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff1f475",
   "metadata": {},
   "source": [
    "#### Importing Dayside(Sept to May) Yrs1-5 Stable IMF Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b77e1ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rmag', 't', 'x', 'y', 'z']\n",
      "Displaying Dayside(Sept-May)Yr 1-6 SoBz Stable Lists\n",
      "Start_str      object\n",
      "Start_ind       int64\n",
      "Mgs#_avg      float64\n",
      "Clang_avg     float64\n",
      "Rmag_avg      float64\n",
      "Bx_avg(nT)    float64\n",
      "By_avg(nT)    float64\n",
      "Bz_avg(nT)    float64\n",
      "Bdeviat       float64\n",
      "Dtheta        float64\n",
      "End_ind         int64\n",
      "End_str        object\n",
      "dtype: object\n",
      "\n",
      "Displaying Dayside(Sept-May)Yr 1-6 NegBy Stable Lists\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-09-01 00:10:00</td>\n",
       "      <td>2</td>\n",
       "      <td>5.28</td>\n",
       "      <td>270.271</td>\n",
       "      <td>8.646</td>\n",
       "      <td>3.502</td>\n",
       "      <td>-3.177</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5.28</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-09-01 00:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-09-01 08:40:00</td>\n",
       "      <td>88</td>\n",
       "      <td>5.42</td>\n",
       "      <td>284.483</td>\n",
       "      <td>7.927</td>\n",
       "      <td>1.962</td>\n",
       "      <td>-4.547</td>\n",
       "      <td>1.157</td>\n",
       "      <td>0.02</td>\n",
       "      <td>27.44</td>\n",
       "      <td>93</td>\n",
       "      <td>2015-09-01 09:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-09-01 10:35:00</td>\n",
       "      <td>111</td>\n",
       "      <td>5.33</td>\n",
       "      <td>260.121</td>\n",
       "      <td>9.749</td>\n",
       "      <td>3.143</td>\n",
       "      <td>-3.738</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>0.02</td>\n",
       "      <td>27.20</td>\n",
       "      <td>116</td>\n",
       "      <td>2015-09-01 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-09-01 12:30:00</td>\n",
       "      <td>134</td>\n",
       "      <td>5.17</td>\n",
       "      <td>299.448</td>\n",
       "      <td>10.965</td>\n",
       "      <td>3.513</td>\n",
       "      <td>-3.783</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.04</td>\n",
       "      <td>12.78</td>\n",
       "      <td>139</td>\n",
       "      <td>2015-09-01 12:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-09-01 19:15:00</td>\n",
       "      <td>215</td>\n",
       "      <td>5.38</td>\n",
       "      <td>251.441</td>\n",
       "      <td>11.616</td>\n",
       "      <td>3.822</td>\n",
       "      <td>-3.078</td>\n",
       "      <td>-1.018</td>\n",
       "      <td>0.03</td>\n",
       "      <td>14.60</td>\n",
       "      <td>220</td>\n",
       "      <td>2015-09-01 19:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>2016-05-30 09:05:00</td>\n",
       "      <td>72631</td>\n",
       "      <td>6.57</td>\n",
       "      <td>271.550</td>\n",
       "      <td>11.994</td>\n",
       "      <td>2.197</td>\n",
       "      <td>-4.147</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.07</td>\n",
       "      <td>9.33</td>\n",
       "      <td>72636</td>\n",
       "      <td>2016-05-30 09:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>2016-05-30 09:35:00</td>\n",
       "      <td>72637</td>\n",
       "      <td>6.13</td>\n",
       "      <td>275.711</td>\n",
       "      <td>12.009</td>\n",
       "      <td>3.940</td>\n",
       "      <td>-3.460</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.06</td>\n",
       "      <td>15.26</td>\n",
       "      <td>72642</td>\n",
       "      <td>2016-05-30 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>2016-05-30 10:05:00</td>\n",
       "      <td>72643</td>\n",
       "      <td>6.17</td>\n",
       "      <td>267.143</td>\n",
       "      <td>11.996</td>\n",
       "      <td>3.412</td>\n",
       "      <td>-4.288</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5.79</td>\n",
       "      <td>72648</td>\n",
       "      <td>2016-05-30 10:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>2016-05-30 13:05:00</td>\n",
       "      <td>72679</td>\n",
       "      <td>6.92</td>\n",
       "      <td>266.897</td>\n",
       "      <td>11.312</td>\n",
       "      <td>3.228</td>\n",
       "      <td>-1.163</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.09</td>\n",
       "      <td>12.47</td>\n",
       "      <td>72684</td>\n",
       "      <td>2016-05-30 13:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>2016-05-30 14:15:00</td>\n",
       "      <td>72693</td>\n",
       "      <td>6.60</td>\n",
       "      <td>271.308</td>\n",
       "      <td>10.748</td>\n",
       "      <td>3.652</td>\n",
       "      <td>-1.893</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.09</td>\n",
       "      <td>27.24</td>\n",
       "      <td>72698</td>\n",
       "      <td>2016-05-30 14:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>665 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2015-09-01 00:10:00          2      5.28    270.271     8.646   \n",
       "1    2015-09-01 08:40:00         88      5.42    284.483     7.927   \n",
       "2    2015-09-01 10:35:00        111      5.33    260.121     9.749   \n",
       "3    2015-09-01 12:30:00        134      5.17    299.448    10.965   \n",
       "4    2015-09-01 19:15:00        215      5.38    251.441    11.616   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "660  2016-05-30 09:05:00      72631      6.57    271.550    11.994   \n",
       "661  2016-05-30 09:35:00      72637      6.13    275.711    12.009   \n",
       "662  2016-05-30 10:05:00      72643      6.17    267.143    11.996   \n",
       "663  2016-05-30 13:05:00      72679      6.92    266.897    11.312   \n",
       "664  2016-05-30 14:15:00      72693      6.60    271.308    10.748   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0         3.502      -3.177       0.023     0.08    5.28        7   \n",
       "1         1.962      -4.547       1.157     0.02   27.44       93   \n",
       "2         3.143      -3.738      -0.730     0.02   27.20      116   \n",
       "3         3.513      -3.783       2.150     0.04   12.78      139   \n",
       "4         3.822      -3.078      -1.018     0.03   14.60      220   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "660       2.197      -4.147       0.128     0.07    9.33    72636   \n",
       "661       3.940      -3.460       0.367     0.06   15.26    72642   \n",
       "662       3.412      -4.288      -0.208     0.04    5.79    72648   \n",
       "663       3.228      -1.163      -0.033     0.09   12.47    72684   \n",
       "664       3.652      -1.893       0.092     0.09   27.24    72698   \n",
       "\n",
       "                 End_str  \n",
       "0    2015-09-01 00:35:00  \n",
       "1    2015-09-01 09:05:00  \n",
       "2    2015-09-01 11:00:00  \n",
       "3    2015-09-01 12:55:00  \n",
       "4    2015-09-01 19:40:00  \n",
       "..                   ...  \n",
       "660  2016-05-30 09:30:00  \n",
       "661  2016-05-30 10:00:00  \n",
       "662  2016-05-30 10:30:00  \n",
       "663  2016-05-30 13:30:00  \n",
       "664  2016-05-30 14:40:00  \n",
       "\n",
       "[665 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-08 16:00:00</td>\n",
       "      <td>1935</td>\n",
       "      <td>6.93</td>\n",
       "      <td>254.787</td>\n",
       "      <td>9.922</td>\n",
       "      <td>-1.043</td>\n",
       "      <td>-4.162</td>\n",
       "      <td>-1.125</td>\n",
       "      <td>0.04</td>\n",
       "      <td>19.62</td>\n",
       "      <td>1940</td>\n",
       "      <td>2016-09-08 16:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-11 22:15:00</td>\n",
       "      <td>2854</td>\n",
       "      <td>5.65</td>\n",
       "      <td>240.055</td>\n",
       "      <td>11.952</td>\n",
       "      <td>-2.332</td>\n",
       "      <td>-4.287</td>\n",
       "      <td>-2.442</td>\n",
       "      <td>0.02</td>\n",
       "      <td>13.50</td>\n",
       "      <td>2859</td>\n",
       "      <td>2016-09-11 22:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-11 22:45:00</td>\n",
       "      <td>2860</td>\n",
       "      <td>5.72</td>\n",
       "      <td>237.653</td>\n",
       "      <td>11.897</td>\n",
       "      <td>-4.373</td>\n",
       "      <td>-3.188</td>\n",
       "      <td>-2.063</td>\n",
       "      <td>0.07</td>\n",
       "      <td>22.09</td>\n",
       "      <td>2865</td>\n",
       "      <td>2016-09-11 23:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-16 13:40:00</td>\n",
       "      <td>4191</td>\n",
       "      <td>5.03</td>\n",
       "      <td>305.148</td>\n",
       "      <td>8.705</td>\n",
       "      <td>2.902</td>\n",
       "      <td>-4.585</td>\n",
       "      <td>3.210</td>\n",
       "      <td>0.05</td>\n",
       "      <td>17.18</td>\n",
       "      <td>4196</td>\n",
       "      <td>2016-09-16 14:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-17 17:25:00</td>\n",
       "      <td>4524</td>\n",
       "      <td>5.60</td>\n",
       "      <td>302.025</td>\n",
       "      <td>11.303</td>\n",
       "      <td>2.752</td>\n",
       "      <td>-2.783</td>\n",
       "      <td>1.733</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7.31</td>\n",
       "      <td>4529</td>\n",
       "      <td>2016-09-17 17:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>2017-05-27 10:30:00</td>\n",
       "      <td>73252</td>\n",
       "      <td>5.78</td>\n",
       "      <td>274.884</td>\n",
       "      <td>8.388</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-2.595</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.08</td>\n",
       "      <td>22.23</td>\n",
       "      <td>73257</td>\n",
       "      <td>2017-05-27 10:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>2017-05-27 11:00:00</td>\n",
       "      <td>73258</td>\n",
       "      <td>5.88</td>\n",
       "      <td>278.537</td>\n",
       "      <td>9.165</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>-2.617</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.01</td>\n",
       "      <td>21.20</td>\n",
       "      <td>73263</td>\n",
       "      <td>2017-05-27 11:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>2017-05-27 11:30:00</td>\n",
       "      <td>73264</td>\n",
       "      <td>5.90</td>\n",
       "      <td>268.346</td>\n",
       "      <td>9.897</td>\n",
       "      <td>0.222</td>\n",
       "      <td>-2.638</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.07</td>\n",
       "      <td>24.93</td>\n",
       "      <td>73269</td>\n",
       "      <td>2017-05-27 11:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>2017-05-27 14:15:00</td>\n",
       "      <td>73297</td>\n",
       "      <td>5.87</td>\n",
       "      <td>264.697</td>\n",
       "      <td>13.330</td>\n",
       "      <td>-1.552</td>\n",
       "      <td>-2.630</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>0.10</td>\n",
       "      <td>25.11</td>\n",
       "      <td>73302</td>\n",
       "      <td>2017-05-27 14:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>2017-05-30 07:25:00</td>\n",
       "      <td>74064</td>\n",
       "      <td>5.87</td>\n",
       "      <td>285.066</td>\n",
       "      <td>10.808</td>\n",
       "      <td>3.578</td>\n",
       "      <td>-5.758</td>\n",
       "      <td>1.535</td>\n",
       "      <td>0.07</td>\n",
       "      <td>11.14</td>\n",
       "      <td>74069</td>\n",
       "      <td>2017-05-30 07:50:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>613 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2016-09-08 16:00:00       1935      6.93    254.787     9.922   \n",
       "1    2016-09-11 22:15:00       2854      5.65    240.055    11.952   \n",
       "2    2016-09-11 22:45:00       2860      5.72    237.653    11.897   \n",
       "3    2016-09-16 13:40:00       4191      5.03    305.148     8.705   \n",
       "4    2016-09-17 17:25:00       4524      5.60    302.025    11.303   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "608  2017-05-27 10:30:00      73252      5.78    274.884     8.388   \n",
       "609  2017-05-27 11:00:00      73258      5.88    278.537     9.165   \n",
       "610  2017-05-27 11:30:00      73264      5.90    268.346     9.897   \n",
       "611  2017-05-27 14:15:00      73297      5.87    264.697    13.330   \n",
       "612  2017-05-30 07:25:00      74064      5.87    285.066    10.808   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0        -1.043      -4.162      -1.125     0.04   19.62     1940   \n",
       "1        -2.332      -4.287      -2.442     0.02   13.50     2859   \n",
       "2        -4.373      -3.188      -2.063     0.07   22.09     2865   \n",
       "3         2.902      -4.585       3.210     0.05   17.18     4196   \n",
       "4         2.752      -2.783       1.733     0.05    7.31     4529   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "608      -0.223      -2.595       0.222     0.08   22.23    73257   \n",
       "609      -0.262      -2.617       0.395     0.01   21.20    73263   \n",
       "610       0.222      -2.638      -0.082     0.07   24.93    73269   \n",
       "611      -1.552      -2.630      -0.240     0.10   25.11    73302   \n",
       "612       3.578      -5.758       1.535     0.07   11.14    74069   \n",
       "\n",
       "                 End_str  \n",
       "0    2016-09-08 16:25:00  \n",
       "1    2016-09-11 22:40:00  \n",
       "2    2016-09-11 23:10:00  \n",
       "3    2016-09-16 14:05:00  \n",
       "4    2016-09-17 17:50:00  \n",
       "..                   ...  \n",
       "608  2017-05-27 10:55:00  \n",
       "609  2017-05-27 11:25:00  \n",
       "610  2017-05-27 11:55:00  \n",
       "611  2017-05-27 14:40:00  \n",
       "612  2017-05-30 07:50:00  \n",
       "\n",
       "[613 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-01 18:35:00</td>\n",
       "      <td>223</td>\n",
       "      <td>6.20</td>\n",
       "      <td>311.273</td>\n",
       "      <td>18.642</td>\n",
       "      <td>-4.432</td>\n",
       "      <td>-3.587</td>\n",
       "      <td>3.130</td>\n",
       "      <td>0.03</td>\n",
       "      <td>29.17</td>\n",
       "      <td>228</td>\n",
       "      <td>2017-09-01 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-01 20:30:00</td>\n",
       "      <td>246</td>\n",
       "      <td>6.37</td>\n",
       "      <td>279.942</td>\n",
       "      <td>17.200</td>\n",
       "      <td>-5.642</td>\n",
       "      <td>-2.452</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.08</td>\n",
       "      <td>25.32</td>\n",
       "      <td>251</td>\n",
       "      <td>2017-09-01 20:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-01 22:25:00</td>\n",
       "      <td>259</td>\n",
       "      <td>6.03</td>\n",
       "      <td>310.823</td>\n",
       "      <td>15.542</td>\n",
       "      <td>-5.735</td>\n",
       "      <td>-3.620</td>\n",
       "      <td>3.128</td>\n",
       "      <td>0.06</td>\n",
       "      <td>21.42</td>\n",
       "      <td>264</td>\n",
       "      <td>2017-09-01 22:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-03 05:30:00</td>\n",
       "      <td>631</td>\n",
       "      <td>6.95</td>\n",
       "      <td>309.260</td>\n",
       "      <td>23.015</td>\n",
       "      <td>-3.452</td>\n",
       "      <td>-1.092</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.08</td>\n",
       "      <td>26.70</td>\n",
       "      <td>636</td>\n",
       "      <td>2017-09-03 05:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-09-06 22:45:00</td>\n",
       "      <td>1699</td>\n",
       "      <td>6.47</td>\n",
       "      <td>295.288</td>\n",
       "      <td>23.593</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>-2.987</td>\n",
       "      <td>1.430</td>\n",
       "      <td>0.08</td>\n",
       "      <td>19.97</td>\n",
       "      <td>1704</td>\n",
       "      <td>2017-09-06 23:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>2018-05-22 14:15:00</td>\n",
       "      <td>71970</td>\n",
       "      <td>5.70</td>\n",
       "      <td>265.307</td>\n",
       "      <td>17.828</td>\n",
       "      <td>4.483</td>\n",
       "      <td>-5.903</td>\n",
       "      <td>-0.462</td>\n",
       "      <td>0.09</td>\n",
       "      <td>22.07</td>\n",
       "      <td>71975</td>\n",
       "      <td>2018-05-22 14:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>2018-05-22 14:45:00</td>\n",
       "      <td>71976</td>\n",
       "      <td>5.72</td>\n",
       "      <td>265.247</td>\n",
       "      <td>18.202</td>\n",
       "      <td>4.557</td>\n",
       "      <td>-5.773</td>\n",
       "      <td>-0.492</td>\n",
       "      <td>0.04</td>\n",
       "      <td>17.35</td>\n",
       "      <td>71981</td>\n",
       "      <td>2018-05-22 15:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>2018-05-22 16:15:00</td>\n",
       "      <td>71994</td>\n",
       "      <td>5.67</td>\n",
       "      <td>271.157</td>\n",
       "      <td>19.249</td>\n",
       "      <td>4.250</td>\n",
       "      <td>-6.382</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.09</td>\n",
       "      <td>28.11</td>\n",
       "      <td>71999</td>\n",
       "      <td>2018-05-22 16:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>2018-05-24 17:35:00</td>\n",
       "      <td>72586</td>\n",
       "      <td>6.90</td>\n",
       "      <td>263.469</td>\n",
       "      <td>9.301</td>\n",
       "      <td>-3.033</td>\n",
       "      <td>-0.715</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>0.10</td>\n",
       "      <td>18.64</td>\n",
       "      <td>72591</td>\n",
       "      <td>2018-05-24 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>2018-05-29 19:15:00</td>\n",
       "      <td>73981</td>\n",
       "      <td>6.32</td>\n",
       "      <td>262.345</td>\n",
       "      <td>21.239</td>\n",
       "      <td>2.843</td>\n",
       "      <td>-1.545</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>0.04</td>\n",
       "      <td>26.35</td>\n",
       "      <td>73986</td>\n",
       "      <td>2018-05-29 19:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>822 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2017-09-01 18:35:00        223      6.20    311.273    18.642   \n",
       "1    2017-09-01 20:30:00        246      6.37    279.942    17.200   \n",
       "2    2017-09-01 22:25:00        259      6.03    310.823    15.542   \n",
       "3    2017-09-03 05:30:00        631      6.95    309.260    23.015   \n",
       "4    2017-09-06 22:45:00       1699      6.47    295.288    23.593   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "817  2018-05-22 14:15:00      71970      5.70    265.307    17.828   \n",
       "818  2018-05-22 14:45:00      71976      5.72    265.247    18.202   \n",
       "819  2018-05-22 16:15:00      71994      5.67    271.157    19.249   \n",
       "820  2018-05-24 17:35:00      72586      6.90    263.469     9.301   \n",
       "821  2018-05-29 19:15:00      73981      6.32    262.345    21.239   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0        -4.432      -3.587       3.130     0.03   29.17      228   \n",
       "1        -5.642      -2.452       0.287     0.08   25.32      251   \n",
       "2        -5.735      -3.620       3.128     0.06   21.42      264   \n",
       "3        -3.452      -1.092       0.905     0.08   26.70      636   \n",
       "4        -0.320      -2.987       1.430     0.08   19.97     1704   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "817       4.483      -5.903      -0.462     0.09   22.07    71975   \n",
       "818       4.557      -5.773      -0.492     0.04   17.35    71981   \n",
       "819       4.250      -6.382       0.187     0.09   28.11    71999   \n",
       "820      -3.033      -0.715      -0.083     0.10   18.64    72591   \n",
       "821       2.843      -1.545      -0.197     0.04   26.35    73986   \n",
       "\n",
       "                 End_str  \n",
       "0    2017-09-01 19:00:00  \n",
       "1    2017-09-01 20:55:00  \n",
       "2    2017-09-01 22:50:00  \n",
       "3    2017-09-03 05:55:00  \n",
       "4    2017-09-06 23:10:00  \n",
       "..                   ...  \n",
       "817  2018-05-22 14:40:00  \n",
       "818  2018-05-22 15:10:00  \n",
       "819  2018-05-22 16:40:00  \n",
       "820  2018-05-24 18:00:00  \n",
       "821  2018-05-29 19:40:00  \n",
       "\n",
       "[822 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-01 01:20:00</td>\n",
       "      <td>16</td>\n",
       "      <td>6.43</td>\n",
       "      <td>284.177</td>\n",
       "      <td>18.733</td>\n",
       "      <td>-3.255</td>\n",
       "      <td>-1.057</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.05</td>\n",
       "      <td>23.74</td>\n",
       "      <td>21</td>\n",
       "      <td>2018-09-01 01:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-01 03:45:00</td>\n",
       "      <td>45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>312.375</td>\n",
       "      <td>20.288</td>\n",
       "      <td>-2.530</td>\n",
       "      <td>-1.597</td>\n",
       "      <td>1.462</td>\n",
       "      <td>0.05</td>\n",
       "      <td>13.52</td>\n",
       "      <td>50</td>\n",
       "      <td>2018-09-01 04:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-02 09:00:00</td>\n",
       "      <td>396</td>\n",
       "      <td>6.72</td>\n",
       "      <td>308.625</td>\n",
       "      <td>23.407</td>\n",
       "      <td>1.515</td>\n",
       "      <td>-1.805</td>\n",
       "      <td>1.445</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.62</td>\n",
       "      <td>401</td>\n",
       "      <td>2018-09-02 09:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-02 09:30:00</td>\n",
       "      <td>402</td>\n",
       "      <td>6.60</td>\n",
       "      <td>313.785</td>\n",
       "      <td>23.235</td>\n",
       "      <td>1.790</td>\n",
       "      <td>-1.483</td>\n",
       "      <td>1.420</td>\n",
       "      <td>0.06</td>\n",
       "      <td>9.89</td>\n",
       "      <td>407</td>\n",
       "      <td>2018-09-02 09:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-02 11:30:00</td>\n",
       "      <td>426</td>\n",
       "      <td>6.12</td>\n",
       "      <td>302.135</td>\n",
       "      <td>22.464</td>\n",
       "      <td>1.747</td>\n",
       "      <td>-2.313</td>\n",
       "      <td>1.455</td>\n",
       "      <td>0.06</td>\n",
       "      <td>25.33</td>\n",
       "      <td>431</td>\n",
       "      <td>2018-09-02 11:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>2019-05-24 12:40:00</td>\n",
       "      <td>72182</td>\n",
       "      <td>5.98</td>\n",
       "      <td>278.693</td>\n",
       "      <td>14.310</td>\n",
       "      <td>1.618</td>\n",
       "      <td>-3.207</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.07</td>\n",
       "      <td>27.07</td>\n",
       "      <td>72187</td>\n",
       "      <td>2019-05-24 13:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>2019-05-24 13:10:00</td>\n",
       "      <td>72188</td>\n",
       "      <td>6.20</td>\n",
       "      <td>265.719</td>\n",
       "      <td>13.749</td>\n",
       "      <td>1.315</td>\n",
       "      <td>-3.248</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>0.09</td>\n",
       "      <td>22.99</td>\n",
       "      <td>72193</td>\n",
       "      <td>2019-05-24 13:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2019-05-28 15:55:00</td>\n",
       "      <td>73373</td>\n",
       "      <td>5.15</td>\n",
       "      <td>299.266</td>\n",
       "      <td>13.273</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-6.640</td>\n",
       "      <td>3.740</td>\n",
       "      <td>0.07</td>\n",
       "      <td>12.04</td>\n",
       "      <td>73378</td>\n",
       "      <td>2019-05-28 16:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>2019-05-28 20:30:00</td>\n",
       "      <td>73428</td>\n",
       "      <td>5.05</td>\n",
       "      <td>236.574</td>\n",
       "      <td>17.884</td>\n",
       "      <td>5.833</td>\n",
       "      <td>-4.823</td>\n",
       "      <td>-3.205</td>\n",
       "      <td>0.10</td>\n",
       "      <td>13.43</td>\n",
       "      <td>73433</td>\n",
       "      <td>2019-05-28 20:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>2019-05-29 05:05:00</td>\n",
       "      <td>73531</td>\n",
       "      <td>5.50</td>\n",
       "      <td>227.371</td>\n",
       "      <td>23.722</td>\n",
       "      <td>3.018</td>\n",
       "      <td>-4.662</td>\n",
       "      <td>-4.323</td>\n",
       "      <td>0.06</td>\n",
       "      <td>24.80</td>\n",
       "      <td>73536</td>\n",
       "      <td>2019-05-29 05:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>897 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2018-09-01 01:20:00         16      6.43    284.177    18.733   \n",
       "1    2018-09-01 03:45:00         45      6.48    312.375    20.288   \n",
       "2    2018-09-02 09:00:00        396      6.72    308.625    23.407   \n",
       "3    2018-09-02 09:30:00        402      6.60    313.785    23.235   \n",
       "4    2018-09-02 11:30:00        426      6.12    302.135    22.464   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "892  2019-05-24 12:40:00      72182      5.98    278.693    14.310   \n",
       "893  2019-05-24 13:10:00      72188      6.20    265.719    13.749   \n",
       "894  2019-05-28 15:55:00      73373      5.15    299.266    13.273   \n",
       "895  2019-05-28 20:30:00      73428      5.05    236.574    17.884   \n",
       "896  2019-05-29 05:05:00      73531      5.50    227.371    23.722   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0        -3.255      -1.057       0.307     0.05   23.74       21   \n",
       "1        -2.530      -1.597       1.462     0.05   13.52       50   \n",
       "2         1.515      -1.805       1.445     0.05    5.62      401   \n",
       "3         1.790      -1.483       1.420     0.06    9.89      407   \n",
       "4         1.747      -2.313       1.455     0.06   25.33      431   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "892       1.618      -3.207       0.517     0.07   27.07    72187   \n",
       "893       1.315      -3.248      -0.265     0.09   22.99    72193   \n",
       "894       0.162      -6.640       3.740     0.07   12.04    73378   \n",
       "895       5.833      -4.823      -3.205     0.10   13.43    73433   \n",
       "896       3.018      -4.662      -4.323     0.06   24.80    73536   \n",
       "\n",
       "                 End_str  \n",
       "0    2018-09-01 01:45:00  \n",
       "1    2018-09-01 04:10:00  \n",
       "2    2018-09-02 09:25:00  \n",
       "3    2018-09-02 09:55:00  \n",
       "4    2018-09-02 11:55:00  \n",
       "..                   ...  \n",
       "892  2019-05-24 13:05:00  \n",
       "893  2019-05-24 13:35:00  \n",
       "894  2019-05-28 16:20:00  \n",
       "895  2019-05-28 20:55:00  \n",
       "896  2019-05-29 05:30:00  \n",
       "\n",
       "[897 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-17 07:15:00</td>\n",
       "      <td>4513</td>\n",
       "      <td>5.88</td>\n",
       "      <td>284.799</td>\n",
       "      <td>9.618</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>-4.797</td>\n",
       "      <td>1.262</td>\n",
       "      <td>0.06</td>\n",
       "      <td>7.48</td>\n",
       "      <td>4518</td>\n",
       "      <td>2019-09-17 07:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-17 15:00:00</td>\n",
       "      <td>4606</td>\n",
       "      <td>5.13</td>\n",
       "      <td>294.556</td>\n",
       "      <td>7.924</td>\n",
       "      <td>2.822</td>\n",
       "      <td>-3.960</td>\n",
       "      <td>1.790</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.21</td>\n",
       "      <td>4611</td>\n",
       "      <td>2019-09-17 15:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-17 15:30:00</td>\n",
       "      <td>4612</td>\n",
       "      <td>5.03</td>\n",
       "      <td>294.403</td>\n",
       "      <td>8.730</td>\n",
       "      <td>2.950</td>\n",
       "      <td>-3.825</td>\n",
       "      <td>1.777</td>\n",
       "      <td>0.02</td>\n",
       "      <td>22.56</td>\n",
       "      <td>4617</td>\n",
       "      <td>2019-09-17 15:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-17 16:25:00</td>\n",
       "      <td>4623</td>\n",
       "      <td>5.12</td>\n",
       "      <td>235.839</td>\n",
       "      <td>10.102</td>\n",
       "      <td>3.665</td>\n",
       "      <td>-2.655</td>\n",
       "      <td>-1.760</td>\n",
       "      <td>0.06</td>\n",
       "      <td>23.84</td>\n",
       "      <td>4628</td>\n",
       "      <td>2019-09-17 16:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-09-20 09:35:00</td>\n",
       "      <td>5404</td>\n",
       "      <td>6.17</td>\n",
       "      <td>251.279</td>\n",
       "      <td>19.678</td>\n",
       "      <td>-1.085</td>\n",
       "      <td>-2.295</td>\n",
       "      <td>-0.712</td>\n",
       "      <td>0.04</td>\n",
       "      <td>24.22</td>\n",
       "      <td>5409</td>\n",
       "      <td>2019-09-20 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>2020-05-30 10:35:00</td>\n",
       "      <td>71251</td>\n",
       "      <td>5.23</td>\n",
       "      <td>267.097</td>\n",
       "      <td>13.176</td>\n",
       "      <td>5.738</td>\n",
       "      <td>-10.587</td>\n",
       "      <td>-0.558</td>\n",
       "      <td>0.04</td>\n",
       "      <td>20.43</td>\n",
       "      <td>71256</td>\n",
       "      <td>2020-05-30 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>2020-05-30 11:05:00</td>\n",
       "      <td>71257</td>\n",
       "      <td>5.37</td>\n",
       "      <td>270.261</td>\n",
       "      <td>13.730</td>\n",
       "      <td>5.477</td>\n",
       "      <td>-10.423</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7.24</td>\n",
       "      <td>71262</td>\n",
       "      <td>2020-05-30 11:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>2020-05-30 12:00:00</td>\n",
       "      <td>71268</td>\n",
       "      <td>5.37</td>\n",
       "      <td>278.151</td>\n",
       "      <td>14.696</td>\n",
       "      <td>4.732</td>\n",
       "      <td>-9.122</td>\n",
       "      <td>1.333</td>\n",
       "      <td>0.09</td>\n",
       "      <td>11.86</td>\n",
       "      <td>71273</td>\n",
       "      <td>2020-05-30 12:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>2020-05-30 13:20:00</td>\n",
       "      <td>71284</td>\n",
       "      <td>5.57</td>\n",
       "      <td>288.296</td>\n",
       "      <td>16.002</td>\n",
       "      <td>4.653</td>\n",
       "      <td>-8.377</td>\n",
       "      <td>2.793</td>\n",
       "      <td>0.09</td>\n",
       "      <td>25.20</td>\n",
       "      <td>71289</td>\n",
       "      <td>2020-05-30 13:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>2020-05-30 13:50:00</td>\n",
       "      <td>71290</td>\n",
       "      <td>5.78</td>\n",
       "      <td>301.037</td>\n",
       "      <td>16.463</td>\n",
       "      <td>5.362</td>\n",
       "      <td>-6.838</td>\n",
       "      <td>4.105</td>\n",
       "      <td>0.06</td>\n",
       "      <td>16.29</td>\n",
       "      <td>71295</td>\n",
       "      <td>2020-05-30 14:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2019-09-17 07:15:00       4513      5.88    284.799     9.618   \n",
       "1    2019-09-17 15:00:00       4606      5.13    294.556     7.924   \n",
       "2    2019-09-17 15:30:00       4612      5.03    294.403     8.730   \n",
       "3    2019-09-17 16:25:00       4623      5.12    235.839    10.102   \n",
       "4    2019-09-20 09:35:00       5404      6.17    251.279    19.678   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "527  2020-05-30 10:35:00      71251      5.23    267.097    13.176   \n",
       "528  2020-05-30 11:05:00      71257      5.37    270.261    13.730   \n",
       "529  2020-05-30 12:00:00      71268      5.37    278.151    14.696   \n",
       "530  2020-05-30 13:20:00      71284      5.57    288.296    16.002   \n",
       "531  2020-05-30 13:50:00      71290      5.78    301.037    16.463   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0        -0.280      -4.797       1.262     0.06    7.48     4518   \n",
       "1         2.822      -3.960       1.790     0.03    9.21     4611   \n",
       "2         2.950      -3.825       1.777     0.02   22.56     4617   \n",
       "3         3.665      -2.655      -1.760     0.06   23.84     4628   \n",
       "4        -1.085      -2.295      -0.712     0.04   24.22     5409   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "527       5.738     -10.587      -0.558     0.04   20.43    71256   \n",
       "528       5.477     -10.423       0.052     0.05    7.24    71262   \n",
       "529       4.732      -9.122       1.333     0.09   11.86    71273   \n",
       "530       4.653      -8.377       2.793     0.09   25.20    71289   \n",
       "531       5.362      -6.838       4.105     0.06   16.29    71295   \n",
       "\n",
       "                 End_str  \n",
       "0    2019-09-17 07:40:00  \n",
       "1    2019-09-17 15:25:00  \n",
       "2    2019-09-17 15:55:00  \n",
       "3    2019-09-17 16:50:00  \n",
       "4    2019-09-20 10:00:00  \n",
       "..                   ...  \n",
       "527  2020-05-30 11:00:00  \n",
       "528  2020-05-30 11:30:00  \n",
       "529  2020-05-30 12:25:00  \n",
       "530  2020-05-30 13:45:00  \n",
       "531  2020-05-30 14:15:00  \n",
       "\n",
       "[532 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-04 11:55:00</td>\n",
       "      <td>1006</td>\n",
       "      <td>5.82</td>\n",
       "      <td>230.346</td>\n",
       "      <td>16.924</td>\n",
       "      <td>-1.595</td>\n",
       "      <td>-3.253</td>\n",
       "      <td>-2.697</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1011</td>\n",
       "      <td>2020-09-04 12:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-05 11:30:00</td>\n",
       "      <td>1287</td>\n",
       "      <td>5.78</td>\n",
       "      <td>278.429</td>\n",
       "      <td>17.760</td>\n",
       "      <td>-2.863</td>\n",
       "      <td>-3.333</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.09</td>\n",
       "      <td>16.08</td>\n",
       "      <td>1292</td>\n",
       "      <td>2020-09-05 11:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-05 12:05:00</td>\n",
       "      <td>1294</td>\n",
       "      <td>5.88</td>\n",
       "      <td>280.664</td>\n",
       "      <td>18.234</td>\n",
       "      <td>-1.750</td>\n",
       "      <td>-4.168</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.02</td>\n",
       "      <td>15.71</td>\n",
       "      <td>1299</td>\n",
       "      <td>2020-09-05 12:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-05 13:50:00</td>\n",
       "      <td>1315</td>\n",
       "      <td>5.70</td>\n",
       "      <td>306.456</td>\n",
       "      <td>19.565</td>\n",
       "      <td>-2.135</td>\n",
       "      <td>-3.267</td>\n",
       "      <td>2.450</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28.62</td>\n",
       "      <td>1320</td>\n",
       "      <td>2020-09-05 14:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-05 14:20:00</td>\n",
       "      <td>1321</td>\n",
       "      <td>5.73</td>\n",
       "      <td>289.126</td>\n",
       "      <td>19.921</td>\n",
       "      <td>-1.967</td>\n",
       "      <td>-3.955</td>\n",
       "      <td>1.370</td>\n",
       "      <td>0.05</td>\n",
       "      <td>23.20</td>\n",
       "      <td>1326</td>\n",
       "      <td>2020-09-05 14:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>2021-05-25 12:00:00</td>\n",
       "      <td>73973</td>\n",
       "      <td>5.80</td>\n",
       "      <td>269.120</td>\n",
       "      <td>11.525</td>\n",
       "      <td>0.857</td>\n",
       "      <td>-3.748</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>0.06</td>\n",
       "      <td>16.75</td>\n",
       "      <td>73978</td>\n",
       "      <td>2021-05-25 12:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>2021-05-25 12:40:00</td>\n",
       "      <td>73981</td>\n",
       "      <td>6.40</td>\n",
       "      <td>286.236</td>\n",
       "      <td>10.695</td>\n",
       "      <td>1.723</td>\n",
       "      <td>-2.167</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10.34</td>\n",
       "      <td>73986</td>\n",
       "      <td>2021-05-25 13:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>2021-05-25 21:55:00</td>\n",
       "      <td>74089</td>\n",
       "      <td>5.92</td>\n",
       "      <td>228.189</td>\n",
       "      <td>7.845</td>\n",
       "      <td>0.762</td>\n",
       "      <td>-2.085</td>\n",
       "      <td>-1.870</td>\n",
       "      <td>0.10</td>\n",
       "      <td>11.83</td>\n",
       "      <td>74094</td>\n",
       "      <td>2021-05-25 22:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>2021-05-26 01:55:00</td>\n",
       "      <td>74137</td>\n",
       "      <td>6.68</td>\n",
       "      <td>235.480</td>\n",
       "      <td>13.013</td>\n",
       "      <td>1.132</td>\n",
       "      <td>-1.710</td>\n",
       "      <td>-1.178</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5.03</td>\n",
       "      <td>74142</td>\n",
       "      <td>2021-05-26 02:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>2021-05-30 00:35:00</td>\n",
       "      <td>75273</td>\n",
       "      <td>5.58</td>\n",
       "      <td>307.561</td>\n",
       "      <td>21.742</td>\n",
       "      <td>3.385</td>\n",
       "      <td>-3.318</td>\n",
       "      <td>2.555</td>\n",
       "      <td>0.04</td>\n",
       "      <td>4.51</td>\n",
       "      <td>75278</td>\n",
       "      <td>2021-05-30 01:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>642 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2020-09-04 11:55:00       1006      5.82    230.346    16.924   \n",
       "1    2020-09-05 11:30:00       1287      5.78    278.429    17.760   \n",
       "2    2020-09-05 12:05:00       1294      5.88    280.664    18.234   \n",
       "3    2020-09-05 13:50:00       1315      5.70    306.456    19.565   \n",
       "4    2020-09-05 14:20:00       1321      5.73    289.126    19.921   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "637  2021-05-25 12:00:00      73973      5.80    269.120    11.525   \n",
       "638  2021-05-25 12:40:00      73981      6.40    286.236    10.695   \n",
       "639  2021-05-25 21:55:00      74089      5.92    228.189     7.845   \n",
       "640  2021-05-26 01:55:00      74137      6.68    235.480    13.013   \n",
       "641  2021-05-30 00:35:00      75273      5.58    307.561    21.742   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0        -1.595      -3.253      -2.697     0.03    3.61     1011   \n",
       "1        -2.863      -3.333       0.495     0.09   16.08     1292   \n",
       "2        -1.750      -4.168       0.778     0.02   15.71     1299   \n",
       "3        -2.135      -3.267       2.450     0.05   28.62     1320   \n",
       "4        -1.967      -3.955       1.370     0.05   23.20     1326   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "637       0.857      -3.748      -0.070     0.06   16.75    73978   \n",
       "638       1.723      -2.167       0.625     0.02   10.34    73986   \n",
       "639       0.762      -2.085      -1.870     0.10   11.83    74094   \n",
       "640       1.132      -1.710      -1.178     0.08    5.03    74142   \n",
       "641       3.385      -3.318       2.555     0.04    4.51    75278   \n",
       "\n",
       "                 End_str  \n",
       "0    2020-09-04 12:20:00  \n",
       "1    2020-09-05 11:55:00  \n",
       "2    2020-09-05 12:30:00  \n",
       "3    2020-09-05 14:15:00  \n",
       "4    2020-09-05 14:45:00  \n",
       "..                   ...  \n",
       "637  2021-05-25 12:25:00  \n",
       "638  2021-05-25 13:05:00  \n",
       "639  2021-05-25 22:20:00  \n",
       "640  2021-05-26 02:20:00  \n",
       "641  2021-05-30 01:00:00  \n",
       "\n",
       "[642 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Displaying Dayside(Sept-May)Yr 1-6 PosBy Stable Lists\n",
      "\n",
      "Displaying Dayside(Sept-May)Yr 1-6 NorBz Stable Lists\n",
      "Displaying Dayside(Sept-May)Yr 1-6 General Stable Lists\n"
     ]
    }
   ],
   "source": [
    "# Importing yearly MEC positional data\n",
    "    #Extracting MEC radial position(km) and time(unix time) arrays\n",
    "#Load Dayside MEC Data\n",
    "yr1_MECposdata = np.load(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/MEC exported Dayside posdata/yr1_MECgsm_posdata.npz')\n",
    "yr2_MECposdata = np.load(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/MEC exported Dayside posdata/yr2_MECgsm_posdata.npz')\n",
    "yr3_MECposdata = np.load(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/MEC exported Dayside posdata/yr3_MECgsm_posdata.npz')\n",
    "yr4_MECposdata = np.load(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/MEC exported Dayside posdata/yr4_MECgsm_posdata.npz')\n",
    "yr5_MECposdata = np.load(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/MEC exported Dayside posdata/yr5_MECgsm_posdata.npz')\n",
    "yr6_MECposdata = np.load(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/MEC exported Dayside posdata/Dayside_yr6_MECgsm_posdata.npz')\n",
    "\n",
    "print(sorted(yr5_MECposdata))\n",
    "\n",
    "def show1to5DF(df_1, df_2, df_3, df_4, df_5):\n",
    "    \"\"\"Displays Yrs 1to5 DFs\"\"\"\n",
    "    display(df_1)\n",
    "    display(df_2)\n",
    "    display(df_3)\n",
    "    display(df_4)\n",
    "    display(df_5)\n",
    "    return;\n",
    "\n",
    "def show1to6DF(df_1, df_2, df_3, df_4, df_5, df_6):\n",
    "    \"\"\"Displays Yrs 1to6 DFs\"\"\"\n",
    "    display(df_1)\n",
    "    display(df_2)\n",
    "    display(df_3)\n",
    "    display(df_4)\n",
    "    display(df_5)\n",
    "    display(df_6)\n",
    "    return;\n",
    "\n",
    "#'''\n",
    "#Importing Yr 1-5 SoBZ Stable List\n",
    "df_DaysoBz_yr1 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_soBz_withBcomp/pdFile_Day_Yr1_7to24Re_30mFilt_Stable_soBz.txt', sep = '\\t')\n",
    "df_DaysoBz_yr2 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_soBz_withBcomp/pdFile_Day_Yr2_7to24Re_30mFilt_Stable_soBz.txt', sep = '\\t')\n",
    "df_DaysoBz_yr3 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_soBz_withBcomp/pdFile_Day_Yr3_7to24Re_30mFilt_Stable_soBz.txt', sep = '\\t')\n",
    "df_DaysoBz_yr4 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_soBz_withBcomp/pdFile_Day_Yr4_7to24Re_30mFilt_Stable_soBz.txt', sep = '\\t')\n",
    "df_DaysoBz_yr5 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_soBz_withBcomp/pdFile_Day_Yr5_7to24Re_30mFilt_Stable_soBz_noMECgap.txt', sep = '\\t')\n",
    "df_DaysoBz_yr6 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_soBz_withBcomp/pdFile_Day_Yr6_7to24Re_30mFilt_Stable_soBz.txt', sep = '\\t')\n",
    "\n",
    "print('Displaying Dayside(Sept-May)Yr 1-6 SoBz Stable Lists')\n",
    "print(df_DaysoBz_yr1.dtypes) #displaying column names and type of column data\n",
    "#show1to6DF(df_DaysoBz_yr1, df_DaysoBz_yr2, df_DaysoBz_yr3, df_DaysoBz_yr4, df_DaysoBz_yr5, df_DaysoBz_yr6)\n",
    "\n",
    "#Importing Yr1-5 -By Stable List\n",
    "df_DaynegBy_yr1 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_negBy_withBcomp/pdFile_Day_Yr1_7to24Re_30mFilt_Stable_negBy.txt', sep = '\\t')\n",
    "df_DaynegBy_yr2 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_negBy_withBcomp/pdFile_Day_Yr2_7to24Re_30mFilt_Stable_negBy.txt', sep = '\\t')\n",
    "df_DaynegBy_yr3 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_negBy_withBcomp/pdFile_Day_Yr3_7to24Re_30mFilt_Stable_negBy.txt', sep = '\\t')\n",
    "df_DaynegBy_yr4 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_negBy_withBcomp/pdFile_Day_Yr4_7to24Re_30mFilt_Stable_negBy.txt', sep = '\\t')\n",
    "df_DaynegBy_yr5 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_negBy_withBcomp/pdFile_Day_Yr5_7to24Re_30mFilt_Stable_negBy_noMECgap_incr.txt', sep = '\\t')\n",
    "df_DaynegBy_yr6 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_negBy_withBcomp/pdFile_Day_Yr6_7to24Re_30mFilt_Stable_negBy.txt', sep = '\\t')\n",
    "\n",
    "print('\\nDisplaying Dayside(Sept-May)Yr 1-6 NegBy Stable Lists')\n",
    "show1to6DF(df_DaynegBy_yr1, df_DaynegBy_yr2, df_DaynegBy_yr3, df_DaynegBy_yr4, df_DaynegBy_yr5, df_DaynegBy_yr6)\n",
    "\n",
    "#Importing Yr1-5 +By Stable List\n",
    "df_DayposBy_yr1 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_posBy_withBcomp/pdFile_Day_Yr1_7to24Re_30mFilt_Stable_posBy.txt', sep = '\\t')\n",
    "df_DayposBy_yr2 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_posBy_withBcomp/pdFile_Day_Yr2_7to24Re_30mFilt_Stable_posBy.txt', sep = '\\t')\n",
    "df_DayposBy_yr3 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_posBy_withBcomp/pdFile_Day_Yr3_7to24Re_30mFilt_Stable_posBy.txt', sep = '\\t')\n",
    "df_DayposBy_yr4 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_posBy_withBcomp/pdFile_Day_Yr4_7to24Re_30mFilt_Stable_posBy.txt', sep = '\\t')\n",
    "df_DayposBy_yr5 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_posBy_withBcomp/pdFile_Day_Yr5_7to24Re_30mFilt_Stable_posBy_noMECgap_incr.txt', sep = '\\t')\n",
    "df_DayposBy_yr6 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_posBy_withBcomp/pdFile_Day_Yr6_7to24Re_30mFilt_Stable_posBy.txt', sep = '\\t')\n",
    "\n",
    "print('\\nDisplaying Dayside(Sept-May)Yr 1-6 PosBy Stable Lists')\n",
    "#show1to6DF(df_DayposBy_yr1, df_DayposBy_yr2, df_DayposBy_yr3, df_DayposBy_yr4, df_DayposBy_yr5, df_DayposBy_yr6)\n",
    "\n",
    "\n",
    "#Importing Yr 1-5 NorBz Stable List\n",
    "df_DaynorBz_yr1 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_norBz_withBcomp/pdFile_Day_Yr1_7to24Re_30mFilt_Stable_norBz.txt', sep = '\\t')\n",
    "df_DaynorBz_yr2 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_norBz_withBcomp/pdFile_Day_Yr2_7to24Re_30mFilt_Stable_norBz.txt', sep = '\\t')\n",
    "df_DaynorBz_yr3 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_norBz_withBcomp/pdFile_Day_Yr3_7to24Re_30mFilt_Stable_norBz.txt', sep = '\\t')\n",
    "df_DaynorBz_yr4 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_norBz_withBcomp/pdFile_Day_Yr4_7to24Re_30mFilt_Stable_norBz.txt', sep = '\\t')\n",
    "df_DaynorBz_yr5 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_norBz_withBcomp/pdFile_Day_Yr5_7to24Re_30mFilt_Stable_norBz_noMECgap.txt', sep = '\\t')\n",
    "df_DaynorBz_yr6 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_norBz_withBcomp/pdFile_Day_Yr6_7to24Re_30mFilt_Stable_norBz.txt', sep = '\\t')\n",
    "\n",
    "print('\\nDisplaying Dayside(Sept-May)Yr 1-6 NorBz Stable Lists')\n",
    "#show1to6DF(df_DaynorBz_yr1, df_DaynorBz_yr2, df_DaynorBz_yr3, df_DaynorBz_yr4, df_DaynorBz_yr5, df_DaynorBz_yr6)\n",
    "\n",
    "#'''\n",
    "#Importing Yr 1-5 NonClang Sorted Stable Lists\n",
    "df_Daystable_yr1 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_General_withBcomp/pdFile_Day_Yr1_7to24Re_30mFilt_Stable_General.txt', sep = '\\t')\n",
    "df_Daystable_yr2 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_General_withBcomp/pdFile_Day_Yr2_7to24Re_30mFilt_Stable_General.txt', sep = '\\t')\n",
    "df_Daystable_yr3 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_General_withBcomp/pdFile_Day_Yr3_7to24Re_30mFilt_Stable_General.txt', sep = '\\t')\n",
    "df_Daystable_yr4 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_General_withBcomp/pdFile_Day_Yr4_7to24Re_30mFilt_Stable_General.txt', sep = '\\t')\n",
    "df_Daystable_yr5 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_General_withBcomp/pdFile_Day_Yr5_7to24Re_30mFilt_Stable_General_noMECgap.txt', sep = '\\t')\n",
    "df_Daystable_yr6 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "'Stable Day List_with Bcomps/pdFile_Day_General_withBcomp/pdFile_Day_Yr6_7to24Re_30mFilt_Stable_General.txt', sep = '\\t')\n",
    "\n",
    "print('Displaying Dayside(Sept-May)Yr 1-6 General Stable Lists')\n",
    "#print(df_soBz_yr1.dtypes) #displaying column names and type of column data\n",
    "#show1to6DF(df_Daystable_yr1, df_Daystable_yr2, df_Daystable_yr3, df_Daystable_yr4, df_Daystable_yr5, df_Daystable_yr6)\n",
    "#''';\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aed4bf",
   "metadata": {},
   "source": [
    "#### Importing Nightside(Jun to Aug) Yrs1-7 Stable IMF Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfc6b993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying Nightside(Jun-Aug)Yr 1-7 SoBz Stable Lists\n",
      "Start_str      object\n",
      "Start_ind       int64\n",
      "Mgs#_avg      float64\n",
      "Clang_avg     float64\n",
      "Rmag_avg      float64\n",
      "Bx_avg(nT)    float64\n",
      "By_avg(nT)    float64\n",
      "Bz_avg(nT)    float64\n",
      "Bdeviat       float64\n",
      "Dtheta        float64\n",
      "End_ind         int64\n",
      "End_str        object\n",
      "dtype: object\n",
      "Displaying Nightside(Jun-Aug)Yr 1-7 norBz Stable Lists\n",
      "Displaying Nightside(Jun-Aug)Yr 1-7 posBy Stable Lists\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-06-01 07:30:00</td>\n",
       "      <td>90</td>\n",
       "      <td>5.02</td>\n",
       "      <td>112.984</td>\n",
       "      <td>10.912</td>\n",
       "      <td>-3.340</td>\n",
       "      <td>4.468</td>\n",
       "      <td>-1.863</td>\n",
       "      <td>0.03</td>\n",
       "      <td>18.25</td>\n",
       "      <td>95</td>\n",
       "      <td>2015-06-01 07:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-01 08:00:00</td>\n",
       "      <td>96</td>\n",
       "      <td>5.10</td>\n",
       "      <td>93.657</td>\n",
       "      <td>10.634</td>\n",
       "      <td>-1.402</td>\n",
       "      <td>5.523</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>0.01</td>\n",
       "      <td>13.42</td>\n",
       "      <td>101</td>\n",
       "      <td>2015-06-01 08:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-06-01 10:30:00</td>\n",
       "      <td>126</td>\n",
       "      <td>5.03</td>\n",
       "      <td>82.656</td>\n",
       "      <td>8.670</td>\n",
       "      <td>-3.748</td>\n",
       "      <td>3.315</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.05</td>\n",
       "      <td>24.08</td>\n",
       "      <td>131</td>\n",
       "      <td>2015-06-01 10:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-01 21:15:00</td>\n",
       "      <td>243</td>\n",
       "      <td>5.12</td>\n",
       "      <td>56.757</td>\n",
       "      <td>10.035</td>\n",
       "      <td>-0.642</td>\n",
       "      <td>4.498</td>\n",
       "      <td>2.995</td>\n",
       "      <td>0.09</td>\n",
       "      <td>26.53</td>\n",
       "      <td>248</td>\n",
       "      <td>2015-06-01 21:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-06-02 03:30:00</td>\n",
       "      <td>318</td>\n",
       "      <td>5.05</td>\n",
       "      <td>47.210</td>\n",
       "      <td>12.009</td>\n",
       "      <td>0.610</td>\n",
       "      <td>4.537</td>\n",
       "      <td>4.170</td>\n",
       "      <td>0.09</td>\n",
       "      <td>18.98</td>\n",
       "      <td>323</td>\n",
       "      <td>2015-06-02 03:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>2015-08-26 01:45:00</td>\n",
       "      <td>22470</td>\n",
       "      <td>5.80</td>\n",
       "      <td>100.515</td>\n",
       "      <td>7.664</td>\n",
       "      <td>3.415</td>\n",
       "      <td>6.328</td>\n",
       "      <td>-1.225</td>\n",
       "      <td>0.06</td>\n",
       "      <td>18.33</td>\n",
       "      <td>22475</td>\n",
       "      <td>2015-08-26 02:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2015-08-26 02:15:00</td>\n",
       "      <td>22476</td>\n",
       "      <td>5.72</td>\n",
       "      <td>103.717</td>\n",
       "      <td>7.034</td>\n",
       "      <td>2.693</td>\n",
       "      <td>6.778</td>\n",
       "      <td>-1.738</td>\n",
       "      <td>0.05</td>\n",
       "      <td>29.79</td>\n",
       "      <td>22481</td>\n",
       "      <td>2015-08-26 02:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2015-08-26 10:00:00</td>\n",
       "      <td>22530</td>\n",
       "      <td>5.45</td>\n",
       "      <td>126.521</td>\n",
       "      <td>8.618</td>\n",
       "      <td>4.793</td>\n",
       "      <td>6.402</td>\n",
       "      <td>-4.810</td>\n",
       "      <td>0.03</td>\n",
       "      <td>28.87</td>\n",
       "      <td>22535</td>\n",
       "      <td>2015-08-26 10:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2015-08-26 10:30:00</td>\n",
       "      <td>22536</td>\n",
       "      <td>5.48</td>\n",
       "      <td>120.923</td>\n",
       "      <td>9.097</td>\n",
       "      <td>5.012</td>\n",
       "      <td>6.795</td>\n",
       "      <td>-4.067</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6.13</td>\n",
       "      <td>22541</td>\n",
       "      <td>2015-08-26 10:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2015-08-26 11:00:00</td>\n",
       "      <td>22542</td>\n",
       "      <td>5.72</td>\n",
       "      <td>129.472</td>\n",
       "      <td>9.531</td>\n",
       "      <td>4.268</td>\n",
       "      <td>6.008</td>\n",
       "      <td>-4.945</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6.35</td>\n",
       "      <td>22547</td>\n",
       "      <td>2015-08-26 11:25:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2015-06-01 07:30:00         90      5.02    112.984    10.912   \n",
       "1    2015-06-01 08:00:00         96      5.10     93.657    10.634   \n",
       "2    2015-06-01 10:30:00        126      5.03     82.656     8.670   \n",
       "3    2015-06-01 21:15:00        243      5.12     56.757    10.035   \n",
       "4    2015-06-02 03:30:00        318      5.05     47.210    12.009   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "394  2015-08-26 01:45:00      22470      5.80    100.515     7.664   \n",
       "395  2015-08-26 02:15:00      22476      5.72    103.717     7.034   \n",
       "396  2015-08-26 10:00:00      22530      5.45    126.521     8.618   \n",
       "397  2015-08-26 10:30:00      22536      5.48    120.923     9.097   \n",
       "398  2015-08-26 11:00:00      22542      5.72    129.472     9.531   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0        -3.340       4.468      -1.863     0.03   18.25       95   \n",
       "1        -1.402       5.523      -0.335     0.01   13.42      101   \n",
       "2        -3.748       3.315       0.452     0.05   24.08      131   \n",
       "3        -0.642       4.498       2.995     0.09   26.53      248   \n",
       "4         0.610       4.537       4.170     0.09   18.98      323   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "394       3.415       6.328      -1.225     0.06   18.33    22475   \n",
       "395       2.693       6.778      -1.738     0.05   29.79    22481   \n",
       "396       4.793       6.402      -4.810     0.03   28.87    22535   \n",
       "397       5.012       6.795      -4.067     0.03    6.13    22541   \n",
       "398       4.268       6.008      -4.945     0.03    6.35    22547   \n",
       "\n",
       "                 End_str  \n",
       "0    2015-06-01 07:55:00  \n",
       "1    2015-06-01 08:25:00  \n",
       "2    2015-06-01 10:55:00  \n",
       "3    2015-06-01 21:40:00  \n",
       "4    2015-06-02 03:55:00  \n",
       "..                   ...  \n",
       "394  2015-08-26 02:10:00  \n",
       "395  2015-08-26 02:40:00  \n",
       "396  2015-08-26 10:25:00  \n",
       "397  2015-08-26 10:55:00  \n",
       "398  2015-08-26 11:25:00  \n",
       "\n",
       "[399 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-06-02 00:30:00</td>\n",
       "      <td>293</td>\n",
       "      <td>5.38</td>\n",
       "      <td>57.640</td>\n",
       "      <td>7.045</td>\n",
       "      <td>4.173</td>\n",
       "      <td>1.298</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.09</td>\n",
       "      <td>16.64</td>\n",
       "      <td>298</td>\n",
       "      <td>2016-06-02 00:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-06-05 03:35:00</td>\n",
       "      <td>1144</td>\n",
       "      <td>5.88</td>\n",
       "      <td>115.085</td>\n",
       "      <td>10.329</td>\n",
       "      <td>-1.730</td>\n",
       "      <td>5.193</td>\n",
       "      <td>-2.432</td>\n",
       "      <td>0.09</td>\n",
       "      <td>25.72</td>\n",
       "      <td>1149</td>\n",
       "      <td>2016-06-05 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-06-09 09:55:00</td>\n",
       "      <td>2363</td>\n",
       "      <td>5.53</td>\n",
       "      <td>53.073</td>\n",
       "      <td>11.896</td>\n",
       "      <td>3.258</td>\n",
       "      <td>1.760</td>\n",
       "      <td>1.318</td>\n",
       "      <td>0.09</td>\n",
       "      <td>5.56</td>\n",
       "      <td>2368</td>\n",
       "      <td>2016-06-09 10:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-06-10 16:00:00</td>\n",
       "      <td>2724</td>\n",
       "      <td>5.32</td>\n",
       "      <td>78.493</td>\n",
       "      <td>8.385</td>\n",
       "      <td>-3.650</td>\n",
       "      <td>6.497</td>\n",
       "      <td>1.327</td>\n",
       "      <td>0.08</td>\n",
       "      <td>14.46</td>\n",
       "      <td>2729</td>\n",
       "      <td>2016-06-10 16:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-06-10 16:30:00</td>\n",
       "      <td>2730</td>\n",
       "      <td>5.12</td>\n",
       "      <td>72.778</td>\n",
       "      <td>7.829</td>\n",
       "      <td>-3.775</td>\n",
       "      <td>7.142</td>\n",
       "      <td>2.238</td>\n",
       "      <td>0.10</td>\n",
       "      <td>16.21</td>\n",
       "      <td>2735</td>\n",
       "      <td>2016-06-10 16:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2016-08-28 14:40:00</td>\n",
       "      <td>22632</td>\n",
       "      <td>6.08</td>\n",
       "      <td>53.856</td>\n",
       "      <td>7.346</td>\n",
       "      <td>2.382</td>\n",
       "      <td>2.430</td>\n",
       "      <td>1.788</td>\n",
       "      <td>0.05</td>\n",
       "      <td>27.54</td>\n",
       "      <td>22637</td>\n",
       "      <td>2016-08-28 15:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2016-08-29 17:25:00</td>\n",
       "      <td>22881</td>\n",
       "      <td>5.70</td>\n",
       "      <td>128.040</td>\n",
       "      <td>10.092</td>\n",
       "      <td>-3.610</td>\n",
       "      <td>2.393</td>\n",
       "      <td>-1.920</td>\n",
       "      <td>0.05</td>\n",
       "      <td>27.10</td>\n",
       "      <td>22886</td>\n",
       "      <td>2016-08-29 17:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2016-08-30 03:25:00</td>\n",
       "      <td>22951</td>\n",
       "      <td>5.00</td>\n",
       "      <td>134.520</td>\n",
       "      <td>10.878</td>\n",
       "      <td>-6.558</td>\n",
       "      <td>2.717</td>\n",
       "      <td>-2.707</td>\n",
       "      <td>0.07</td>\n",
       "      <td>25.62</td>\n",
       "      <td>22956</td>\n",
       "      <td>2016-08-30 03:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2016-08-30 19:05:00</td>\n",
       "      <td>23101</td>\n",
       "      <td>5.72</td>\n",
       "      <td>54.188</td>\n",
       "      <td>11.119</td>\n",
       "      <td>-1.313</td>\n",
       "      <td>6.098</td>\n",
       "      <td>4.440</td>\n",
       "      <td>0.05</td>\n",
       "      <td>17.72</td>\n",
       "      <td>23106</td>\n",
       "      <td>2016-08-30 19:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>2016-08-30 20:35:00</td>\n",
       "      <td>23119</td>\n",
       "      <td>6.30</td>\n",
       "      <td>79.704</td>\n",
       "      <td>11.663</td>\n",
       "      <td>-3.705</td>\n",
       "      <td>3.725</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.06</td>\n",
       "      <td>22.21</td>\n",
       "      <td>23124</td>\n",
       "      <td>2016-08-30 21:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2016-06-02 00:30:00        293      5.38     57.640     7.045   \n",
       "1    2016-06-05 03:35:00       1144      5.88    115.085    10.329   \n",
       "2    2016-06-09 09:55:00       2363      5.53     53.073    11.896   \n",
       "3    2016-06-10 16:00:00       2724      5.32     78.493     8.385   \n",
       "4    2016-06-10 16:30:00       2730      5.12     72.778     7.829   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "230  2016-08-28 14:40:00      22632      6.08     53.856     7.346   \n",
       "231  2016-08-29 17:25:00      22881      5.70    128.040    10.092   \n",
       "232  2016-08-30 03:25:00      22951      5.00    134.520    10.878   \n",
       "233  2016-08-30 19:05:00      23101      5.72     54.188    11.119   \n",
       "234  2016-08-30 20:35:00      23119      6.30     79.704    11.663   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0         4.173       1.298       0.803     0.09   16.64      298   \n",
       "1        -1.730       5.193      -2.432     0.09   25.72     1149   \n",
       "2         3.258       1.760       1.318     0.09    5.56     2368   \n",
       "3        -3.650       6.497       1.327     0.08   14.46     2729   \n",
       "4        -3.775       7.142       2.238     0.10   16.21     2735   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "230       2.382       2.430       1.788     0.05   27.54    22637   \n",
       "231      -3.610       2.393      -1.920     0.05   27.10    22886   \n",
       "232      -6.558       2.717      -2.707     0.07   25.62    22956   \n",
       "233      -1.313       6.098       4.440     0.05   17.72    23106   \n",
       "234      -3.705       3.725       0.690     0.06   22.21    23124   \n",
       "\n",
       "                 End_str  \n",
       "0    2016-06-02 00:55:00  \n",
       "1    2016-06-05 04:00:00  \n",
       "2    2016-06-09 10:20:00  \n",
       "3    2016-06-10 16:25:00  \n",
       "4    2016-06-10 16:55:00  \n",
       "..                   ...  \n",
       "230  2016-08-28 15:05:00  \n",
       "231  2016-08-29 17:50:00  \n",
       "232  2016-08-30 03:50:00  \n",
       "233  2016-08-30 19:30:00  \n",
       "234  2016-08-30 21:00:00  \n",
       "\n",
       "[235 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>5.12</td>\n",
       "      <td>66.934</td>\n",
       "      <td>22.907</td>\n",
       "      <td>-2.442</td>\n",
       "      <td>6.127</td>\n",
       "      <td>2.598</td>\n",
       "      <td>0.07</td>\n",
       "      <td>15.50</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-06-01 00:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-06-01 00:30:00</td>\n",
       "      <td>6</td>\n",
       "      <td>5.42</td>\n",
       "      <td>62.966</td>\n",
       "      <td>22.718</td>\n",
       "      <td>-1.187</td>\n",
       "      <td>6.173</td>\n",
       "      <td>3.150</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6.66</td>\n",
       "      <td>11</td>\n",
       "      <td>2017-06-01 00:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-06-01 01:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>5.35</td>\n",
       "      <td>69.270</td>\n",
       "      <td>22.521</td>\n",
       "      <td>-1.030</td>\n",
       "      <td>6.558</td>\n",
       "      <td>2.468</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.92</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-06-01 01:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-06-01 01:30:00</td>\n",
       "      <td>18</td>\n",
       "      <td>5.22</td>\n",
       "      <td>66.155</td>\n",
       "      <td>22.314</td>\n",
       "      <td>-1.557</td>\n",
       "      <td>6.302</td>\n",
       "      <td>2.783</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.43</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-06-01 01:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-06-01 02:00:00</td>\n",
       "      <td>24</td>\n",
       "      <td>5.28</td>\n",
       "      <td>61.896</td>\n",
       "      <td>22.099</td>\n",
       "      <td>-3.812</td>\n",
       "      <td>5.147</td>\n",
       "      <td>2.735</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.93</td>\n",
       "      <td>29</td>\n",
       "      <td>2017-06-01 02:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2017-08-25 15:20:00</td>\n",
       "      <td>22756</td>\n",
       "      <td>5.37</td>\n",
       "      <td>91.360</td>\n",
       "      <td>20.993</td>\n",
       "      <td>-2.992</td>\n",
       "      <td>5.058</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>0.05</td>\n",
       "      <td>11.95</td>\n",
       "      <td>22761</td>\n",
       "      <td>2017-08-25 15:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2017-08-25 16:25:00</td>\n",
       "      <td>22769</td>\n",
       "      <td>5.48</td>\n",
       "      <td>120.968</td>\n",
       "      <td>21.543</td>\n",
       "      <td>-2.938</td>\n",
       "      <td>3.703</td>\n",
       "      <td>-2.227</td>\n",
       "      <td>0.03</td>\n",
       "      <td>29.89</td>\n",
       "      <td>22774</td>\n",
       "      <td>2017-08-25 16:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2017-08-25 16:55:00</td>\n",
       "      <td>22775</td>\n",
       "      <td>5.57</td>\n",
       "      <td>133.794</td>\n",
       "      <td>21.781</td>\n",
       "      <td>-3.352</td>\n",
       "      <td>2.652</td>\n",
       "      <td>-2.545</td>\n",
       "      <td>0.08</td>\n",
       "      <td>7.84</td>\n",
       "      <td>22780</td>\n",
       "      <td>2017-08-25 17:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>2017-08-25 17:25:00</td>\n",
       "      <td>22781</td>\n",
       "      <td>5.62</td>\n",
       "      <td>128.043</td>\n",
       "      <td>22.010</td>\n",
       "      <td>-3.207</td>\n",
       "      <td>2.863</td>\n",
       "      <td>-2.233</td>\n",
       "      <td>0.02</td>\n",
       "      <td>14.03</td>\n",
       "      <td>22786</td>\n",
       "      <td>2017-08-25 17:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2017-08-25 19:10:00</td>\n",
       "      <td>22802</td>\n",
       "      <td>5.72</td>\n",
       "      <td>111.535</td>\n",
       "      <td>22.739</td>\n",
       "      <td>-2.855</td>\n",
       "      <td>3.092</td>\n",
       "      <td>-1.193</td>\n",
       "      <td>0.07</td>\n",
       "      <td>20.38</td>\n",
       "      <td>22807</td>\n",
       "      <td>2017-08-25 19:35:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2017-06-01 00:00:00          0      5.12     66.934    22.907   \n",
       "1    2017-06-01 00:30:00          6      5.42     62.966    22.718   \n",
       "2    2017-06-01 01:00:00         12      5.35     69.270    22.521   \n",
       "3    2017-06-01 01:30:00         18      5.22     66.155    22.314   \n",
       "4    2017-06-01 02:00:00         24      5.28     61.896    22.099   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "238  2017-08-25 15:20:00      22756      5.37     91.360    20.993   \n",
       "239  2017-08-25 16:25:00      22769      5.48    120.968    21.543   \n",
       "240  2017-08-25 16:55:00      22775      5.57    133.794    21.781   \n",
       "241  2017-08-25 17:25:00      22781      5.62    128.043    22.010   \n",
       "242  2017-08-25 19:10:00      22802      5.72    111.535    22.739   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0        -2.442       6.127       2.598     0.07   15.50        5   \n",
       "1        -1.187       6.173       3.150     0.03    6.66       11   \n",
       "2        -1.030       6.558       2.468     0.01   10.92       17   \n",
       "3        -1.557       6.302       2.783     0.01    6.43       23   \n",
       "4        -3.812       5.147       2.735     0.05    5.93       29   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "238      -2.992       5.058      -0.135     0.05   11.95    22761   \n",
       "239      -2.938       3.703      -2.227     0.03   29.89    22774   \n",
       "240      -3.352       2.652      -2.545     0.08    7.84    22780   \n",
       "241      -3.207       2.863      -2.233     0.02   14.03    22786   \n",
       "242      -2.855       3.092      -1.193     0.07   20.38    22807   \n",
       "\n",
       "                 End_str  \n",
       "0    2017-06-01 00:25:00  \n",
       "1    2017-06-01 00:55:00  \n",
       "2    2017-06-01 01:25:00  \n",
       "3    2017-06-01 01:55:00  \n",
       "4    2017-06-01 02:25:00  \n",
       "..                   ...  \n",
       "238  2017-08-25 15:45:00  \n",
       "239  2017-08-25 16:50:00  \n",
       "240  2017-08-25 17:20:00  \n",
       "241  2017-08-25 17:50:00  \n",
       "242  2017-08-25 19:35:00  \n",
       "\n",
       "[243 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-08 21:10:00</td>\n",
       "      <td>2169</td>\n",
       "      <td>6.90</td>\n",
       "      <td>83.417</td>\n",
       "      <td>23.012</td>\n",
       "      <td>-2.085</td>\n",
       "      <td>2.532</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8.26</td>\n",
       "      <td>2174</td>\n",
       "      <td>2018-06-08 21:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-08 22:25:00</td>\n",
       "      <td>2184</td>\n",
       "      <td>6.43</td>\n",
       "      <td>93.096</td>\n",
       "      <td>23.449</td>\n",
       "      <td>-0.808</td>\n",
       "      <td>3.412</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6.65</td>\n",
       "      <td>2189</td>\n",
       "      <td>2018-06-08 22:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-08 23:00:00</td>\n",
       "      <td>2191</td>\n",
       "      <td>6.45</td>\n",
       "      <td>94.207</td>\n",
       "      <td>23.636</td>\n",
       "      <td>-0.780</td>\n",
       "      <td>3.268</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>0.09</td>\n",
       "      <td>9.02</td>\n",
       "      <td>2196</td>\n",
       "      <td>2018-06-08 23:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-08 23:45:00</td>\n",
       "      <td>2200</td>\n",
       "      <td>6.62</td>\n",
       "      <td>110.452</td>\n",
       "      <td>23.860</td>\n",
       "      <td>0.328</td>\n",
       "      <td>2.725</td>\n",
       "      <td>-1.018</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10.27</td>\n",
       "      <td>2205</td>\n",
       "      <td>2018-06-09 00:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-06-09 20:00:00</td>\n",
       "      <td>2443</td>\n",
       "      <td>6.60</td>\n",
       "      <td>92.703</td>\n",
       "      <td>23.601</td>\n",
       "      <td>-1.703</td>\n",
       "      <td>2.180</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.10</td>\n",
       "      <td>14.42</td>\n",
       "      <td>2448</td>\n",
       "      <td>2018-06-09 20:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2018-08-27 22:00:00</td>\n",
       "      <td>23281</td>\n",
       "      <td>6.77</td>\n",
       "      <td>58.448</td>\n",
       "      <td>21.745</td>\n",
       "      <td>-3.187</td>\n",
       "      <td>2.435</td>\n",
       "      <td>1.547</td>\n",
       "      <td>0.06</td>\n",
       "      <td>26.42</td>\n",
       "      <td>23286</td>\n",
       "      <td>2018-08-27 22:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2018-08-27 22:30:00</td>\n",
       "      <td>23287</td>\n",
       "      <td>6.70</td>\n",
       "      <td>47.403</td>\n",
       "      <td>21.500</td>\n",
       "      <td>-3.483</td>\n",
       "      <td>2.200</td>\n",
       "      <td>2.020</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15.43</td>\n",
       "      <td>23292</td>\n",
       "      <td>2018-08-27 22:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2018-08-27 23:00:00</td>\n",
       "      <td>23293</td>\n",
       "      <td>6.82</td>\n",
       "      <td>67.745</td>\n",
       "      <td>21.245</td>\n",
       "      <td>-3.095</td>\n",
       "      <td>3.182</td>\n",
       "      <td>1.307</td>\n",
       "      <td>0.05</td>\n",
       "      <td>22.69</td>\n",
       "      <td>23298</td>\n",
       "      <td>2018-08-27 23:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2018-08-28 22:30:00</td>\n",
       "      <td>23575</td>\n",
       "      <td>6.98</td>\n",
       "      <td>59.626</td>\n",
       "      <td>11.967</td>\n",
       "      <td>-3.060</td>\n",
       "      <td>1.618</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.03</td>\n",
       "      <td>26.65</td>\n",
       "      <td>23580</td>\n",
       "      <td>2018-08-28 22:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2018-08-29 03:25:00</td>\n",
       "      <td>23634</td>\n",
       "      <td>6.82</td>\n",
       "      <td>60.407</td>\n",
       "      <td>16.927</td>\n",
       "      <td>-3.340</td>\n",
       "      <td>2.088</td>\n",
       "      <td>1.175</td>\n",
       "      <td>0.09</td>\n",
       "      <td>16.07</td>\n",
       "      <td>23639</td>\n",
       "      <td>2018-08-29 03:50:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2018-06-08 21:10:00       2169      6.90     83.417    23.012   \n",
       "1    2018-06-08 22:25:00       2184      6.43     93.096    23.449   \n",
       "2    2018-06-08 23:00:00       2191      6.45     94.207    23.636   \n",
       "3    2018-06-08 23:45:00       2200      6.62    110.452    23.860   \n",
       "4    2018-06-09 20:00:00       2443      6.60     92.703    23.601   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "220  2018-08-27 22:00:00      23281      6.77     58.448    21.745   \n",
       "221  2018-08-27 22:30:00      23287      6.70     47.403    21.500   \n",
       "222  2018-08-27 23:00:00      23293      6.82     67.745    21.245   \n",
       "223  2018-08-28 22:30:00      23575      6.98     59.626    11.967   \n",
       "224  2018-08-29 03:25:00      23634      6.82     60.407    16.927   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0        -2.085       2.532       0.287     0.05    8.26     2174   \n",
       "1        -0.808       3.412      -0.190     0.06    6.65     2189   \n",
       "2        -0.780       3.268      -0.245     0.09    9.02     2196   \n",
       "3         0.328       2.725      -1.018     0.09   10.27     2205   \n",
       "4        -1.703       2.180      -0.102     0.10   14.42     2448   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "220      -3.187       2.435       1.547     0.06   26.42    23286   \n",
       "221      -3.483       2.200       2.020     0.03   15.43    23292   \n",
       "222      -3.095       3.182       1.307     0.05   22.69    23298   \n",
       "223      -3.060       1.618       0.882     0.03   26.65    23580   \n",
       "224      -3.340       2.088       1.175     0.09   16.07    23639   \n",
       "\n",
       "                 End_str  \n",
       "0    2018-06-08 21:35:00  \n",
       "1    2018-06-08 22:50:00  \n",
       "2    2018-06-08 23:25:00  \n",
       "3    2018-06-09 00:10:00  \n",
       "4    2018-06-09 20:25:00  \n",
       "..                   ...  \n",
       "220  2018-08-27 22:25:00  \n",
       "221  2018-08-27 22:55:00  \n",
       "222  2018-08-27 23:25:00  \n",
       "223  2018-08-28 22:55:00  \n",
       "224  2018-08-29 03:50:00  \n",
       "\n",
       "[225 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-04 11:30:00</td>\n",
       "      <td>709</td>\n",
       "      <td>5.18</td>\n",
       "      <td>64.111</td>\n",
       "      <td>7.109</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>5.370</td>\n",
       "      <td>2.610</td>\n",
       "      <td>0.05</td>\n",
       "      <td>11.35</td>\n",
       "      <td>714</td>\n",
       "      <td>2019-06-04 11:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-04 12:00:00</td>\n",
       "      <td>715</td>\n",
       "      <td>5.05</td>\n",
       "      <td>64.677</td>\n",
       "      <td>7.975</td>\n",
       "      <td>-1.792</td>\n",
       "      <td>5.190</td>\n",
       "      <td>2.442</td>\n",
       "      <td>0.08</td>\n",
       "      <td>10.44</td>\n",
       "      <td>720</td>\n",
       "      <td>2019-06-04 12:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-04 13:20:00</td>\n",
       "      <td>731</td>\n",
       "      <td>5.10</td>\n",
       "      <td>54.952</td>\n",
       "      <td>10.053</td>\n",
       "      <td>-1.447</td>\n",
       "      <td>5.408</td>\n",
       "      <td>3.782</td>\n",
       "      <td>0.06</td>\n",
       "      <td>12.14</td>\n",
       "      <td>736</td>\n",
       "      <td>2019-06-04 13:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-14 03:55:00</td>\n",
       "      <td>3271</td>\n",
       "      <td>5.98</td>\n",
       "      <td>93.926</td>\n",
       "      <td>21.829</td>\n",
       "      <td>-1.438</td>\n",
       "      <td>6.265</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>0.05</td>\n",
       "      <td>28.39</td>\n",
       "      <td>3276</td>\n",
       "      <td>2019-06-14 04:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-14 05:45:00</td>\n",
       "      <td>3293</td>\n",
       "      <td>6.00</td>\n",
       "      <td>111.608</td>\n",
       "      <td>20.598</td>\n",
       "      <td>-2.918</td>\n",
       "      <td>4.402</td>\n",
       "      <td>-1.672</td>\n",
       "      <td>0.08</td>\n",
       "      <td>22.35</td>\n",
       "      <td>3298</td>\n",
       "      <td>2019-06-14 06:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2019-08-17 05:50:00</td>\n",
       "      <td>19874</td>\n",
       "      <td>6.50</td>\n",
       "      <td>103.752</td>\n",
       "      <td>13.158</td>\n",
       "      <td>-3.107</td>\n",
       "      <td>2.010</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>0.04</td>\n",
       "      <td>21.24</td>\n",
       "      <td>19879</td>\n",
       "      <td>2019-08-17 06:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2019-08-17 09:25:00</td>\n",
       "      <td>19917</td>\n",
       "      <td>6.17</td>\n",
       "      <td>108.830</td>\n",
       "      <td>16.906</td>\n",
       "      <td>-2.567</td>\n",
       "      <td>2.342</td>\n",
       "      <td>-0.822</td>\n",
       "      <td>0.08</td>\n",
       "      <td>17.96</td>\n",
       "      <td>19922</td>\n",
       "      <td>2019-08-17 09:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2019-08-17 09:55:00</td>\n",
       "      <td>19923</td>\n",
       "      <td>6.05</td>\n",
       "      <td>114.956</td>\n",
       "      <td>17.362</td>\n",
       "      <td>-2.505</td>\n",
       "      <td>2.470</td>\n",
       "      <td>-1.160</td>\n",
       "      <td>0.06</td>\n",
       "      <td>18.88</td>\n",
       "      <td>19928</td>\n",
       "      <td>2019-08-17 10:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2019-08-17 10:25:00</td>\n",
       "      <td>19929</td>\n",
       "      <td>6.00</td>\n",
       "      <td>120.754</td>\n",
       "      <td>17.805</td>\n",
       "      <td>-1.595</td>\n",
       "      <td>2.755</td>\n",
       "      <td>-1.588</td>\n",
       "      <td>0.03</td>\n",
       "      <td>26.89</td>\n",
       "      <td>19934</td>\n",
       "      <td>2019-08-17 10:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2019-08-24 11:25:00</td>\n",
       "      <td>21710</td>\n",
       "      <td>6.60</td>\n",
       "      <td>60.394</td>\n",
       "      <td>18.574</td>\n",
       "      <td>-1.342</td>\n",
       "      <td>1.617</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.03</td>\n",
       "      <td>26.82</td>\n",
       "      <td>21715</td>\n",
       "      <td>2019-08-24 11:50:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2019-06-04 11:30:00        709      5.18     64.111     7.109   \n",
       "1    2019-06-04 12:00:00        715      5.05     64.677     7.975   \n",
       "2    2019-06-04 13:20:00        731      5.10     54.952    10.053   \n",
       "3    2019-06-14 03:55:00       3271      5.98     93.926    21.829   \n",
       "4    2019-06-14 05:45:00       3293      6.00    111.608    20.598   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "142  2019-08-17 05:50:00      19874      6.50    103.752    13.158   \n",
       "143  2019-08-17 09:25:00      19917      6.17    108.830    16.906   \n",
       "144  2019-08-17 09:55:00      19923      6.05    114.956    17.362   \n",
       "145  2019-08-17 10:25:00      19929      6.00    120.754    17.805   \n",
       "146  2019-08-24 11:25:00      21710      6.60     60.394    18.574   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0        -0.982       5.370       2.610     0.05   11.35      714   \n",
       "1        -1.792       5.190       2.442     0.08   10.44      720   \n",
       "2        -1.447       5.408       3.782     0.06   12.14      736   \n",
       "3        -1.438       6.265      -0.427     0.05   28.39     3276   \n",
       "4        -2.918       4.402      -1.672     0.08   22.35     3298   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "142      -3.107       2.010      -0.503     0.04   21.24    19879   \n",
       "143      -2.567       2.342      -0.822     0.08   17.96    19922   \n",
       "144      -2.505       2.470      -1.160     0.06   18.88    19928   \n",
       "145      -1.595       2.755      -1.588     0.03   26.89    19934   \n",
       "146      -1.342       1.617       0.880     0.03   26.82    21715   \n",
       "\n",
       "                 End_str  \n",
       "0    2019-06-04 11:55:00  \n",
       "1    2019-06-04 12:25:00  \n",
       "2    2019-06-04 13:45:00  \n",
       "3    2019-06-14 04:20:00  \n",
       "4    2019-06-14 06:10:00  \n",
       "..                   ...  \n",
       "142  2019-08-17 06:15:00  \n",
       "143  2019-08-17 09:50:00  \n",
       "144  2019-08-17 10:20:00  \n",
       "145  2019-08-17 10:50:00  \n",
       "146  2019-08-24 11:50:00  \n",
       "\n",
       "[147 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-05 19:25:00</td>\n",
       "      <td>1326</td>\n",
       "      <td>6.08</td>\n",
       "      <td>119.749</td>\n",
       "      <td>12.802</td>\n",
       "      <td>-1.212</td>\n",
       "      <td>2.685</td>\n",
       "      <td>-1.532</td>\n",
       "      <td>0.05</td>\n",
       "      <td>11.70</td>\n",
       "      <td>1331</td>\n",
       "      <td>2020-06-05 19:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-08 23:35:00</td>\n",
       "      <td>2150</td>\n",
       "      <td>5.78</td>\n",
       "      <td>71.110</td>\n",
       "      <td>19.801</td>\n",
       "      <td>-3.327</td>\n",
       "      <td>1.785</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.07</td>\n",
       "      <td>27.85</td>\n",
       "      <td>2155</td>\n",
       "      <td>2020-06-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-09 00:05:00</td>\n",
       "      <td>2156</td>\n",
       "      <td>6.15</td>\n",
       "      <td>59.874</td>\n",
       "      <td>19.439</td>\n",
       "      <td>-2.257</td>\n",
       "      <td>2.333</td>\n",
       "      <td>1.372</td>\n",
       "      <td>0.08</td>\n",
       "      <td>7.36</td>\n",
       "      <td>2161</td>\n",
       "      <td>2020-06-09 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-09 02:45:00</td>\n",
       "      <td>2188</td>\n",
       "      <td>6.65</td>\n",
       "      <td>49.587</td>\n",
       "      <td>17.320</td>\n",
       "      <td>-2.203</td>\n",
       "      <td>1.243</td>\n",
       "      <td>1.060</td>\n",
       "      <td>0.10</td>\n",
       "      <td>11.58</td>\n",
       "      <td>2193</td>\n",
       "      <td>2020-06-09 03:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-09 05:35:00</td>\n",
       "      <td>2222</td>\n",
       "      <td>6.97</td>\n",
       "      <td>67.212</td>\n",
       "      <td>14.660</td>\n",
       "      <td>0.068</td>\n",
       "      <td>2.558</td>\n",
       "      <td>1.075</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5.03</td>\n",
       "      <td>2227</td>\n",
       "      <td>2020-06-09 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>2020-08-28 20:10:00</td>\n",
       "      <td>24643</td>\n",
       "      <td>5.25</td>\n",
       "      <td>63.758</td>\n",
       "      <td>7.143</td>\n",
       "      <td>-2.552</td>\n",
       "      <td>6.062</td>\n",
       "      <td>3.058</td>\n",
       "      <td>0.08</td>\n",
       "      <td>21.52</td>\n",
       "      <td>24648</td>\n",
       "      <td>2020-08-28 20:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>2020-08-29 02:10:00</td>\n",
       "      <td>24715</td>\n",
       "      <td>5.25</td>\n",
       "      <td>112.123</td>\n",
       "      <td>7.014</td>\n",
       "      <td>-3.565</td>\n",
       "      <td>3.977</td>\n",
       "      <td>-1.620</td>\n",
       "      <td>0.06</td>\n",
       "      <td>23.78</td>\n",
       "      <td>24720</td>\n",
       "      <td>2020-08-29 02:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>2020-08-29 02:40:00</td>\n",
       "      <td>24721</td>\n",
       "      <td>5.13</td>\n",
       "      <td>128.283</td>\n",
       "      <td>7.827</td>\n",
       "      <td>-4.385</td>\n",
       "      <td>2.788</td>\n",
       "      <td>-2.140</td>\n",
       "      <td>0.01</td>\n",
       "      <td>26.88</td>\n",
       "      <td>24726</td>\n",
       "      <td>2020-08-29 03:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>2020-08-29 16:30:00</td>\n",
       "      <td>24887</td>\n",
       "      <td>5.53</td>\n",
       "      <td>96.626</td>\n",
       "      <td>21.407</td>\n",
       "      <td>-3.847</td>\n",
       "      <td>2.850</td>\n",
       "      <td>-0.515</td>\n",
       "      <td>0.02</td>\n",
       "      <td>29.37</td>\n",
       "      <td>24892</td>\n",
       "      <td>2020-08-29 16:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>2020-08-29 17:35:00</td>\n",
       "      <td>24900</td>\n",
       "      <td>6.25</td>\n",
       "      <td>134.169</td>\n",
       "      <td>22.059</td>\n",
       "      <td>-2.927</td>\n",
       "      <td>1.903</td>\n",
       "      <td>-1.798</td>\n",
       "      <td>0.09</td>\n",
       "      <td>17.62</td>\n",
       "      <td>24905</td>\n",
       "      <td>2020-08-29 18:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2020-06-05 19:25:00       1326      6.08    119.749    12.802   \n",
       "1    2020-06-08 23:35:00       2150      5.78     71.110    19.801   \n",
       "2    2020-06-09 00:05:00       2156      6.15     59.874    19.439   \n",
       "3    2020-06-09 02:45:00       2188      6.65     49.587    17.320   \n",
       "4    2020-06-09 05:35:00       2222      6.97     67.212    14.660   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "286  2020-08-28 20:10:00      24643      5.25     63.758     7.143   \n",
       "287  2020-08-29 02:10:00      24715      5.25    112.123     7.014   \n",
       "288  2020-08-29 02:40:00      24721      5.13    128.283     7.827   \n",
       "289  2020-08-29 16:30:00      24887      5.53     96.626    21.407   \n",
       "290  2020-08-29 17:35:00      24900      6.25    134.169    22.059   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0        -1.212       2.685      -1.532     0.05   11.70     1331   \n",
       "1        -3.327       1.785       0.670     0.07   27.85     2155   \n",
       "2        -2.257       2.333       1.372     0.08    7.36     2161   \n",
       "3        -2.203       1.243       1.060     0.10   11.58     2193   \n",
       "4         0.068       2.558       1.075     0.03    5.03     2227   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "286      -2.552       6.062       3.058     0.08   21.52    24648   \n",
       "287      -3.565       3.977      -1.620     0.06   23.78    24720   \n",
       "288      -4.385       2.788      -2.140     0.01   26.88    24726   \n",
       "289      -3.847       2.850      -0.515     0.02   29.37    24892   \n",
       "290      -2.927       1.903      -1.798     0.09   17.62    24905   \n",
       "\n",
       "                 End_str  \n",
       "0    2020-06-05 19:50:00  \n",
       "1    2020-06-09 00:00:00  \n",
       "2    2020-06-09 00:30:00  \n",
       "3    2020-06-09 03:10:00  \n",
       "4    2020-06-09 06:00:00  \n",
       "..                   ...  \n",
       "286  2020-08-28 20:35:00  \n",
       "287  2020-08-29 02:35:00  \n",
       "288  2020-08-29 03:05:00  \n",
       "289  2020-08-29 16:55:00  \n",
       "290  2020-08-29 18:00:00  \n",
       "\n",
       "[291 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-04 11:25:00</td>\n",
       "      <td>1001</td>\n",
       "      <td>5.03</td>\n",
       "      <td>91.297</td>\n",
       "      <td>22.256</td>\n",
       "      <td>-4.165</td>\n",
       "      <td>3.523</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12.32</td>\n",
       "      <td>1006</td>\n",
       "      <td>2021-06-04 11:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-04 19:35:00</td>\n",
       "      <td>1099</td>\n",
       "      <td>6.48</td>\n",
       "      <td>101.981</td>\n",
       "      <td>16.499</td>\n",
       "      <td>-0.938</td>\n",
       "      <td>3.143</td>\n",
       "      <td>-0.667</td>\n",
       "      <td>0.07</td>\n",
       "      <td>9.15</td>\n",
       "      <td>1104</td>\n",
       "      <td>2021-06-04 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-04 20:05:00</td>\n",
       "      <td>1105</td>\n",
       "      <td>6.20</td>\n",
       "      <td>99.390</td>\n",
       "      <td>16.050</td>\n",
       "      <td>-1.967</td>\n",
       "      <td>2.925</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>0.09</td>\n",
       "      <td>5.21</td>\n",
       "      <td>1110</td>\n",
       "      <td>2021-06-04 20:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-04 21:20:00</td>\n",
       "      <td>1120</td>\n",
       "      <td>5.92</td>\n",
       "      <td>99.945</td>\n",
       "      <td>14.866</td>\n",
       "      <td>-2.072</td>\n",
       "      <td>2.530</td>\n",
       "      <td>-0.443</td>\n",
       "      <td>0.08</td>\n",
       "      <td>12.38</td>\n",
       "      <td>1125</td>\n",
       "      <td>2021-06-04 21:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-04 21:50:00</td>\n",
       "      <td>1126</td>\n",
       "      <td>6.00</td>\n",
       "      <td>105.006</td>\n",
       "      <td>14.365</td>\n",
       "      <td>-2.350</td>\n",
       "      <td>2.200</td>\n",
       "      <td>-0.585</td>\n",
       "      <td>0.04</td>\n",
       "      <td>12.43</td>\n",
       "      <td>1131</td>\n",
       "      <td>2021-06-04 22:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2021-08-25 18:20:00</td>\n",
       "      <td>22912</td>\n",
       "      <td>5.50</td>\n",
       "      <td>78.062</td>\n",
       "      <td>22.901</td>\n",
       "      <td>-3.747</td>\n",
       "      <td>2.485</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7.56</td>\n",
       "      <td>22917</td>\n",
       "      <td>2021-08-25 18:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2021-08-28 13:15:00</td>\n",
       "      <td>23713</td>\n",
       "      <td>5.22</td>\n",
       "      <td>112.512</td>\n",
       "      <td>7.022</td>\n",
       "      <td>-1.648</td>\n",
       "      <td>7.038</td>\n",
       "      <td>-2.913</td>\n",
       "      <td>0.02</td>\n",
       "      <td>15.48</td>\n",
       "      <td>23718</td>\n",
       "      <td>2021-08-28 13:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2021-08-28 13:45:00</td>\n",
       "      <td>23719</td>\n",
       "      <td>5.33</td>\n",
       "      <td>98.548</td>\n",
       "      <td>7.815</td>\n",
       "      <td>-1.555</td>\n",
       "      <td>7.318</td>\n",
       "      <td>-1.103</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5.71</td>\n",
       "      <td>23724</td>\n",
       "      <td>2021-08-28 14:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2021-08-28 14:15:00</td>\n",
       "      <td>23725</td>\n",
       "      <td>5.63</td>\n",
       "      <td>95.961</td>\n",
       "      <td>8.572</td>\n",
       "      <td>-1.477</td>\n",
       "      <td>7.087</td>\n",
       "      <td>-0.740</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.91</td>\n",
       "      <td>23730</td>\n",
       "      <td>2021-08-28 14:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2021-08-28 14:45:00</td>\n",
       "      <td>23731</td>\n",
       "      <td>5.28</td>\n",
       "      <td>88.390</td>\n",
       "      <td>9.295</td>\n",
       "      <td>-1.380</td>\n",
       "      <td>6.535</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.08</td>\n",
       "      <td>23.75</td>\n",
       "      <td>23736</td>\n",
       "      <td>2021-08-28 15:10:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2021-06-04 11:25:00       1001      5.03     91.297    22.256   \n",
       "1    2021-06-04 19:35:00       1099      6.48    101.981    16.499   \n",
       "2    2021-06-04 20:05:00       1105      6.20     99.390    16.050   \n",
       "3    2021-06-04 21:20:00       1120      5.92     99.945    14.866   \n",
       "4    2021-06-04 21:50:00       1126      6.00    105.006    14.365   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "173  2021-08-25 18:20:00      22912      5.50     78.062    22.901   \n",
       "174  2021-08-28 13:15:00      23713      5.22    112.512     7.022   \n",
       "175  2021-08-28 13:45:00      23719      5.33     98.548     7.815   \n",
       "176  2021-08-28 14:15:00      23725      5.63     95.961     8.572   \n",
       "177  2021-08-28 14:45:00      23731      5.28     88.390     9.295   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0        -4.165       3.523      -0.088     0.05   12.32     1006   \n",
       "1        -0.938       3.143      -0.667     0.07    9.15     1104   \n",
       "2        -1.967       2.925      -0.485     0.09    5.21     1110   \n",
       "3        -2.072       2.530      -0.443     0.08   12.38     1125   \n",
       "4        -2.350       2.200      -0.585     0.04   12.43     1131   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "173      -3.747       2.485       0.533     0.03    7.56    22917   \n",
       "174      -1.648       7.038      -2.913     0.02   15.48    23718   \n",
       "175      -1.555       7.318      -1.103     0.04    5.71    23724   \n",
       "176      -1.477       7.087      -0.740     0.05    1.91    23730   \n",
       "177      -1.380       6.535       0.192     0.08   23.75    23736   \n",
       "\n",
       "                 End_str  \n",
       "0    2021-06-04 11:50:00  \n",
       "1    2021-06-04 20:00:00  \n",
       "2    2021-06-04 20:30:00  \n",
       "3    2021-06-04 21:45:00  \n",
       "4    2021-06-04 22:15:00  \n",
       "..                   ...  \n",
       "173  2021-08-25 18:45:00  \n",
       "174  2021-08-28 13:40:00  \n",
       "175  2021-08-28 14:10:00  \n",
       "176  2021-08-28 14:40:00  \n",
       "177  2021-08-28 15:10:00  \n",
       "\n",
       "[178 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying Nightside(Jun-Aug)Yr 1-7 negBy Stable Lists\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-06-01 23:20:00</td>\n",
       "      <td>268</td>\n",
       "      <td>5.32</td>\n",
       "      <td>274.914</td>\n",
       "      <td>11.234</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-5.033</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.06</td>\n",
       "      <td>27.10</td>\n",
       "      <td>273</td>\n",
       "      <td>2015-06-01 23:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-04 01:15:00</td>\n",
       "      <td>844</td>\n",
       "      <td>5.05</td>\n",
       "      <td>306.590</td>\n",
       "      <td>11.880</td>\n",
       "      <td>-3.323</td>\n",
       "      <td>-1.833</td>\n",
       "      <td>1.352</td>\n",
       "      <td>0.01</td>\n",
       "      <td>19.58</td>\n",
       "      <td>849</td>\n",
       "      <td>2015-06-04 01:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-06-08 17:45:00</td>\n",
       "      <td>2172</td>\n",
       "      <td>6.30</td>\n",
       "      <td>234.522</td>\n",
       "      <td>7.376</td>\n",
       "      <td>3.328</td>\n",
       "      <td>-4.262</td>\n",
       "      <td>-3.047</td>\n",
       "      <td>0.06</td>\n",
       "      <td>27.46</td>\n",
       "      <td>2177</td>\n",
       "      <td>2015-06-08 18:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-08 21:20:00</td>\n",
       "      <td>2215</td>\n",
       "      <td>6.40</td>\n",
       "      <td>251.061</td>\n",
       "      <td>10.591</td>\n",
       "      <td>2.560</td>\n",
       "      <td>-5.203</td>\n",
       "      <td>-1.783</td>\n",
       "      <td>0.07</td>\n",
       "      <td>8.62</td>\n",
       "      <td>2220</td>\n",
       "      <td>2015-06-08 21:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-06-09 04:00:00</td>\n",
       "      <td>2295</td>\n",
       "      <td>6.90</td>\n",
       "      <td>261.563</td>\n",
       "      <td>11.840</td>\n",
       "      <td>2.985</td>\n",
       "      <td>-3.827</td>\n",
       "      <td>-0.598</td>\n",
       "      <td>0.03</td>\n",
       "      <td>23.90</td>\n",
       "      <td>2300</td>\n",
       "      <td>2015-06-09 04:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2015-08-30 18:55:00</td>\n",
       "      <td>23592</td>\n",
       "      <td>5.58</td>\n",
       "      <td>286.640</td>\n",
       "      <td>11.758</td>\n",
       "      <td>2.807</td>\n",
       "      <td>-3.322</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.05</td>\n",
       "      <td>22.34</td>\n",
       "      <td>23597</td>\n",
       "      <td>2015-08-30 19:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2015-08-30 20:10:00</td>\n",
       "      <td>23607</td>\n",
       "      <td>5.42</td>\n",
       "      <td>250.543</td>\n",
       "      <td>11.380</td>\n",
       "      <td>4.403</td>\n",
       "      <td>-3.178</td>\n",
       "      <td>-1.112</td>\n",
       "      <td>0.05</td>\n",
       "      <td>21.45</td>\n",
       "      <td>23612</td>\n",
       "      <td>2015-08-30 20:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2015-08-30 20:40:00</td>\n",
       "      <td>23613</td>\n",
       "      <td>5.10</td>\n",
       "      <td>275.666</td>\n",
       "      <td>11.175</td>\n",
       "      <td>4.908</td>\n",
       "      <td>-2.790</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9.66</td>\n",
       "      <td>23618</td>\n",
       "      <td>2015-08-30 21:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2015-08-30 21:35:00</td>\n",
       "      <td>23624</td>\n",
       "      <td>5.88</td>\n",
       "      <td>282.491</td>\n",
       "      <td>10.715</td>\n",
       "      <td>-2.167</td>\n",
       "      <td>-4.065</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.03</td>\n",
       "      <td>20.67</td>\n",
       "      <td>23629</td>\n",
       "      <td>2015-08-30 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2015-08-30 23:05:00</td>\n",
       "      <td>23642</td>\n",
       "      <td>5.32</td>\n",
       "      <td>263.855</td>\n",
       "      <td>9.708</td>\n",
       "      <td>1.980</td>\n",
       "      <td>-5.277</td>\n",
       "      <td>-0.587</td>\n",
       "      <td>0.04</td>\n",
       "      <td>20.25</td>\n",
       "      <td>23647</td>\n",
       "      <td>2015-08-30 23:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2015-06-01 23:20:00        268      5.32    274.914    11.234   \n",
       "1    2015-06-04 01:15:00        844      5.05    306.590    11.880   \n",
       "2    2015-06-08 17:45:00       2172      6.30    234.522     7.376   \n",
       "3    2015-06-08 21:20:00       2215      6.40    251.061    10.591   \n",
       "4    2015-06-09 04:00:00       2295      6.90    261.563    11.840   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "185  2015-08-30 18:55:00      23592      5.58    286.640    11.758   \n",
       "186  2015-08-30 20:10:00      23607      5.42    250.543    11.380   \n",
       "187  2015-08-30 20:40:00      23613      5.10    275.666    11.175   \n",
       "188  2015-08-30 21:35:00      23624      5.88    282.491    10.715   \n",
       "189  2015-08-30 23:05:00      23642      5.32    263.855     9.708   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0        -0.290      -5.033       0.433     0.06   27.10      273   \n",
       "1        -3.323      -1.833       1.352     0.01   19.58      849   \n",
       "2         3.328      -4.262      -3.047     0.06   27.46     2177   \n",
       "3         2.560      -5.203      -1.783     0.07    8.62     2220   \n",
       "4         2.985      -3.827      -0.598     0.03   23.90     2300   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "185       2.807      -3.322       0.922     0.05   22.34    23597   \n",
       "186       4.403      -3.178      -1.112     0.05   21.45    23612   \n",
       "187       4.908      -2.790       0.280     0.05    9.66    23618   \n",
       "188      -2.167      -4.065       0.875     0.03   20.67    23629   \n",
       "189       1.980      -5.277      -0.587     0.04   20.25    23647   \n",
       "\n",
       "                 End_str  \n",
       "0    2015-06-01 23:45:00  \n",
       "1    2015-06-04 01:40:00  \n",
       "2    2015-06-08 18:10:00  \n",
       "3    2015-06-08 21:45:00  \n",
       "4    2015-06-09 04:25:00  \n",
       "..                   ...  \n",
       "185  2015-08-30 19:20:00  \n",
       "186  2015-08-30 20:35:00  \n",
       "187  2015-08-30 21:05:00  \n",
       "188  2015-08-30 22:00:00  \n",
       "189  2015-08-30 23:30:00  \n",
       "\n",
       "[190 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-06-01 00:35:00</td>\n",
       "      <td>7</td>\n",
       "      <td>6.47</td>\n",
       "      <td>278.914</td>\n",
       "      <td>7.003</td>\n",
       "      <td>-2.200</td>\n",
       "      <td>-4.128</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.06</td>\n",
       "      <td>22.00</td>\n",
       "      <td>12</td>\n",
       "      <td>2016-06-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-06-01 01:05:00</td>\n",
       "      <td>13</td>\n",
       "      <td>6.65</td>\n",
       "      <td>272.391</td>\n",
       "      <td>7.639</td>\n",
       "      <td>-2.148</td>\n",
       "      <td>-3.757</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.06</td>\n",
       "      <td>15.14</td>\n",
       "      <td>18</td>\n",
       "      <td>2016-06-01 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-06-01 01:35:00</td>\n",
       "      <td>19</td>\n",
       "      <td>6.73</td>\n",
       "      <td>256.390</td>\n",
       "      <td>8.213</td>\n",
       "      <td>-2.127</td>\n",
       "      <td>-3.663</td>\n",
       "      <td>-0.890</td>\n",
       "      <td>0.07</td>\n",
       "      <td>24.60</td>\n",
       "      <td>24</td>\n",
       "      <td>2016-06-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-06-01 03:20:00</td>\n",
       "      <td>40</td>\n",
       "      <td>6.68</td>\n",
       "      <td>239.010</td>\n",
       "      <td>9.826</td>\n",
       "      <td>-1.472</td>\n",
       "      <td>-3.192</td>\n",
       "      <td>-1.887</td>\n",
       "      <td>0.05</td>\n",
       "      <td>22.03</td>\n",
       "      <td>45</td>\n",
       "      <td>2016-06-01 03:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-06-01 04:15:00</td>\n",
       "      <td>51</td>\n",
       "      <td>6.77</td>\n",
       "      <td>260.723</td>\n",
       "      <td>10.465</td>\n",
       "      <td>0.900</td>\n",
       "      <td>-3.362</td>\n",
       "      <td>-0.585</td>\n",
       "      <td>0.07</td>\n",
       "      <td>25.20</td>\n",
       "      <td>56</td>\n",
       "      <td>2016-06-01 04:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2016-08-28 05:30:00</td>\n",
       "      <td>22522</td>\n",
       "      <td>5.65</td>\n",
       "      <td>279.358</td>\n",
       "      <td>9.670</td>\n",
       "      <td>3.795</td>\n",
       "      <td>-2.545</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8.43</td>\n",
       "      <td>22527</td>\n",
       "      <td>2016-08-28 05:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2016-08-28 06:25:00</td>\n",
       "      <td>22533</td>\n",
       "      <td>5.90</td>\n",
       "      <td>265.505</td>\n",
       "      <td>8.869</td>\n",
       "      <td>3.635</td>\n",
       "      <td>-1.848</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>0.03</td>\n",
       "      <td>29.86</td>\n",
       "      <td>22538</td>\n",
       "      <td>2016-08-28 06:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>2016-08-28 06:55:00</td>\n",
       "      <td>22539</td>\n",
       "      <td>5.80</td>\n",
       "      <td>268.191</td>\n",
       "      <td>8.367</td>\n",
       "      <td>3.687</td>\n",
       "      <td>-1.917</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.01</td>\n",
       "      <td>29.16</td>\n",
       "      <td>22544</td>\n",
       "      <td>2016-08-28 07:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>2016-08-28 07:25:00</td>\n",
       "      <td>22545</td>\n",
       "      <td>5.80</td>\n",
       "      <td>244.416</td>\n",
       "      <td>7.812</td>\n",
       "      <td>3.845</td>\n",
       "      <td>-1.405</td>\n",
       "      <td>-0.667</td>\n",
       "      <td>0.01</td>\n",
       "      <td>16.61</td>\n",
       "      <td>22550</td>\n",
       "      <td>2016-08-28 07:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2016-08-29 15:35:00</td>\n",
       "      <td>22859</td>\n",
       "      <td>5.87</td>\n",
       "      <td>231.969</td>\n",
       "      <td>8.520</td>\n",
       "      <td>-4.307</td>\n",
       "      <td>-1.510</td>\n",
       "      <td>-1.190</td>\n",
       "      <td>0.08</td>\n",
       "      <td>12.44</td>\n",
       "      <td>22864</td>\n",
       "      <td>2016-08-29 16:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2016-06-01 00:35:00          7      6.47    278.914     7.003   \n",
       "1    2016-06-01 01:05:00         13      6.65    272.391     7.639   \n",
       "2    2016-06-01 01:35:00         19      6.73    256.390     8.213   \n",
       "3    2016-06-01 03:20:00         40      6.68    239.010     9.826   \n",
       "4    2016-06-01 04:15:00         51      6.77    260.723    10.465   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "308  2016-08-28 05:30:00      22522      5.65    279.358     9.670   \n",
       "309  2016-08-28 06:25:00      22533      5.90    265.505     8.869   \n",
       "310  2016-08-28 06:55:00      22539      5.80    268.191     8.367   \n",
       "311  2016-08-28 07:25:00      22545      5.80    244.416     7.812   \n",
       "312  2016-08-29 15:35:00      22859      5.87    231.969     8.520   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0        -2.200      -4.128       0.643     0.06   22.00       12   \n",
       "1        -2.148      -3.757       0.173     0.06   15.14       18   \n",
       "2        -2.127      -3.663      -0.890     0.07   24.60       24   \n",
       "3        -1.472      -3.192      -1.887     0.05   22.03       45   \n",
       "4         0.900      -3.362      -0.585     0.07   25.20       56   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "308       3.795      -2.545       0.420     0.03    8.43    22527   \n",
       "309       3.635      -1.848      -0.127     0.03   29.86    22538   \n",
       "310       3.687      -1.917      -0.047     0.01   29.16    22544   \n",
       "311       3.845      -1.405      -0.667     0.01   16.61    22550   \n",
       "312      -4.307      -1.510      -1.190     0.08   12.44    22864   \n",
       "\n",
       "                 End_str  \n",
       "0    2016-06-01 01:00:00  \n",
       "1    2016-06-01 01:30:00  \n",
       "2    2016-06-01 02:00:00  \n",
       "3    2016-06-01 03:45:00  \n",
       "4    2016-06-01 04:40:00  \n",
       "..                   ...  \n",
       "308  2016-08-28 05:55:00  \n",
       "309  2016-08-28 06:50:00  \n",
       "310  2016-08-28 07:20:00  \n",
       "311  2016-08-28 07:50:00  \n",
       "312  2016-08-29 16:00:00  \n",
       "\n",
       "[313 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-01 09:50:00</td>\n",
       "      <td>118</td>\n",
       "      <td>6.20</td>\n",
       "      <td>293.056</td>\n",
       "      <td>17.389</td>\n",
       "      <td>0.595</td>\n",
       "      <td>-4.195</td>\n",
       "      <td>1.770</td>\n",
       "      <td>0.06</td>\n",
       "      <td>19.66</td>\n",
       "      <td>123</td>\n",
       "      <td>2017-06-01 10:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-06-02 00:10:00</td>\n",
       "      <td>290</td>\n",
       "      <td>5.97</td>\n",
       "      <td>262.933</td>\n",
       "      <td>7.011</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-4.832</td>\n",
       "      <td>-0.632</td>\n",
       "      <td>0.10</td>\n",
       "      <td>29.20</td>\n",
       "      <td>295</td>\n",
       "      <td>2017-06-02 00:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-06-02 01:35:00</td>\n",
       "      <td>307</td>\n",
       "      <td>6.18</td>\n",
       "      <td>246.847</td>\n",
       "      <td>9.319</td>\n",
       "      <td>1.547</td>\n",
       "      <td>-3.790</td>\n",
       "      <td>-1.605</td>\n",
       "      <td>0.09</td>\n",
       "      <td>24.07</td>\n",
       "      <td>312</td>\n",
       "      <td>2017-06-02 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-06-02 03:20:00</td>\n",
       "      <td>328</td>\n",
       "      <td>6.58</td>\n",
       "      <td>225.236</td>\n",
       "      <td>11.698</td>\n",
       "      <td>3.572</td>\n",
       "      <td>-1.372</td>\n",
       "      <td>-1.312</td>\n",
       "      <td>0.05</td>\n",
       "      <td>22.01</td>\n",
       "      <td>333</td>\n",
       "      <td>2017-06-02 03:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-06-02 03:50:00</td>\n",
       "      <td>334</td>\n",
       "      <td>6.35</td>\n",
       "      <td>235.073</td>\n",
       "      <td>12.306</td>\n",
       "      <td>3.567</td>\n",
       "      <td>-2.147</td>\n",
       "      <td>-1.370</td>\n",
       "      <td>0.09</td>\n",
       "      <td>27.74</td>\n",
       "      <td>339</td>\n",
       "      <td>2017-06-02 04:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2017-08-30 19:45:00</td>\n",
       "      <td>24199</td>\n",
       "      <td>6.00</td>\n",
       "      <td>310.324</td>\n",
       "      <td>13.295</td>\n",
       "      <td>3.990</td>\n",
       "      <td>-1.860</td>\n",
       "      <td>1.555</td>\n",
       "      <td>0.03</td>\n",
       "      <td>23.50</td>\n",
       "      <td>24204</td>\n",
       "      <td>2017-08-30 20:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2017-08-30 20:25:00</td>\n",
       "      <td>24207</td>\n",
       "      <td>6.15</td>\n",
       "      <td>285.092</td>\n",
       "      <td>14.012</td>\n",
       "      <td>3.355</td>\n",
       "      <td>-2.912</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.06</td>\n",
       "      <td>10.45</td>\n",
       "      <td>24212</td>\n",
       "      <td>2017-08-30 20:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2017-08-30 21:25:00</td>\n",
       "      <td>24219</td>\n",
       "      <td>6.40</td>\n",
       "      <td>300.168</td>\n",
       "      <td>15.019</td>\n",
       "      <td>3.497</td>\n",
       "      <td>-1.742</td>\n",
       "      <td>1.002</td>\n",
       "      <td>0.08</td>\n",
       "      <td>14.82</td>\n",
       "      <td>24224</td>\n",
       "      <td>2017-08-30 21:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>2017-08-30 22:10:00</td>\n",
       "      <td>24228</td>\n",
       "      <td>6.55</td>\n",
       "      <td>295.559</td>\n",
       "      <td>15.724</td>\n",
       "      <td>3.403</td>\n",
       "      <td>-1.572</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.09</td>\n",
       "      <td>27.18</td>\n",
       "      <td>24233</td>\n",
       "      <td>2017-08-30 22:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2017-08-30 22:40:00</td>\n",
       "      <td>24234</td>\n",
       "      <td>6.67</td>\n",
       "      <td>292.211</td>\n",
       "      <td>16.172</td>\n",
       "      <td>2.933</td>\n",
       "      <td>-1.842</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.08</td>\n",
       "      <td>17.16</td>\n",
       "      <td>24239</td>\n",
       "      <td>2017-08-30 23:05:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2017-06-01 09:50:00        118      6.20    293.056    17.389   \n",
       "1    2017-06-02 00:10:00        290      5.97    262.933     7.011   \n",
       "2    2017-06-02 01:35:00        307      6.18    246.847     9.319   \n",
       "3    2017-06-02 03:20:00        328      6.58    225.236    11.698   \n",
       "4    2017-06-02 03:50:00        334      6.35    235.073    12.306   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "238  2017-08-30 19:45:00      24199      6.00    310.324    13.295   \n",
       "239  2017-08-30 20:25:00      24207      6.15    285.092    14.012   \n",
       "240  2017-08-30 21:25:00      24219      6.40    300.168    15.019   \n",
       "241  2017-08-30 22:10:00      24228      6.55    295.559    15.724   \n",
       "242  2017-08-30 22:40:00      24234      6.67    292.211    16.172   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0         0.595      -4.195       1.770     0.06   19.66      123   \n",
       "1         0.063      -4.832      -0.632     0.10   29.20      295   \n",
       "2         1.547      -3.790      -1.605     0.09   24.07      312   \n",
       "3         3.572      -1.372      -1.312     0.05   22.01      333   \n",
       "4         3.567      -2.147      -1.370     0.09   27.74      339   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "238       3.990      -1.860       1.555     0.03   23.50    24204   \n",
       "239       3.355      -2.912       0.775     0.06   10.45    24212   \n",
       "240       3.497      -1.742       1.002     0.08   14.82    24224   \n",
       "241       3.403      -1.572       0.705     0.09   27.18    24233   \n",
       "242       2.933      -1.842       0.752     0.08   17.16    24239   \n",
       "\n",
       "                 End_str  \n",
       "0    2017-06-01 10:15:00  \n",
       "1    2017-06-02 00:35:00  \n",
       "2    2017-06-02 02:00:00  \n",
       "3    2017-06-02 03:45:00  \n",
       "4    2017-06-02 04:15:00  \n",
       "..                   ...  \n",
       "238  2017-08-30 20:10:00  \n",
       "239  2017-08-30 20:50:00  \n",
       "240  2017-08-30 21:50:00  \n",
       "241  2017-08-30 22:35:00  \n",
       "242  2017-08-30 23:05:00  \n",
       "\n",
       "[243 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-02 17:05:00</td>\n",
       "      <td>493</td>\n",
       "      <td>6.38</td>\n",
       "      <td>304.109</td>\n",
       "      <td>14.843</td>\n",
       "      <td>4.523</td>\n",
       "      <td>-3.513</td>\n",
       "      <td>2.282</td>\n",
       "      <td>0.02</td>\n",
       "      <td>29.93</td>\n",
       "      <td>498</td>\n",
       "      <td>2018-06-02 17:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-04 10:25:00</td>\n",
       "      <td>892</td>\n",
       "      <td>6.68</td>\n",
       "      <td>277.666</td>\n",
       "      <td>21.348</td>\n",
       "      <td>3.815</td>\n",
       "      <td>-1.967</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.06</td>\n",
       "      <td>24.03</td>\n",
       "      <td>897</td>\n",
       "      <td>2018-06-04 10:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-04 12:20:00</td>\n",
       "      <td>915</td>\n",
       "      <td>6.72</td>\n",
       "      <td>294.454</td>\n",
       "      <td>20.296</td>\n",
       "      <td>4.328</td>\n",
       "      <td>-1.463</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.04</td>\n",
       "      <td>12.47</td>\n",
       "      <td>920</td>\n",
       "      <td>2018-06-04 12:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-04 12:50:00</td>\n",
       "      <td>921</td>\n",
       "      <td>6.72</td>\n",
       "      <td>288.418</td>\n",
       "      <td>19.997</td>\n",
       "      <td>3.978</td>\n",
       "      <td>-1.982</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.06</td>\n",
       "      <td>21.87</td>\n",
       "      <td>926</td>\n",
       "      <td>2018-06-04 13:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-06-04 13:20:00</td>\n",
       "      <td>927</td>\n",
       "      <td>6.15</td>\n",
       "      <td>286.128</td>\n",
       "      <td>19.686</td>\n",
       "      <td>3.717</td>\n",
       "      <td>-2.055</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10.48</td>\n",
       "      <td>932</td>\n",
       "      <td>2018-06-04 13:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2018-08-30 20:05:00</td>\n",
       "      <td>24121</td>\n",
       "      <td>5.70</td>\n",
       "      <td>266.572</td>\n",
       "      <td>20.389</td>\n",
       "      <td>-1.180</td>\n",
       "      <td>-4.237</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>0.02</td>\n",
       "      <td>14.84</td>\n",
       "      <td>24126</td>\n",
       "      <td>2018-08-30 20:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>2018-08-30 20:40:00</td>\n",
       "      <td>24128</td>\n",
       "      <td>5.35</td>\n",
       "      <td>267.789</td>\n",
       "      <td>20.042</td>\n",
       "      <td>-1.267</td>\n",
       "      <td>-4.523</td>\n",
       "      <td>-0.202</td>\n",
       "      <td>0.08</td>\n",
       "      <td>13.71</td>\n",
       "      <td>24133</td>\n",
       "      <td>2018-08-30 21:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>2018-08-30 21:10:00</td>\n",
       "      <td>24134</td>\n",
       "      <td>5.17</td>\n",
       "      <td>255.979</td>\n",
       "      <td>19.733</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-4.782</td>\n",
       "      <td>-1.195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>10.19</td>\n",
       "      <td>24139</td>\n",
       "      <td>2018-08-30 21:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>2018-08-30 22:30:00</td>\n",
       "      <td>24150</td>\n",
       "      <td>6.92</td>\n",
       "      <td>239.805</td>\n",
       "      <td>18.852</td>\n",
       "      <td>1.937</td>\n",
       "      <td>-2.883</td>\n",
       "      <td>-1.672</td>\n",
       "      <td>0.09</td>\n",
       "      <td>19.43</td>\n",
       "      <td>24155</td>\n",
       "      <td>2018-08-30 22:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>2018-08-30 23:00:00</td>\n",
       "      <td>24156</td>\n",
       "      <td>6.80</td>\n",
       "      <td>251.891</td>\n",
       "      <td>18.500</td>\n",
       "      <td>0.993</td>\n",
       "      <td>-3.962</td>\n",
       "      <td>-1.272</td>\n",
       "      <td>0.06</td>\n",
       "      <td>29.06</td>\n",
       "      <td>24161</td>\n",
       "      <td>2018-08-30 23:25:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2018-06-02 17:05:00        493      6.38    304.109    14.843   \n",
       "1    2018-06-04 10:25:00        892      6.68    277.666    21.348   \n",
       "2    2018-06-04 12:20:00        915      6.72    294.454    20.296   \n",
       "3    2018-06-04 12:50:00        921      6.72    288.418    19.997   \n",
       "4    2018-06-04 13:20:00        927      6.15    286.128    19.686   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "284  2018-08-30 20:05:00      24121      5.70    266.572    20.389   \n",
       "285  2018-08-30 20:40:00      24128      5.35    267.789    20.042   \n",
       "286  2018-08-30 21:10:00      24134      5.17    255.979    19.733   \n",
       "287  2018-08-30 22:30:00      24150      6.92    239.805    18.852   \n",
       "288  2018-08-30 23:00:00      24156      6.80    251.891    18.500   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0         4.523      -3.513       2.282     0.02   29.93      498   \n",
       "1         3.815      -1.967       0.257     0.06   24.03      897   \n",
       "2         4.328      -1.463       0.662     0.04   12.47      920   \n",
       "3         3.978      -1.982       0.663     0.06   21.87      926   \n",
       "4         3.717      -2.055       0.595     0.05   10.48      932   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "284      -1.180      -4.237      -0.265     0.02   14.84    24126   \n",
       "285      -1.267      -4.523      -0.202     0.08   13.71    24133   \n",
       "286       0.000      -4.782      -1.195     0.03   10.19    24139   \n",
       "287       1.937      -2.883      -1.672     0.09   19.43    24155   \n",
       "288       0.993      -3.962      -1.272     0.06   29.06    24161   \n",
       "\n",
       "                 End_str  \n",
       "0    2018-06-02 17:30:00  \n",
       "1    2018-06-04 10:50:00  \n",
       "2    2018-06-04 12:45:00  \n",
       "3    2018-06-04 13:15:00  \n",
       "4    2018-06-04 13:45:00  \n",
       "..                   ...  \n",
       "284  2018-08-30 20:30:00  \n",
       "285  2018-08-30 21:05:00  \n",
       "286  2018-08-30 21:35:00  \n",
       "287  2018-08-30 22:55:00  \n",
       "288  2018-08-30 23:25:00  \n",
       "\n",
       "[289 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-01 00:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.32</td>\n",
       "      <td>257.237</td>\n",
       "      <td>8.075</td>\n",
       "      <td>1.465</td>\n",
       "      <td>-1.693</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>0.10</td>\n",
       "      <td>8.21</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-06-01 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-01 06:20:00</td>\n",
       "      <td>73</td>\n",
       "      <td>5.70</td>\n",
       "      <td>251.751</td>\n",
       "      <td>15.959</td>\n",
       "      <td>1.675</td>\n",
       "      <td>-2.445</td>\n",
       "      <td>-0.813</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.50</td>\n",
       "      <td>78</td>\n",
       "      <td>2019-06-01 06:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-01 12:05:00</td>\n",
       "      <td>142</td>\n",
       "      <td>5.33</td>\n",
       "      <td>281.045</td>\n",
       "      <td>20.735</td>\n",
       "      <td>1.910</td>\n",
       "      <td>-1.903</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.08</td>\n",
       "      <td>21.85</td>\n",
       "      <td>147</td>\n",
       "      <td>2019-06-01 12:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-01 12:35:00</td>\n",
       "      <td>148</td>\n",
       "      <td>5.17</td>\n",
       "      <td>278.571</td>\n",
       "      <td>21.079</td>\n",
       "      <td>2.458</td>\n",
       "      <td>-1.438</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.04</td>\n",
       "      <td>20.96</td>\n",
       "      <td>153</td>\n",
       "      <td>2019-06-01 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-01 13:05:00</td>\n",
       "      <td>154</td>\n",
       "      <td>5.22</td>\n",
       "      <td>273.090</td>\n",
       "      <td>21.413</td>\n",
       "      <td>2.258</td>\n",
       "      <td>-1.897</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6.67</td>\n",
       "      <td>159</td>\n",
       "      <td>2019-06-01 13:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>2019-08-27 22:15:00</td>\n",
       "      <td>22649</td>\n",
       "      <td>6.92</td>\n",
       "      <td>254.653</td>\n",
       "      <td>17.476</td>\n",
       "      <td>-2.693</td>\n",
       "      <td>-3.213</td>\n",
       "      <td>-0.863</td>\n",
       "      <td>0.06</td>\n",
       "      <td>20.53</td>\n",
       "      <td>22654</td>\n",
       "      <td>2019-08-27 22:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2019-08-30 03:05:00</td>\n",
       "      <td>23204</td>\n",
       "      <td>6.65</td>\n",
       "      <td>262.737</td>\n",
       "      <td>23.616</td>\n",
       "      <td>2.083</td>\n",
       "      <td>-2.355</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.10</td>\n",
       "      <td>26.81</td>\n",
       "      <td>23209</td>\n",
       "      <td>2019-08-30 03:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2019-08-30 03:45:00</td>\n",
       "      <td>23212</td>\n",
       "      <td>6.43</td>\n",
       "      <td>308.751</td>\n",
       "      <td>23.255</td>\n",
       "      <td>2.253</td>\n",
       "      <td>-1.945</td>\n",
       "      <td>1.552</td>\n",
       "      <td>0.08</td>\n",
       "      <td>15.45</td>\n",
       "      <td>23217</td>\n",
       "      <td>2019-08-30 04:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>2019-08-30 12:30:00</td>\n",
       "      <td>23317</td>\n",
       "      <td>6.30</td>\n",
       "      <td>240.611</td>\n",
       "      <td>16.970</td>\n",
       "      <td>4.650</td>\n",
       "      <td>-4.623</td>\n",
       "      <td>-2.702</td>\n",
       "      <td>0.08</td>\n",
       "      <td>27.65</td>\n",
       "      <td>23322</td>\n",
       "      <td>2019-08-30 12:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2019-08-30 13:00:00</td>\n",
       "      <td>23323</td>\n",
       "      <td>7.00</td>\n",
       "      <td>232.942</td>\n",
       "      <td>16.503</td>\n",
       "      <td>3.510</td>\n",
       "      <td>-4.423</td>\n",
       "      <td>-3.362</td>\n",
       "      <td>0.09</td>\n",
       "      <td>14.75</td>\n",
       "      <td>23328</td>\n",
       "      <td>2019-08-30 13:25:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2019-06-01 00:05:00          1      6.32    257.237     8.075   \n",
       "1    2019-06-01 06:20:00         73      5.70    251.751    15.959   \n",
       "2    2019-06-01 12:05:00        142      5.33    281.045    20.735   \n",
       "3    2019-06-01 12:35:00        148      5.17    278.571    21.079   \n",
       "4    2019-06-01 13:05:00        154      5.22    273.090    21.413   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "227  2019-08-27 22:15:00      22649      6.92    254.653    17.476   \n",
       "228  2019-08-30 03:05:00      23204      6.65    262.737    23.616   \n",
       "229  2019-08-30 03:45:00      23212      6.43    308.751    23.255   \n",
       "230  2019-08-30 12:30:00      23317      6.30    240.611    16.970   \n",
       "231  2019-08-30 13:00:00      23323      7.00    232.942    16.503   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0         1.465      -1.693      -0.392     0.10    8.21        6   \n",
       "1         1.675      -2.445      -0.813     0.06    8.50       78   \n",
       "2         1.910      -1.903       0.380     0.08   21.85      147   \n",
       "3         2.458      -1.438       0.210     0.04   20.96      153   \n",
       "4         2.258      -1.897       0.097     0.02    6.67      159   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "227      -2.693      -3.213      -0.863     0.06   20.53    22654   \n",
       "228       2.083      -2.355      -0.275     0.10   26.81    23209   \n",
       "229       2.253      -1.945       1.552     0.08   15.45    23217   \n",
       "230       4.650      -4.623      -2.702     0.08   27.65    23322   \n",
       "231       3.510      -4.423      -3.362     0.09   14.75    23328   \n",
       "\n",
       "                 End_str  \n",
       "0    2019-06-01 00:30:00  \n",
       "1    2019-06-01 06:45:00  \n",
       "2    2019-06-01 12:30:00  \n",
       "3    2019-06-01 13:00:00  \n",
       "4    2019-06-01 13:30:00  \n",
       "..                   ...  \n",
       "227  2019-08-27 22:40:00  \n",
       "228  2019-08-30 03:30:00  \n",
       "229  2019-08-30 04:10:00  \n",
       "230  2019-08-30 12:55:00  \n",
       "231  2019-08-30 13:25:00  \n",
       "\n",
       "[232 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-02 06:55:00</td>\n",
       "      <td>319</td>\n",
       "      <td>5.00</td>\n",
       "      <td>226.182</td>\n",
       "      <td>13.729</td>\n",
       "      <td>3.943</td>\n",
       "      <td>-3.213</td>\n",
       "      <td>-3.013</td>\n",
       "      <td>0.04</td>\n",
       "      <td>26.45</td>\n",
       "      <td>324</td>\n",
       "      <td>2020-06-02 07:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-02 09:00:00</td>\n",
       "      <td>344</td>\n",
       "      <td>5.27</td>\n",
       "      <td>226.166</td>\n",
       "      <td>11.284</td>\n",
       "      <td>1.592</td>\n",
       "      <td>-4.300</td>\n",
       "      <td>-4.105</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20.13</td>\n",
       "      <td>349</td>\n",
       "      <td>2020-06-02 09:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-02 10:00:00</td>\n",
       "      <td>356</td>\n",
       "      <td>5.38</td>\n",
       "      <td>229.107</td>\n",
       "      <td>9.962</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-4.347</td>\n",
       "      <td>-3.767</td>\n",
       "      <td>0.02</td>\n",
       "      <td>15.49</td>\n",
       "      <td>361</td>\n",
       "      <td>2020-06-02 10:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-02 11:05:00</td>\n",
       "      <td>369</td>\n",
       "      <td>5.20</td>\n",
       "      <td>258.937</td>\n",
       "      <td>8.390</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>-6.360</td>\n",
       "      <td>-1.258</td>\n",
       "      <td>0.03</td>\n",
       "      <td>20.04</td>\n",
       "      <td>374</td>\n",
       "      <td>2020-06-02 11:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-02 11:35:00</td>\n",
       "      <td>375</td>\n",
       "      <td>5.18</td>\n",
       "      <td>284.889</td>\n",
       "      <td>7.608</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>-6.297</td>\n",
       "      <td>1.677</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.21</td>\n",
       "      <td>380</td>\n",
       "      <td>2020-06-02 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2020-08-25 00:10:00</td>\n",
       "      <td>23539</td>\n",
       "      <td>6.20</td>\n",
       "      <td>296.891</td>\n",
       "      <td>16.946</td>\n",
       "      <td>0.578</td>\n",
       "      <td>-3.435</td>\n",
       "      <td>1.737</td>\n",
       "      <td>0.04</td>\n",
       "      <td>13.08</td>\n",
       "      <td>23544</td>\n",
       "      <td>2020-08-25 00:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2020-08-25 06:00:00</td>\n",
       "      <td>23609</td>\n",
       "      <td>6.42</td>\n",
       "      <td>275.297</td>\n",
       "      <td>10.694</td>\n",
       "      <td>1.407</td>\n",
       "      <td>-3.890</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.10</td>\n",
       "      <td>16.33</td>\n",
       "      <td>23614</td>\n",
       "      <td>2020-08-25 06:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2020-08-25 07:05:00</td>\n",
       "      <td>23622</td>\n",
       "      <td>6.35</td>\n",
       "      <td>304.304</td>\n",
       "      <td>9.199</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>-4.332</td>\n",
       "      <td>2.957</td>\n",
       "      <td>0.03</td>\n",
       "      <td>29.44</td>\n",
       "      <td>23627</td>\n",
       "      <td>2020-08-25 07:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2020-08-25 16:25:00</td>\n",
       "      <td>23734</td>\n",
       "      <td>6.13</td>\n",
       "      <td>311.393</td>\n",
       "      <td>10.028</td>\n",
       "      <td>-3.442</td>\n",
       "      <td>-2.453</td>\n",
       "      <td>2.073</td>\n",
       "      <td>0.10</td>\n",
       "      <td>22.38</td>\n",
       "      <td>23739</td>\n",
       "      <td>2020-08-25 16:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2020-08-29 13:00:00</td>\n",
       "      <td>24845</td>\n",
       "      <td>6.87</td>\n",
       "      <td>268.712</td>\n",
       "      <td>19.002</td>\n",
       "      <td>-2.635</td>\n",
       "      <td>-3.102</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.03</td>\n",
       "      <td>27.41</td>\n",
       "      <td>24850</td>\n",
       "      <td>2020-08-29 13:25:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2020-06-02 06:55:00        319      5.00    226.182    13.729   \n",
       "1    2020-06-02 09:00:00        344      5.27    226.166    11.284   \n",
       "2    2020-06-02 10:00:00        356      5.38    229.107     9.962   \n",
       "3    2020-06-02 11:05:00        369      5.20    258.937     8.390   \n",
       "4    2020-06-02 11:35:00        375      5.18    284.889     7.608   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "143  2020-08-25 00:10:00      23539      6.20    296.891    16.946   \n",
       "144  2020-08-25 06:00:00      23609      6.42    275.297    10.694   \n",
       "145  2020-08-25 07:05:00      23622      6.35    304.304     9.199   \n",
       "146  2020-08-25 16:25:00      23734      6.13    311.393    10.028   \n",
       "147  2020-08-29 13:00:00      24845      6.87    268.712    19.002   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0         3.943      -3.213      -3.013     0.04   26.45      324   \n",
       "1         1.592      -4.300      -4.105     0.05   20.13      349   \n",
       "2         0.010      -4.347      -3.767     0.02   15.49      361   \n",
       "3        -0.357      -6.360      -1.258     0.03   20.04      374   \n",
       "4        -0.497      -6.297       1.677     0.03    9.21      380   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "143       0.578      -3.435       1.737     0.04   13.08    23544   \n",
       "144       1.407      -3.890       0.363     0.10   16.33    23614   \n",
       "145      -0.730      -4.332       2.957     0.03   29.44    23627   \n",
       "146      -3.442      -2.453       2.073     0.10   22.38    23739   \n",
       "147      -2.635      -3.102      -0.037     0.03   27.41    24850   \n",
       "\n",
       "                 End_str  \n",
       "0    2020-06-02 07:20:00  \n",
       "1    2020-06-02 09:25:00  \n",
       "2    2020-06-02 10:25:00  \n",
       "3    2020-06-02 11:30:00  \n",
       "4    2020-06-02 12:00:00  \n",
       "..                   ...  \n",
       "143  2020-08-25 00:35:00  \n",
       "144  2020-08-25 06:25:00  \n",
       "145  2020-08-25 07:30:00  \n",
       "146  2020-08-25 16:50:00  \n",
       "147  2020-08-29 13:25:00  \n",
       "\n",
       "[148 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>Start_ind</th>\n",
       "      <th>Mgs#_avg</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Rmag_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "      <th>Bdeviat</th>\n",
       "      <th>Dtheta</th>\n",
       "      <th>End_ind</th>\n",
       "      <th>End_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-01 00:50:00</td>\n",
       "      <td>10</td>\n",
       "      <td>5.43</td>\n",
       "      <td>244.331</td>\n",
       "      <td>21.428</td>\n",
       "      <td>0.613</td>\n",
       "      <td>-2.403</td>\n",
       "      <td>-1.138</td>\n",
       "      <td>0.07</td>\n",
       "      <td>13.79</td>\n",
       "      <td>15</td>\n",
       "      <td>2021-06-01 01:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-01 01:20:00</td>\n",
       "      <td>16</td>\n",
       "      <td>5.42</td>\n",
       "      <td>245.989</td>\n",
       "      <td>21.123</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>-2.787</td>\n",
       "      <td>-1.243</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9.68</td>\n",
       "      <td>21</td>\n",
       "      <td>2021-06-01 01:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-01 04:10:00</td>\n",
       "      <td>50</td>\n",
       "      <td>5.05</td>\n",
       "      <td>256.041</td>\n",
       "      <td>19.220</td>\n",
       "      <td>1.367</td>\n",
       "      <td>-2.745</td>\n",
       "      <td>-0.673</td>\n",
       "      <td>0.04</td>\n",
       "      <td>22.65</td>\n",
       "      <td>55</td>\n",
       "      <td>2021-06-01 04:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-01 08:40:00</td>\n",
       "      <td>104</td>\n",
       "      <td>6.95</td>\n",
       "      <td>245.306</td>\n",
       "      <td>15.479</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>-1.075</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>0.06</td>\n",
       "      <td>14.51</td>\n",
       "      <td>109</td>\n",
       "      <td>2021-06-01 09:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-01 09:10:00</td>\n",
       "      <td>110</td>\n",
       "      <td>6.92</td>\n",
       "      <td>242.842</td>\n",
       "      <td>14.998</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-1.133</td>\n",
       "      <td>-0.583</td>\n",
       "      <td>0.08</td>\n",
       "      <td>10.50</td>\n",
       "      <td>115</td>\n",
       "      <td>2021-06-01 09:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2021-08-24 03:15:00</td>\n",
       "      <td>22445</td>\n",
       "      <td>5.43</td>\n",
       "      <td>283.072</td>\n",
       "      <td>22.196</td>\n",
       "      <td>2.280</td>\n",
       "      <td>-4.657</td>\n",
       "      <td>1.077</td>\n",
       "      <td>0.08</td>\n",
       "      <td>16.00</td>\n",
       "      <td>22450</td>\n",
       "      <td>2021-08-24 03:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2021-08-24 10:20:00</td>\n",
       "      <td>22530</td>\n",
       "      <td>5.37</td>\n",
       "      <td>248.279</td>\n",
       "      <td>17.246</td>\n",
       "      <td>3.765</td>\n",
       "      <td>-3.012</td>\n",
       "      <td>-1.208</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.67</td>\n",
       "      <td>22535</td>\n",
       "      <td>2021-08-24 10:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2021-08-24 16:40:00</td>\n",
       "      <td>22606</td>\n",
       "      <td>5.78</td>\n",
       "      <td>296.219</td>\n",
       "      <td>10.594</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-5.103</td>\n",
       "      <td>2.523</td>\n",
       "      <td>0.09</td>\n",
       "      <td>27.65</td>\n",
       "      <td>22611</td>\n",
       "      <td>2021-08-24 17:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2021-08-24 17:10:00</td>\n",
       "      <td>22612</td>\n",
       "      <td>5.80</td>\n",
       "      <td>272.861</td>\n",
       "      <td>9.927</td>\n",
       "      <td>0.713</td>\n",
       "      <td>-6.123</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.06</td>\n",
       "      <td>20.93</td>\n",
       "      <td>22617</td>\n",
       "      <td>2021-08-24 17:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2021-08-29 07:40:00</td>\n",
       "      <td>23934</td>\n",
       "      <td>6.33</td>\n",
       "      <td>270.595</td>\n",
       "      <td>23.523</td>\n",
       "      <td>1.902</td>\n",
       "      <td>-4.157</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.09</td>\n",
       "      <td>14.38</td>\n",
       "      <td>23939</td>\n",
       "      <td>2021-08-29 08:05:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str  Start_ind  Mgs#_avg  Clang_avg  Rmag_avg  \\\n",
       "0    2021-06-01 00:50:00         10      5.43    244.331    21.428   \n",
       "1    2021-06-01 01:20:00         16      5.42    245.989    21.123   \n",
       "2    2021-06-01 04:10:00         50      5.05    256.041    19.220   \n",
       "3    2021-06-01 08:40:00        104      6.95    245.306    15.479   \n",
       "4    2021-06-01 09:10:00        110      6.92    242.842    14.998   \n",
       "..                   ...        ...       ...        ...       ...   \n",
       "194  2021-08-24 03:15:00      22445      5.43    283.072    22.196   \n",
       "195  2021-08-24 10:20:00      22530      5.37    248.279    17.246   \n",
       "196  2021-08-24 16:40:00      22606      5.78    296.219    10.594   \n",
       "197  2021-08-24 17:10:00      22612      5.80    272.861     9.927   \n",
       "198  2021-08-29 07:40:00      23934      6.33    270.595    23.523   \n",
       "\n",
       "     Bx_avg(nT)  By_avg(nT)  Bz_avg(nT)  Bdeviat  Dtheta  End_ind  \\\n",
       "0         0.613      -2.403      -1.138     0.07   13.79       15   \n",
       "1        -0.053      -2.787      -1.243     0.05    9.68       21   \n",
       "2         1.367      -2.745      -0.673     0.04   22.65       55   \n",
       "3        -0.295      -1.075      -0.493     0.06   14.51      109   \n",
       "4        -0.210      -1.133      -0.583     0.08   10.50      115   \n",
       "..          ...         ...         ...      ...     ...      ...   \n",
       "194       2.280      -4.657       1.077     0.08   16.00    22450   \n",
       "195       3.765      -3.012      -1.208     0.05    6.67    22535   \n",
       "196       0.145      -5.103       2.523     0.09   27.65    22611   \n",
       "197       0.713      -6.123       0.295     0.06   20.93    22617   \n",
       "198       1.902      -4.157       0.030     0.09   14.38    23939   \n",
       "\n",
       "                 End_str  \n",
       "0    2021-06-01 01:15:00  \n",
       "1    2021-06-01 01:45:00  \n",
       "2    2021-06-01 04:35:00  \n",
       "3    2021-06-01 09:05:00  \n",
       "4    2021-06-01 09:35:00  \n",
       "..                   ...  \n",
       "194  2021-08-24 03:40:00  \n",
       "195  2021-08-24 10:45:00  \n",
       "196  2021-08-24 17:05:00  \n",
       "197  2021-08-24 17:35:00  \n",
       "198  2021-08-29 08:05:00  \n",
       "\n",
       "[199 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying Nightside Yr 1-7 General Stable Lists\n"
     ]
    }
   ],
   "source": [
    "#'''\n",
    "#Load Nightside MEC Data:   Extracting MEC radial position(km) and time(unix time) arrays\n",
    "night_yr1_MECposdata = np.load(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/MEC exported Nightside posdata/Nightside_yr1_MECgsm_posdata.npz')\n",
    "night_yr2_MECposdata = np.load(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/MEC exported Nightside posdata/Nightside_yr2_MECgsm_posdata.npz')\n",
    "night_yr3_MECposdata = np.load(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/MEC exported Nightside posdata/Nightside_yr3_MECgsm_posdata.npz')\n",
    "night_yr4_MECposdata = np.load(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/MEC exported Nightside posdata/Nightside_yr4_MECgsm_posdata.npz')\n",
    "night_yr5_MECposdata = np.load(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/MEC exported Nightside posdata/Nightside_yr5_MECgsm_posdata.npz')\n",
    "night_yr6_MECposdata = np.load(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/MEC exported Nightside posdata/Nightside_yr6_MECgsm_posdata.npz')\n",
    "night_yr7_MECposdata = np.load(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/MEC exported Nightside posdata/Nightside_yr7_MECgsm_posdata.npz')\n",
    "\n",
    "\n",
    "#Importing Night Yr 1-5 SoBZ Stable List##\n",
    "df_NightsoBz_yr1 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_soBz/pdFile_Night_Yr1_7to24Re_30mFilt_Stable_soBz.txt', sep = '\\t')\n",
    "df_NightsoBz_yr2 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_soBz/pdFile_Night_Yr2_7to24Re_30mFilt_Stable_soBz.txt', sep = '\\t')\n",
    "df_NightsoBz_yr3 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_soBz/pdFile_Night_Yr3_7to24Re_30mFilt_Stable_soBz.txt', sep = '\\t')\n",
    "df_NightsoBz_yr4 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_soBz/pdFile_Night_Yr4_7to24Re_30mFilt_Stable_soBz.txt', sep = '\\t')\n",
    "df_NightsoBz_yr5 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_soBz/pdFile_Night_Yr5_7to24Re_30mFilt_Stable_soBz.txt', sep = '\\t')\n",
    "df_NightsoBz_yr6 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_soBz/pdFile_Night_Yr6_7to24Re_30mFilt_Stable_soBz.txt', sep = '\\t')\n",
    "df_NightsoBz_yr7 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_soBz/pdFile_Night_Yr7_7to24Re_30mFilt_Stable_soBz.txt', sep = '\\t')\n",
    "\n",
    "print('Displaying Nightside(Jun-Aug)Yr 1-7 SoBz Stable Lists')\n",
    "print(df_NightsoBz_yr1.dtypes) #displaying column names and type of column data\n",
    "#show1to5DF(df_NightsoBz_yr1, df_NightsoBz_yr2, df_NightsoBz_yr3, df_NightsoBz_yr4, df_NightsoBz_yr5)\n",
    "#display(df_NightsoBz_yr6)\n",
    "#display(df_NightsoBz_yr7)\n",
    "\n",
    "#Importing Night Yr 1-7 norBz Stable List##\n",
    "df_NightnorBz_yr1 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_norBz/pdFile_Night_Yr1_7to24Re_30mFilt_Stable_norBz.txt', sep = '\\t')\n",
    "df_NightnorBz_yr2 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_norBz/pdFile_Night_Yr2_7to24Re_30mFilt_Stable_norBz.txt', sep = '\\t')\n",
    "df_NightnorBz_yr3 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_norBz/pdFile_Night_Yr3_7to24Re_30mFilt_Stable_norBz.txt', sep = '\\t')\n",
    "df_NightnorBz_yr4 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_norBz/pdFile_Night_Yr4_7to24Re_30mFilt_Stable_norBz.txt', sep = '\\t')\n",
    "df_NightnorBz_yr5 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_norBz/pdFile_Night_Yr5_7to24Re_30mFilt_Stable_norBz.txt', sep = '\\t')\n",
    "df_NightnorBz_yr6 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_norBz/pdFile_Night_Yr6_7to24Re_30mFilt_Stable_norBz.txt', sep = '\\t')\n",
    "df_NightnorBz_yr7 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_norBz/pdFile_Night_Yr7_7to24Re_30mFilt_Stable_norBz.txt', sep = '\\t')\n",
    "\n",
    "print('Displaying Nightside(Jun-Aug)Yr 1-7 norBz Stable Lists')\n",
    "#show1to5DF(df_NightnorBz_yr1, df_NightnorBz_yr2, df_NightnorBz_yr3, df_NightnorBz_yr4, df_NightnorBz_yr5)\n",
    "#display(df_NightnorBz_yr6)\n",
    "#display(df_NightnorBz_yr7)\n",
    "\n",
    "#Importing Night Yr 1-7 posBy Stable List##\n",
    "df_NightposBy_yr1 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_posBy/pdFile_Night_Yr1_7to24Re_30mFilt_Stable_posBy.txt', sep = '\\t')\n",
    "df_NightposBy_yr2 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_posBy/pdFile_Night_Yr2_7to24Re_30mFilt_Stable_posBy.txt', sep = '\\t')\n",
    "df_NightposBy_yr3 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_posBy/pdFile_Night_Yr3_7to24Re_30mFilt_Stable_posBy.txt', sep = '\\t')\n",
    "df_NightposBy_yr4 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_posBy/pdFile_Night_Yr4_7to24Re_30mFilt_Stable_posBy.txt', sep = '\\t')\n",
    "df_NightposBy_yr5 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_posBy/pdFile_Night_Yr5_7to24Re_30mFilt_Stable_posBy.txt', sep = '\\t')\n",
    "df_NightposBy_yr6 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_posBy/pdFile_Night_Yr6_7to24Re_30mFilt_Stable_posBy.txt', sep = '\\t')\n",
    "df_NightposBy_yr7 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_posBy/pdFile_Night_Yr7_7to24Re_30mFilt_Stable_posBy.txt', sep = '\\t')\n",
    "\n",
    "print('Displaying Nightside(Jun-Aug)Yr 1-7 posBy Stable Lists')\n",
    "show1to5DF(df_NightposBy_yr1, df_NightposBy_yr2, df_NightposBy_yr3, df_NightposBy_yr4, df_NightposBy_yr5)\n",
    "display(df_NightposBy_yr6)\n",
    "display(df_NightposBy_yr7)\n",
    "\n",
    "#Importing Night Yr 1-7 negBy Stable List##\n",
    "df_NightnegBy_yr1 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_negBy/pdFile_Night_Yr1_7to24Re_30mFilt_Stable_negBy.txt', sep = '\\t')\n",
    "df_NightnegBy_yr2 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_negBy/pdFile_Night_Yr2_7to24Re_30mFilt_Stable_negBy.txt', sep = '\\t')\n",
    "df_NightnegBy_yr3 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_negBy/pdFile_Night_Yr3_7to24Re_30mFilt_Stable_negBy.txt', sep = '\\t')\n",
    "df_NightnegBy_yr4 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_negBy/pdFile_Night_Yr4_7to24Re_30mFilt_Stable_negBy.txt', sep = '\\t')\n",
    "df_NightnegBy_yr5 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_negBy/pdFile_Night_Yr5_7to24Re_30mFilt_Stable_negBy.txt', sep = '\\t')\n",
    "df_NightnegBy_yr6 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_negBy/pdFile_Night_Yr6_7to24Re_30mFilt_Stable_negBy.txt', sep = '\\t')\n",
    "df_NightnegBy_yr7 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_negBy/pdFile_Night_Yr7_7to24Re_30mFilt_Stable_negBy.txt', sep = '\\t')\n",
    "\n",
    "print('Displaying Nightside(Jun-Aug)Yr 1-7 negBy Stable Lists')\n",
    "show1to5DF(df_NightnegBy_yr1, df_NightnegBy_yr2, df_NightnegBy_yr3, df_NightnegBy_yr4, df_NightnegBy_yr5)\n",
    "display(df_NightnegBy_yr6)\n",
    "display(df_NightnegBy_yr7)\n",
    "\n",
    "#Importing Yr 1-7 NonClang Sorted Stable Lists\n",
    "df_Nightstable_yr1 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_General/pdFile_Night_Yr1_7to24Re_30mFilt_Stable_General.txt', sep = '\\t')\n",
    "df_Nightstable_yr2 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_General/pdFile_Night_Yr2_7to24Re_30mFilt_Stable_General.txt', sep = '\\t')\n",
    "df_Nightstable_yr3 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_General/pdFile_Night_Yr3_7to24Re_30mFilt_Stable_General.txt', sep = '\\t')\n",
    "df_Nightstable_yr4 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_General/pdFile_Night_Yr4_7to24Re_30mFilt_Stable_General.txt', sep = '\\t')\n",
    "df_Nightstable_yr5 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_General/pdFile_Night_Yr5_7to24Re_30mFilt_Stable_General.txt', sep = '\\t')\n",
    "df_Nightstable_yr6 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_General/pdFile_Night_Yr6_7to24Re_30mFilt_Stable_General.txt', sep = '\\t')\n",
    "df_Nightstable_yr7 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/'\n",
    "'Under pySPEDAS_venv/Night_Stable IMF Lists/pdFile_Night_General/pdFile_Night_Yr7_7to24Re_30mFilt_Stable_General.txt', sep = '\\t')\n",
    "\n",
    "print('Displaying Nightside Yr 1-7 General Stable Lists')\n",
    "#show1to5DF(df_Nightstable_yr1, df_Nightstable_yr2, df_Nightstable_yr3, df_Nightstable_yr4, df_Nightstable_yr5)\n",
    "#display(df_Nightstable_yr6)\n",
    "#display(df_Nightstable_yr7)\n",
    "#''';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fbaa4b",
   "metadata": {},
   "source": [
    "### Section 1.1:\n",
    "* Creating 10min Sublist from each 30min interval in the Yearly Stable IMF (7to24Re) List\n",
    "* (9-9-2021) As discussed with Rick, the suggestion for the last 10 or 15min of the stable 30min interval was in regards to accounting for any OMNI data timing error. Additionally, since theres a 2500pts difference between using 10min and 15min, the difference shouldn't matter since I'm extracting the median(to rid mmyself of outliers) and other stat parameters of the desired curlometer parameters\n",
    "    * **I'm going with collecting the last 10min for each stable 30min interval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a74ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start_str      object\n",
      "Start_ind       int64\n",
      "Mgs#_avg      float64\n",
      "Clang_avg     float64\n",
      "Rmag_avg      float64\n",
      "Bx_avg(nT)    float64\n",
      "By_avg(nT)    float64\n",
      "Bz_avg(nT)    float64\n",
      "Bdeviat       float64\n",
      "Dtheta        float64\n",
      "End_ind         int64\n",
      "End_str        object\n",
      "dtype: object\n",
      "n\\Extracting PosBy last 10min sublists from Yrly DFs, Theta:[45, 135]\n",
      "Full30 and Last10 minute Dataframes end-date columns are the same:  True\n",
      "Full30 and Last10 minute Dataframes end-date columns are the same:  True\n",
      "Full30 and Last10 minute Dataframes end-date columns are the same:  True\n",
      "Full30 and Last10 minute Dataframes end-date columns are the same:  True\n",
      "Full30 and Last10 minute Dataframes end-date columns are the same:  True\n",
      "\n",
      "Comparing column arrays between:  ['df_DayposBy_yr1'] ['df_pBy_noslash10m_yr1']\n",
      "OG and Last10 minute Dataframes clang_avg columns are the same:  True\n",
      "\tOG and Last10 minute DFs Bx, By, and Bz columns are the same:  True True True\n",
      "\n",
      "Comparing column arrays between:  ['df_DayposBy_yr2'] ['df_pBy_noslash10m_yr2']\n",
      "OG and Last10 minute Dataframes clang_avg columns are the same:  True\n",
      "\tOG and Last10 minute DFs Bx, By, and Bz columns are the same:  True True True\n",
      "\n",
      "Comparing column arrays between:  ['df_DayposBy_yr3'] ['df_pBy_noslash10m_yr3']\n",
      "OG and Last10 minute Dataframes clang_avg columns are the same:  True\n",
      "\tOG and Last10 minute DFs Bx, By, and Bz columns are the same:  True True True\n",
      "\n",
      "Comparing column arrays between:  ['df_DayposBy_yr4'] ['df_pBy_noslash10m_yr4']\n",
      "OG and Last10 minute Dataframes clang_avg columns are the same:  True\n",
      "\tOG and Last10 minute DFs Bx, By, and Bz columns are the same:  True True True\n",
      "\n",
      "Comparing column arrays between:  ['df_DayposBy_yr5'] ['df_pBy_noslash10m_yr5']\n",
      "OG and Last10 minute Dataframes clang_avg columns are the same:  True\n",
      "\tOG and Last10 minute DFs Bx, By, and Bz columns are the same:  True True True\n"
     ]
    }
   ],
   "source": [
    "###Extracting 10min sublists from main Stable IMF events###############################\n",
    "#print(df_NightsoBz_yr1.dtypes) #displaying column name and data type\n",
    "print(df_DaysoBz_yr1.dtypes) #displaying column name and data type\n",
    "def namestr(obj, namespace):\n",
    "## (as defined by the a stackoverflowuser) returns name of object as a string list\n",
    "    return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "\n",
    "def convert_strlist_to_unix(df_yr1,df_yr2,df_yr3, df_yr4, df_yr5):\n",
    "    \"\"\"Converting string end-date arrays from Yearly IMF DFs back to unix time\"\"\"\n",
    "    #extracting string end-date arrays from Yearly Dataframes\n",
    "    endstr_yr1 = df_yr1['End_str'].to_numpy(copy=True)\n",
    "    endstr_yr2 = df_yr2['End_str'].to_numpy(copy=True)\n",
    "    endstr_yr3 = df_yr3['End_str'].to_numpy(copy=True)\n",
    "    endstr_yr4 = df_yr4['End_str'].to_numpy(copy=True)\n",
    "    endstr_yr5 = df_yr5['End_str'].to_numpy(copy=True)\n",
    "    #converting end-date string arrays to unix time\n",
    "    endyr1_unix = time_double(endstr_yr1)\n",
    "    endyr2_unix = time_double(endstr_yr2)\n",
    "    endyr3_unix = time_double(endstr_yr3)\n",
    "    endyr4_unix = time_double(endstr_yr4)\n",
    "    endyr5_unix = time_double(endstr_yr5)\n",
    "    return(endstr_yr1, endstr_yr2, endstr_yr3, endstr_yr4, endstr_yr5,\n",
    "          endyr1_unix, endyr2_unix, endyr3_unix, endyr4_unix, endyr5_unix);\n",
    "\n",
    "def extract_clang(df_yr1,df_yr2,df_yr3, df_yr4, df_yr5):\n",
    "    \"\"\"Extract copies of avg IMF Clock Angle arrays from Yearly DFs\"\"\"\n",
    "    #extracting avg Clang arrays from Yearly Dataframes\n",
    "    clang_yr1 = df_yr1['Clang_avg'].to_numpy(copy=True)\n",
    "    clang_yr2 = df_yr2['Clang_avg'].to_numpy(copy=True)\n",
    "    clang_yr3 = df_yr3['Clang_avg'].to_numpy(copy=True)\n",
    "    clang_yr4 = df_yr4['Clang_avg'].to_numpy(copy=True)\n",
    "    clang_yr5 = df_yr5['Clang_avg'].to_numpy(copy=True)\n",
    "    return(clang_yr1, clang_yr2, clang_yr3, clang_yr4, clang_yr5)\n",
    "\n",
    "def extract_bx(df_yr1,df_yr2,df_yr3, df_yr4, df_yr5):\n",
    "    \"\"\"Extract copies of avg IMF Bx arrays from Yearly DFs\"\"\"\n",
    "    #extracting avg Clang arrays from Yearly Dataframes\n",
    "    bx_yr1 = df_yr1['Bx_avg(nT)'].to_numpy(copy=True)\n",
    "    bx_yr2 = df_yr2['Bx_avg(nT)'].to_numpy(copy=True)\n",
    "    bx_yr3 = df_yr3['Bx_avg(nT)'].to_numpy(copy=True)\n",
    "    bx_yr4 = df_yr4['Bx_avg(nT)'].to_numpy(copy=True)\n",
    "    bx_yr5 = df_yr5['Bx_avg(nT)'].to_numpy(copy=True)\n",
    "    return(bx_yr1, bx_yr2, bx_yr3, bx_yr4, bx_yr5)\n",
    "\n",
    "def extract_by(df_yr1,df_yr2,df_yr3, df_yr4, df_yr5):\n",
    "    \"\"\"Extract copies of avg IMF By arrays from Yearly DFs\"\"\"\n",
    "    #extracting avg Clang arrays from Yearly Dataframes\n",
    "    by_yr1 = df_yr1['By_avg(nT)'].to_numpy(copy=True)\n",
    "    by_yr2 = df_yr2['By_avg(nT)'].to_numpy(copy=True)\n",
    "    by_yr3 = df_yr3['By_avg(nT)'].to_numpy(copy=True)\n",
    "    by_yr4 = df_yr4['By_avg(nT)'].to_numpy(copy=True)\n",
    "    by_yr5 = df_yr5['By_avg(nT)'].to_numpy(copy=True)\n",
    "    return(by_yr1, by_yr2, by_yr3, by_yr4, by_yr5)\n",
    "\n",
    "def extract_bz(df_yr1,df_yr2,df_yr3, df_yr4, df_yr5):\n",
    "    \"\"\"Extract copies of avg IMF Bz arrays from Yearly DFs\"\"\"\n",
    "    #extracting avg Clang arrays from Yearly Dataframes\n",
    "    bz_yr1 = df_yr1['Bz_avg(nT)'].to_numpy(copy=True)\n",
    "    bz_yr2 = df_yr2['Bz_avg(nT)'].to_numpy(copy=True)\n",
    "    bz_yr3 = df_yr3['Bz_avg(nT)'].to_numpy(copy=True)\n",
    "    bz_yr4 = df_yr4['Bz_avg(nT)'].to_numpy(copy=True)\n",
    "    bz_yr5 = df_yr5['Bz_avg(nT)'].to_numpy(copy=True)\n",
    "    return(bz_yr1, bz_yr2, bz_yr3, bz_yr4, bz_yr5)\n",
    "\n",
    "#fSum = 0\n",
    "#for i in range(len(endstr_test)):\n",
    "#    fSum = fSum + (end_unix[i] - start_unix[i])\n",
    "#print('Avg diff between 30min unix time intervals was %0.3f'%(fSum/len(endstr_test)))\n",
    "\n",
    "def unix_interval(unixEND):\n",
    "##Copmuting/displaying startdate using the unix-time array for the end dates\n",
    "    #The number of digits between the start and endpoint for a 30minute interval is 1500pts\n",
    "    #15minute interval is actually 900pts and 600pts for 10min\n",
    "    for i in range(len(unixEND)):\n",
    "        endSTR = time_string(unixEND[i])\n",
    "        startSTR = time_string(unixEND[i] - 600)\n",
    "        print('\\nWith the enddate, %0.19s, the 10minute start should be %0.19s'%(endSTR, startSTR))\n",
    "    return;\n",
    "\n",
    "'''\n",
    "#unix_interval(end_unix)\n",
    "#print(startstr_test[0:10])\n",
    "print(list(endstr_test[0])) #displaying all characters for a string\n",
    "print('Yes:', endstr_test[0][10]) #displaying specific character in string\n",
    "love = endstr_test[0].replace(' ', '/') #adding slash mark to string date for trange input syntax\n",
    "loveunix = time_double(endstr_test[0])\n",
    "lovestr = endstr_test[0]\n",
    "lovestr2 = time_string(loveunix)\n",
    "print('As a string = %s, \\nas a unix time float number= %0.1f, \\nand reconverted back to string %s'\n",
    "      %(lovestr, loveunix, lovestr2))\n",
    "''';\n",
    "\n",
    "\n",
    "def last10min_Stable(unixEND, strEND, afClang, afBx, afBy, afBz):\n",
    "    \"\"\"Creating two dataframes of string dates for the last 10min of Yearly Stable IMF intervals\n",
    "    The 2nd dataframe will add '/' to string date to abide by trange input syntax\"\"\"\n",
    "    #creating empty dataframes with column name\n",
    "    df_last10 = pd.DataFrame(columns = ['Start_str','End_str', 'Clang_avg', \n",
    "                                        'Bx_avg(nT)', 'By_avg(nT)', 'Bz_avg(nT)']) #last10m with no slash mark\n",
    "    df_10slash = pd.DataFrame(columns = ['Start_trang', 'End_trang', 'Clang_avg', \n",
    "                                         'Bx_avg(nT)', 'By_avg(nT)', 'Bz_avg(nT)']) #last10m with a '/' mark\n",
    "    #print(df_last10)\n",
    "        #print(df_Bound) #should display message if empty\n",
    "    #Appending rows to empty dataframes using a loop\n",
    "    for i in range(len(unixEND)):\n",
    "        #Computing startdate using the unix-time array for the end dates\n",
    "        #The number of digits between the start and endpoint for a 10min interval is 600pts\n",
    "        endSTR = time_string(unixEND[i])\n",
    "        startSTR = time_string(unixEND[i] - 600)\n",
    "        clang = afClang[i] #defining variable for IMF Clang orientation to further differentiate DFs\n",
    "        bx_val = afBx[i]\n",
    "        by_val = afBy[i]\n",
    "        bz_val = afBz[i]\n",
    "        #creating other variables that add slash mark for trange input syntax\n",
    "        endTRAN = endSTR.replace(' ', '/') #replace any ' ' marks with a '/' mark\n",
    "        startTRAN = startSTR.replace(' ', '/')\n",
    "        df_last10 = df_last10.append({'Start_str': '%0.19s'%(startSTR), 'End_str': '%0.19s'%(endSTR), \n",
    "                           'Clang_avg': round(clang,3), 'Bx_avg(nT)': round(bx_val,3),\n",
    "                            'By_avg(nT)': round(by_val,3), 'Bz_avg(nT)': round(bz_val,3)}, ignore_index=True)\n",
    "        df_10slash = df_10slash.append({'Start_trang': '%0.19s'%(startTRAN), 'End_trang': '%0.19s'%(endTRAN),\n",
    "                           'Clang_avg': round(clang,3), 'Bx_avg(nT)': round(bx_val,3),\n",
    "                           'By_avg(nT)': round(by_val,3), 'Bz_avg(nT)': round(bz_val,3)}, ignore_index=True)\n",
    "    #print(df_last10['Start_str']) \n",
    "    #display(df_last10.iloc[0:3])\n",
    "    #display(df_10slash)\n",
    "    #print((type(df_last10['Start_str'][0])))\n",
    "        #to display full dataframe in full text format do print(df.to_string())\n",
    "        #use df.iloc[[row], [col]] to index into dataframe\n",
    "    compare_10min_30min(strEND, df_last10)\n",
    "        ##confirmed that the arrays are the same\n",
    "    return(df_10slash, df_last10);\n",
    "\n",
    "def compare_10min_30min(full30, df_last10m):\n",
    "#Compares dataframes columns for End-dates between 30min and 10min dataframe. They should be the same\n",
    "    last10 = df_last10m['End_str'].to_numpy(copy=True)\n",
    "    print('Full30 and Last10 minute Dataframes end-date columns are the same: ', (last10 == full30).all())\n",
    "    return;\n",
    "\n",
    "\n",
    "def compare_imp_df(df_og, df_imp):\n",
    "# Compares the original and reimported dataframes to ensure that they hold the same element values\n",
    "# Also takes into account df.equals() error with the imported DF changing the column types from the original\n",
    "    #Checks for column array equality. The first accounts for dtype while the 2nd ignores it\n",
    "    print((df_og == df_imp).all()) \n",
    "    print('\\nOG and imported DF are the same:', all(df_og == df_imp)) \n",
    "    df_imp2 = df_imp.copy(deep=True)\n",
    "    print('Imported and copy of imported DF are the same:', df_imp2.equals(df_imp))\n",
    "    print('Using df.equals,OG and reimported dataframes are the same:', df_og.equals(df_imp))\n",
    "    #Displaying dataframes and columns dtype if needed\n",
    "    #print(df_imp_30Filt_yr1.dtypes)\n",
    "    display(df_og[:3])\n",
    "    display(df_imp[:3])\n",
    "    return;\n",
    "\n",
    "def compare_clang(df_og, df_NOsl_10m):\n",
    "    \"\"\"Compare ClockAng column arrays between OG and Last10m DFs (should be the same)\"\"\"\n",
    "    print('\\nComparing column arrays between: ',namestr(df_og, globals()), namestr(df_NOsl_10m, globals()) )\n",
    "    clang_noslash = df_NOsl_10m['Clang_avg'].to_numpy(copy=True)\n",
    "    clang_og = df_og['Clang_avg'].to_numpy(copy=True)\n",
    "    print('OG and Last10 minute Dataframes clang_avg columns are the same: ', (clang_noslash == clang_og).all())\n",
    "    #print('CLang columns are the same: ',  np.allclose(clang_noslash,clang_og, equal_nan=True))\n",
    "    bx_nosl = df_NOsl_10m['Bx_avg(nT)'].to_numpy(copy=True)\n",
    "    by_nosl = df_NOsl_10m['By_avg(nT)'].to_numpy(copy=True)\n",
    "    bz_nosl = df_NOsl_10m['Bz_avg(nT)'].to_numpy(copy=True)\n",
    "    bx_og = df_og['Bx_avg(nT)'].to_numpy(copy=True)\n",
    "    by_og = df_og['By_avg(nT)'].to_numpy(copy=True)\n",
    "    bz_og = df_og['Bz_avg(nT)'].to_numpy(copy=True)\n",
    "    print('\\tOG and Last10 minute DFs Bx, By, and Bz columns are the same: ', (bx_nosl == bx_og).all(),\n",
    "         (by_nosl == by_og).all(), (bz_nosl == bz_og).all())\n",
    "    #print('\\tBcomp columns are the same: ', np.allclose(bx_nosl,bx_og, equal_nan=True), np.allclose(by_nosl,by_og, equal_nan=True), \n",
    "     #      np.allclose(bz_nosl,bz_og, equal_nan=True))\n",
    "    #print('\\tAvg ratio and abs difference of OG and Last10m Clang_avg columns:', \n",
    "    #      np.average(clang_og/clang_noslash) ,np.average(np.abs(clang_og - clang_noslash)))\n",
    "    #Confirmed: the same for negBy\n",
    "    return;\n",
    "\n",
    "\n",
    "\n",
    "#################### Main Calling Function####################\n",
    "def pd_extract_last10(df_yr1,df_yr2,df_yr3, df_yr4, df_yr5):\n",
    "    \"\"\"From the 30minute intervals of the inputted <ClockAng> Stable IMF Lists, extract out the last 10min \n",
    "    of the timeframes for curlometer data calculations\"\"\"\n",
    "    #Extracting string date-lists and unix time arrays from Yrly Stable IMF DFs\n",
    "    [endstr_yr1, endstr_yr2, endstr_yr3, endstr_yr4, endstr_yr5, endyr1_unix, endyr2_unix, endyr3_unix, \n",
    "     endyr4_unix, endyr5_unix] = convert_strlist_to_unix(df_yr1, df_yr2, df_yr3, df_yr4, df_yr5)\n",
    "    \n",
    "    #Extracting copies of avg ClockAng and Bx arrays from Yrly DFs\n",
    "    [clang_yr1, clang_yr2, clang_yr3, clang_yr4, clang_yr5]= extract_clang(df_yr1,df_yr2,df_yr3,df_yr4, df_yr5)\n",
    "    [bx_yr1, bx_yr2, bx_yr3, bx_yr4, bx_yr5]= extract_bx(df_yr1,df_yr2,df_yr3,df_yr4, df_yr5)\n",
    "    [by_yr1, by_yr2, by_yr3, by_yr4, by_yr5]= extract_by(df_yr1,df_yr2,df_yr3,df_yr4, df_yr5)\n",
    "    [bz_yr1, bz_yr2, bz_yr3, bz_yr4, bz_yr5]= extract_bz(df_yr1,df_yr2,df_yr3,df_yr4, df_yr5)\n",
    "\n",
    "    \n",
    "    # Extracting Yr1's last 10min from <ClockAng> 30min list\n",
    "    [df_10m_yr1, df_NOSL10m_yr1] = last10min_Stable(endyr1_unix, endstr_yr1, clang_yr1, bx_yr1, by_yr1, bz_yr1)\n",
    "       #Exporting yr1 last10min Filtered Data and comparing the exported/OG dataframe\n",
    "    #df_NOSL10m_yr1.to_csv('pdFile_DayNOSL_Yr1_last10m_trange_posBy.txt', sep = '\\t', index = False)\n",
    "    #df_imp_10min_yr1 = pd.read_csv('pdFile_DayNOSL_Yr1_last10m_trange_posBy.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_NOSL10m_yr1, df_imp_10min_yr1)\n",
    "\n",
    "    # Extracting Yr2's last 10min from <ClockAng> 30min list\n",
    "    [df_10m_yr2, df_NOSL10m_yr2] = last10min_Stable(endyr2_unix, endstr_yr2, clang_yr2, bx_yr2,by_yr2, bz_yr2)\n",
    "        #Exporting yr2 last10min Filtered Data and comparing the exported/OG dataframe\n",
    "    #df_NOSL10m_yr2.to_csv('pdFile_DayNOSL_Yr2_last10m_trange_posBy.txt', sep = '\\t', index = False)\n",
    "    #df_imp_10min_yr2 = pd.read_csv('pdFile_DayNOSL_Yr2_last10m_trange_posBy.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_NOSL10m_yr2, df_imp_10min_yr2)\n",
    "\n",
    "    # Extracting Yr3's last 10min from <ClockAng> 30min list\n",
    "    [df_10m_yr3, df_NOSL10m_yr3] = last10min_Stable(endyr3_unix, endstr_yr3, clang_yr3, bx_yr3,by_yr3, bz_yr3)\n",
    "        #Exporting yr3 last10min Filtered Data and comparing the exported/OG dataframe\n",
    "    #df_NOSL10m_yr3.to_csv('pdFile_DayNOSL_Yr3_last10m_trange_posBy.txt', sep = '\\t', index = False)\n",
    "    #df_imp_10min_yr3 = pd.read_csv('pdFile_DayNOSL_Yr3_last10m_trange_posBy.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_NOSL10m_yr3, df_imp_10min_yr3)\n",
    "\n",
    "    # Extracting Yr4's last 10min from <ClockAng> 30min list\n",
    "    [df_10m_yr4, df_NOSL10m_yr4] = last10min_Stable(endyr4_unix, endstr_yr4, clang_yr4, bx_yr4,by_yr4, bz_yr4)\n",
    "        #Exporting yr4 last10min Filtered Data and comparing the exported/OG dataframe\n",
    "    #df_NOSL10m_yr4.to_csv('pdFile_DayNOSL_Yr4_last10m_trange_posBy.txt', sep = '\\t', index = False)\n",
    "    #df_imp_10min_yr4 = pd.read_csv('pdFile_DayNOSL_Yr4_last10m_trange_posBy.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_NOSL10m_yr4, df_imp_10min_yr4)\n",
    "\n",
    "    # Extracting Yr5's last 10min from <ClockAng> 30min list\n",
    "    [df_10m_yr5, df_NOSL10m_yr5] = last10min_Stable(endyr5_unix, endstr_yr5, clang_yr5, bx_yr5,by_yr5, bz_yr5)\n",
    "        #Exporting yr5 last10min Filtered Data and comparing the exported/OG dataframe\n",
    "    #df_NOSL10m_yr5.to_csv('pdFile_DayNOSL_Yr5_last10m_trange_posBy_noGAP_incr.txt', sep = '\\t', index = False)\n",
    "    #df_imp_10min_yr5 = pd.read_csv('pdFile_DayNOSL_Yr5_last10m_trange_posBy_noGAP_incr.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_NOSL10m_yr5, df_imp_10min_yr5)\n",
    "    \n",
    "    return(df_NOSL10m_yr1, df_NOSL10m_yr2, df_NOSL10m_yr3, df_NOSL10m_yr4, df_NOSL10m_yr5);\n",
    "\n",
    "#Extracting No-slash last10 dataframes and displaying them\n",
    "'''\n",
    "print('Extracting SoBz last 10min sublists from Yrly DFs, Theta:[135, 225]')\n",
    "[df_sBz_noslash10m_yr1, df_sBz_noslash10m_yr2, df_sBz_noslash10m_yr3, df_sBz_noslash10m_yr4, \n",
    "                     df_sBz_noslash10m_yr5] = pd_extract_last10(df_DaysoBz_yr1,df_DaysoBz_yr2,\n",
    "                                    df_DaysoBz_yr3,df_DaysoBz_yr4, df_DaysoBz_yr5)\n",
    "\n",
    "#Comparing clang_avg columns\n",
    "compare_clang(df_DaysoBz_yr1, df_sBz_noslash10m_yr1)\n",
    "compare_clang(df_DaysoBz_yr2, df_sBz_noslash10m_yr2)\n",
    "compare_clang(df_DaysoBz_yr3, df_sBz_noslash10m_yr3)\n",
    "compare_clang(df_DaysoBz_yr4, df_sBz_noslash10m_yr4)\n",
    "compare_clang(df_DaysoBz_yr5, df_sBz_noslash10m_yr5)\n",
    "#Showcase Yr1to5 soBz NoSlash10m DFs\n",
    "#show1to5DF(df_sBz_noslash10m_yr1, df_sBz_noslash10m_yr2, df_sBz_noslash10m_yr3, df_sBz_noslash10m_yr4, df_sBz_noslash10m_yr5)\n",
    "''';\n",
    "\n",
    "'''\n",
    "print('n\\Extracting NegBy last 10min sublists from Yrly DFs, Theta:[225, 315]')\n",
    "[df_nBy_noslash10m_yr1, df_nBy_noslash10m_yr2, df_nBy_noslash10m_yr3, df_nBy_noslash10m_yr4, \n",
    "                     df_nBy_noslash10m_yr5] = pd_extract_last10(df_DaynegBy_yr1, df_DaynegBy_yr2, \n",
    "                                                df_DaynegBy_yr3, df_DaynegBy_yr4, df_DaynegBy_yr5)\n",
    "\n",
    "#Comparing clang_avg columns\n",
    "compare_clang(df_DaynegBy_yr1, df_nBy_noslash10m_yr1)\n",
    "compare_clang(df_DaynegBy_yr2, df_nBy_noslash10m_yr2)\n",
    "compare_clang(df_DaynegBy_yr3, df_nBy_noslash10m_yr3)\n",
    "compare_clang(df_DaynegBy_yr4, df_nBy_noslash10m_yr4)\n",
    "compare_clang(df_DaynegBy_yr5, df_nBy_noslash10m_yr5)\n",
    "#Showcase Yr1to5 negBy NoSlash10m DFs\n",
    "#show1to5DF(df_nBy_noslash10m_yr1, df_nBy_noslash10m_yr2, df_nBy_noslash10m_yr3, df_nBy_noslash10m_yr4, df_nBy_noslash10m_yr5)\n",
    "''';\n",
    "\n",
    "#'''\n",
    "print('n\\Extracting PosBy last 10min sublists from Yrly DFs, Theta:[45, 135]')\n",
    "[df_pBy_noslash10m_yr1, df_pBy_noslash10m_yr2, df_pBy_noslash10m_yr3, df_pBy_noslash10m_yr4, \n",
    "                     df_pBy_noslash10m_yr5] = pd_extract_last10(df_DayposBy_yr1, df_DayposBy_yr2, \n",
    "                                df_DayposBy_yr3, df_DayposBy_yr4, df_DayposBy_yr5)\n",
    "\n",
    "#Comparing clang_avg columns\n",
    "compare_clang(df_DayposBy_yr1, df_pBy_noslash10m_yr1)\n",
    "compare_clang(df_DayposBy_yr2, df_pBy_noslash10m_yr2)\n",
    "compare_clang(df_DayposBy_yr3, df_pBy_noslash10m_yr3)\n",
    "compare_clang(df_DayposBy_yr4, df_pBy_noslash10m_yr4)\n",
    "compare_clang(df_DayposBy_yr5, df_pBy_noslash10m_yr5)\n",
    "#Showcase Yr1to5 posBy NoSlash10m DFs\n",
    "#show1to5DF(df_pBy_noslash10m_yr1, df_pBy_noslash10m_yr2, df_pBy_noslash10m_yr3, df_pBy_noslash10m_yr4, df_pBy_noslash10m_yr5)\n",
    "#''';\n",
    "\n",
    "\n",
    "'''\n",
    "print('n\\Extracting NorBz last 10min sublists from Yrly DFs, Theta:[315, 45]')\n",
    "[df_noBz_noslash10m_yr1, df_noBz_noslash10m_yr2, df_noBz_noslash10m_yr3, df_noBz_noslash10m_yr4, \n",
    "                     df_noBz_noslash10m_yr5] = pd_extract_last10(df_DaynorBz_yr1, df_DaynorBz_yr2, \n",
    "                                 df_DaynorBz_yr3, df_DaynorBz_yr4, df_DaynorBz_yr5)\n",
    "\n",
    "#Comparing clang_avg columns\n",
    "compare_clang(df_DaynorBz_yr1, df_noBz_noslash10m_yr1)\n",
    "compare_clang(df_DaynorBz_yr2, df_noBz_noslash10m_yr2)\n",
    "compare_clang(df_DaynorBz_yr3, df_noBz_noslash10m_yr3)\n",
    "compare_clang(df_DaynorBz_yr4, df_noBz_noslash10m_yr4)\n",
    "compare_clang(df_DaynorBz_yr5, df_noBz_noslash10m_yr5)\n",
    "#Showcase Yr1to5 norBz NoSlash10m DFs\n",
    "#show1to5DF(df_noBz_noslash10m_yr1, df_noBz_noslash10m_yr2, df_noBz_noslash10m_yr3, df_noBz_noslash10m_yr4, df_noBz_noslash10m_yr5)\n",
    "''';\n",
    "\n",
    "\n",
    "'''\n",
    "print('Extracting General NonClangSort last 10min sublists from Yrly DFs')\n",
    "[df_gen_noslash10m_yr1, df_gen_noslash10m_yr2, df_gen_noslash10m_yr3, df_gen_noslash10m_yr4, \n",
    "                     df_gen_noslash10m_yr5] = pd_extract_last10(df_Daystable_yr1,df_Daystable_yr2,\n",
    "                                df_Daystable_yr3,df_Daystable_yr4, df_Daystable_yr5)\n",
    "\n",
    "#Comparing clang_avg columns\n",
    "compare_clang(df_Daystable_yr1, df_gen_noslash10m_yr1)\n",
    "compare_clang(df_Daystable_yr2, df_gen_noslash10m_yr2)\n",
    "compare_clang(df_Daystable_yr3, df_gen_noslash10m_yr3)\n",
    "compare_clang(df_Daystable_yr4, df_gen_noslash10m_yr4)\n",
    "compare_clang(df_Daystable_yr5, df_gen_noslash10m_yr5)\n",
    "#Showcase Yr1to5 General NoSlash10m DFs\n",
    "#show1to5DF(df_gen_noslash10m_yr1, df_gen_noslash10m_yr2, df_gen_noslash10m_yr3, df_gen_noslash10m_yr4, df_gen_noslash10m_yr5)\n",
    "''';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f88e3",
   "metadata": {},
   "source": [
    "* (5-24-2022) Creating Last 10min sublist from 2020-21's Night/Day Stable 30min IMF List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57cb56c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting General NonClangSort last 10min sublists from Yr6(2020-21) DF\n",
      "\n",
      "Creating Last10min Sublist from:  ['df_Nightstable_yr7']\n",
      "Full30 and Last10 minute Dataframes end-date columns are the same:  True\n",
      "\n",
      "Comparing column arrays between:  ['df_Nightstable_yr7'] ['df_gen_noslash10m_yr7']\n",
      "OG and Last10 minute Dataframes clang_avg columns are the same:  True\n",
      "\tOG and Last10 minute DFs Bx, By, and Bz columns are the same:  True True True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_str</th>\n",
       "      <th>End_str</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "      <th>By_avg(nT)</th>\n",
       "      <th>Bz_avg(nT)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-01 01:05:00</td>\n",
       "      <td>2021-06-01 01:15:00</td>\n",
       "      <td>244.331</td>\n",
       "      <td>0.613</td>\n",
       "      <td>-2.403</td>\n",
       "      <td>-1.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-01 01:35:00</td>\n",
       "      <td>2021-06-01 01:45:00</td>\n",
       "      <td>245.989</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>-2.787</td>\n",
       "      <td>-1.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-01 04:25:00</td>\n",
       "      <td>2021-06-01 04:35:00</td>\n",
       "      <td>256.041</td>\n",
       "      <td>1.367</td>\n",
       "      <td>-2.745</td>\n",
       "      <td>-0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-01 08:55:00</td>\n",
       "      <td>2021-06-01 09:05:00</td>\n",
       "      <td>245.306</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>-1.075</td>\n",
       "      <td>-0.493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-01 09:25:00</td>\n",
       "      <td>2021-06-01 09:35:00</td>\n",
       "      <td>242.842</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-1.133</td>\n",
       "      <td>-0.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>2021-08-28 13:30:00</td>\n",
       "      <td>2021-08-28 13:40:00</td>\n",
       "      <td>112.512</td>\n",
       "      <td>-1.648</td>\n",
       "      <td>7.038</td>\n",
       "      <td>-2.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>2021-08-28 14:00:00</td>\n",
       "      <td>2021-08-28 14:10:00</td>\n",
       "      <td>98.548</td>\n",
       "      <td>-1.555</td>\n",
       "      <td>7.318</td>\n",
       "      <td>-1.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>2021-08-28 14:30:00</td>\n",
       "      <td>2021-08-28 14:40:00</td>\n",
       "      <td>95.961</td>\n",
       "      <td>-1.477</td>\n",
       "      <td>7.087</td>\n",
       "      <td>-0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>2021-08-28 15:00:00</td>\n",
       "      <td>2021-08-28 15:10:00</td>\n",
       "      <td>88.390</td>\n",
       "      <td>-1.380</td>\n",
       "      <td>6.535</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>2021-08-29 07:55:00</td>\n",
       "      <td>2021-08-29 08:05:00</td>\n",
       "      <td>270.595</td>\n",
       "      <td>1.902</td>\n",
       "      <td>-4.157</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>511 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Start_str              End_str  Clang_avg  Bx_avg(nT)  \\\n",
       "0    2021-06-01 01:05:00  2021-06-01 01:15:00    244.331       0.613   \n",
       "1    2021-06-01 01:35:00  2021-06-01 01:45:00    245.989      -0.053   \n",
       "2    2021-06-01 04:25:00  2021-06-01 04:35:00    256.041       1.367   \n",
       "3    2021-06-01 08:55:00  2021-06-01 09:05:00    245.306      -0.295   \n",
       "4    2021-06-01 09:25:00  2021-06-01 09:35:00    242.842      -0.210   \n",
       "..                   ...                  ...        ...         ...   \n",
       "506  2021-08-28 13:30:00  2021-08-28 13:40:00    112.512      -1.648   \n",
       "507  2021-08-28 14:00:00  2021-08-28 14:10:00     98.548      -1.555   \n",
       "508  2021-08-28 14:30:00  2021-08-28 14:40:00     95.961      -1.477   \n",
       "509  2021-08-28 15:00:00  2021-08-28 15:10:00     88.390      -1.380   \n",
       "510  2021-08-29 07:55:00  2021-08-29 08:05:00    270.595       1.902   \n",
       "\n",
       "     By_avg(nT)  Bz_avg(nT)  \n",
       "0        -2.403      -1.138  \n",
       "1        -2.787      -1.243  \n",
       "2        -2.745      -0.673  \n",
       "3        -1.075      -0.493  \n",
       "4        -1.133      -0.583  \n",
       "..          ...         ...  \n",
       "506       7.038      -2.913  \n",
       "507       7.318      -1.103  \n",
       "508       7.087      -0.740  \n",
       "509       6.535       0.192  \n",
       "510      -4.157       0.030  \n",
       "\n",
       "[511 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def single_convert_strlist_to_unix(df_yr1):\n",
    "    \"\"\"Converting string end-date arrays from Yearly IMF DFs back to unix time\"\"\"\n",
    "    #extracting string end-date arrays from Yearly Dataframes\n",
    "    endstr_yr1 = df_yr1['End_str'].to_numpy(copy=True)\n",
    "    #converting end-date string arrays to unix time\n",
    "    endyr1_unix = time_double(endstr_yr1)\n",
    "    return(endstr_yr1, endyr1_unix);\n",
    "\n",
    "def single_extract_clang(df_yr1):\n",
    "    \"\"\"Extract copies of avg IMF Clock Angle arrays from Yearly DFs\"\"\"\n",
    "    #extracting avg Clang arrays from Yearly Dataframes\n",
    "    clang_yr1 = df_yr1['Clang_avg'].to_numpy(copy=True)\n",
    "    return(clang_yr1)\n",
    "\n",
    "def single_extract_bx(df_yr1):\n",
    "    \"\"\"Extract copies of avg IMF Bx arrays from Yearly DFs\"\"\"\n",
    "    #extracting avg Clang arrays from Yearly Dataframes\n",
    "    bx_yr1 = df_yr1['Bx_avg(nT)'].to_numpy(copy=True)\n",
    "    return(bx_yr1)\n",
    "\n",
    "def single_extract_by(df_yr1):\n",
    "    \"\"\"Extract copies of avg IMF By arrays from Yearly DFs\"\"\"\n",
    "    #extracting avg Clang arrays from Yearly Dataframes\n",
    "    by_yr1 = df_yr1['By_avg(nT)'].to_numpy(copy=True)\n",
    "    return(by_yr1)\n",
    "\n",
    "def single_extract_bz(df_yr1):\n",
    "    \"\"\"Extract copies of avg IMF Bz arrays from Yearly DFs\"\"\"\n",
    "    #extracting avg Clang arrays from Yearly Dataframes\n",
    "    bz_yr1 = df_yr1['Bz_avg(nT)'].to_numpy(copy=True)\n",
    "    return(bz_yr1)\n",
    "\n",
    "def single_extract_IMFList_params(df_yr1):\n",
    "    \"\"\"From YrX IMF DF extract array copies of: end-date string and unix time; avg IMF Clock Angle,\n",
    "    and avg IMF Bcomps\"\"\"\n",
    "    #extracting string end-date arrays from Yearly Dataframes\n",
    "    endstr_yr1 = df_yr1['End_str'].to_numpy(copy=True)\n",
    "    #converting end-date string arrays to unix time\n",
    "    endyr1_unix = time_double(endstr_yr1)\n",
    "    #extracting avg Clang arrays from Yearly Dataframes\n",
    "    clang_yr1 = df_yr1['Clang_avg'].to_numpy(copy=True)\n",
    "    #extracting avg IMF Bx,By, and Bz arrays \n",
    "    bx_yr1 = df_yr1['Bx_avg(nT)'].to_numpy(copy=True)\n",
    "    by_yr1 = df_yr1['By_avg(nT)'].to_numpy(copy=True)\n",
    "    bz_yr1 = df_yr1['Bz_avg(nT)'].to_numpy(copy=True)\n",
    "    return(endstr_yr1, endyr1_unix, clang_yr1, bx_yr1, by_yr1, bz_yr1);\n",
    "\n",
    "def compare_clang_V2(df_og, df_NOsl_10m):\n",
    "    \"\"\"Compare ClockAng column arrays between OG and Last10m DFs (should be the same)\"\"\"\n",
    "    clang_noslash = df_NOsl_10m['Clang_avg'].to_numpy(copy=True)\n",
    "    clang_og = df_og['Clang_avg'].to_numpy(copy=True)\n",
    "    print(len(clang_noslash), len(clang_og))\n",
    "    #print('OG and Last10 minute Dataframes clang_avg columns are the same: ', (clang_noslash == clang_og).all())\n",
    "    #print('CLang columns are the same: ',  np.allclose(clang_noslash,clang_og, equal_nan=True))\n",
    "    bx_nosl = df_NOsl_10m['Bx_avg(nT)'].to_numpy(copy=True)\n",
    "    by_nosl = df_NOsl_10m['By_avg(nT)'].to_numpy(copy=True)\n",
    "    bz_nosl = df_NOsl_10m['Bz_avg(nT)'].to_numpy(copy=True)\n",
    "    bx_og = df_og['Bx_avg(nT)'].to_numpy(copy=True)\n",
    "    by_og = df_og['By_avg(nT)'].to_numpy(copy=True)\n",
    "    bz_og = df_og['Bz_avg(nT)'].to_numpy(copy=True)\n",
    "    #print('\\tOG and Last10 minute DFs Bx, By, and Bz columns are the same: ', (bx_nosl == bx_og).all(),\n",
    "     #    (by_nosl == by_og).all(), (bz_nosl == bz_og).all())\n",
    "    #print('\\tBcomp columns are the same: ', np.allclose(bx_nosl,bx_og, equal_nan=True), np.allclose(by_nosl,by_og, equal_nan=True), \n",
    "     #      np.allclose(bz_nosl,bz_og, equal_nan=True))\n",
    "    #print('\\tAvg ratio and abs difference of OG and Last10m Clang_avg columns:', \n",
    "    #      np.average(clang_og/clang_noslash) ,np.average(np.abs(clang_og - clang_noslash)))\n",
    "    #Confirmed: the same for negBy\n",
    "\n",
    "def single_pd_extract_last10(df_yrX):\n",
    "    \"\"\"From the 30minute intervals of the inputted YrX <ClockAng> Stable IMF List, extract out the last 10min \n",
    "    of the timeframes for curlometer data calculations\"\"\"\n",
    "    print('\\nCreating Last10min Sublist from: ',namestr(df_yrX, globals()))\n",
    "    #Extracting string date-lists and unix time arrays from YrX Stable IMF DFs\n",
    "    #[endstr_yr1, endyr1_unix] = convert_strlist_to_unix(df_yrX)\n",
    "    #Extracting copies of avg ClockAng and IMF Bcomp arrays from YrX DFs\n",
    "    #clang_yr1 = extract_clang(df_yrX)\n",
    "    #bx_yr1 = extract_bx(df_yrX)\n",
    "    #by_yr1 = extract_by(df_yrX)\n",
    "    #bz_yr1 = extract_bz(df_yrX)\n",
    "    #extract string date-list, unix time array, avg ClockAng, and avg IMF Bcomp arrays from YrX DF\n",
    "    [endstr_yr1, endyr1_unix, clang_yr1, bx_yr1, by_yr1, bz_yr1] = single_extract_IMFList_params(df_yrX)    \n",
    "    # Extracting Yr1's last 10min from <ClockAng> 30min list\n",
    "    [df_SL10m_yr1, df_NOSL10m_yr1] = last10min_Stable(endyr1_unix, endstr_yr1, clang_yr1, bx_yr1, by_yr1, bz_yr1)\n",
    "       #Exporting yr1 last10min Filtered Data and comparing the exported/OG dataframe\n",
    "    #df_NOSL10m_yr1.to_csv('pdFile_NightNOSL_Yr7_last10m_trange_general.txt', sep = '\\t', index = False)\n",
    "    #df_imp_10min_yr1 = pd.read_csv('pdFile_NightNOSL_Yr7_last10m_trange_general.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_NOSL10m_yr1, df_imp_10min_yr1)\n",
    "    return(df_NOSL10m_yr1);\n",
    "\n",
    "#----------------------Fundamental Functions Above/Main Calling Below----------\n",
    "##---soBz--Extracting No-slash last10min dataframes \n",
    "'''\n",
    "print('Extracting SoBz last 10min sublists from Yr6(2020-21) DF, Theta:[135, 225)')\n",
    "#df_sBz_noslash10m_yr6 = single_pd_extract_last10(df_DaysoBz_yr6)\n",
    "    #Compare clang_avg columns and display Yr6 soBz NoSlash10m DF\n",
    "#compare_clang(df_DaysoBz_yr6, df_sBz_noslash10m_yr6)\n",
    "\n",
    "#df_sBz_noslash10m_yr6 = single_pd_extract_last10(df_NightsoBz_yr6)\n",
    "#compare_clang(df_NightsoBz_yr6, df_sBz_noslash10m_yr6)\n",
    "\n",
    "#df_sBz_noslash10m_yr7 = single_pd_extract_last10(df_NightsoBz_yr7)\n",
    "#compare_clang(df_NightsoBz_yr7, df_sBz_noslash10m_yr7)\n",
    "#display(df_sBz_noslash10m_yr7)\n",
    "''';\n",
    "\n",
    "\n",
    "##---norBz--Extracting No-slash last10min dataframes \n",
    "'''\n",
    "print('Extracting norBz last 10min sublists from Yr6(2020-21) DF, Theta:[315, 45)')\n",
    "#df_nBz_noslash10m_yr6 = single_pd_extract_last10(df_DaynorBz_yr6)\n",
    "    #Compare clang_avg columns and display Yr6 norBz NoSlash10m DF\n",
    "#compare_clang(df_DaynorBz_yr6, df_nBz_noslash10m_yr6)\n",
    "\n",
    "#df_nBz_noslash10m_yr6 = single_pd_extract_last10(df_NightnorBz_yr6)\n",
    "#compare_clang(df_NightnorBz_yr6, df_nBz_noslash10m_yr6)\n",
    "\n",
    "\n",
    "df_nBz_noslash10m_yr7 = single_pd_extract_last10(df_NightnorBz_yr7)\n",
    "compare_clang(df_NightnorBz_yr7, df_nBz_noslash10m_yr7)\n",
    "#display(df_nBz_noslash10m_yr7)\n",
    "''';\n",
    "\n",
    "##---posBy--Extracting No-slash last10min dataframes \n",
    "'''\n",
    "print('Extracting posBy last 10min sublists from Yr6(2020-21) DF, Theta:[45, 135)')\n",
    "#df_pBy_noslash10m_yr6 = single_pd_extract_last10(df_DayposBy_yr6)\n",
    "    #Compare clang_avg columns and display Yr6 posBy NoSlash10m DF\n",
    "#compare_clang(df_DayposBy_yr6, df_pBy_noslash10m_yr6)\n",
    "\n",
    "#df_pBy_noslash10m_yr6 = single_pd_extract_last10(df_NightposBy_yr6)\n",
    "#compare_clang(df_NightposBy_yr6, df_pBy_noslash10m_yr6)\n",
    "\n",
    "df_pBy_noslash10m_yr7 = single_pd_extract_last10(df_NightposBy_yr7)\n",
    "compare_clang(df_NightposBy_yr7, df_pBy_noslash10m_yr7)\n",
    "display(df_pBy_noslash10m_yr7)\n",
    "''';\n",
    "\n",
    "##---negBy--Extracting No-slash last10min dataframes \n",
    "'''\n",
    "print('Extracting negBy last 10min sublists from Yr6(2020-21) DF, Theta:[225, 315)')\n",
    "#df_nBy_noslash10m_yr6 = single_pd_extract_last10(df_DaynegBy_yr6)\n",
    "    #Compare clang_avg columns and display Yr6 negBy NoSlash10m DF\n",
    "#compare_clang(df_DaynegBy_yr6, df_nBy_noslash10m_yr6)\n",
    "\n",
    "#df_nBy_noslash10m_yr6 = single_pd_extract_last10(df_NightnegBy_yr6)\n",
    "#compare_clang(df_NightnegBy_yr6, df_nBy_noslash10m_yr6)\n",
    "\n",
    "df_nBy_noslash10m_yr7 = single_pd_extract_last10(df_NightnegBy_yr7)\n",
    "compare_clang(df_NightnegBy_yr7, df_nBy_noslash10m_yr7)\n",
    "display(df_nBy_noslash10m_yr7)\n",
    "''';\n",
    "\n",
    "##---General--Extracting No-slash last10min dataframes \n",
    "#'''\n",
    "print('Extracting General NonClangSort last 10min sublists from Yr6(2020-21) DF')\n",
    "#df_gen_noslash10m_yr6 = single_pd_extract_last10(df_Daystable_yr6)\n",
    "    #Compare clang_avg columns and display Yr6 posBy NoSlash10m DF\n",
    "#compare_clang(df_Daystable_yr6, df_gen_noslash10m_yr6)\n",
    "\n",
    "#df_gen_noslash10m_yr6 = single_pd_extract_last10(df_Nightstable_yr6)\n",
    "#compare_clang(df_Nightstable_yr6, df_gen_noslash10m_yr6)\n",
    "\n",
    "df_gen_noslash10m_yr7 = single_pd_extract_last10(df_Nightstable_yr7)\n",
    "compare_clang(df_Nightstable_yr7, df_gen_noslash10m_yr7)\n",
    "display(df_gen_noslash10m_yr7)\n",
    "#''';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8596ac6",
   "metadata": {},
   "source": [
    "* In observing start and endbdates in unix times. The number of digits between the start and endpoint for a 30minute interval is 1500pts. Meaning a 15minute interval *should* be about 750pts\n",
    "    * Results computed from Avg-For-Loop algorithm, <br>`fSum = fSum + (end_unix[i] - start_unix[i])` and confirmed by `unix_interval()` function\n",
    "    * **It's 900pts for a 15minute interval and 600pts for 10min** as confirmed with number adjusting\n",
    "    \n",
    "* Replacing a character within a string: https://stackoverflow.com/questions/12723751/replacing-instances-of-a-character-in-a-string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c671e9",
   "metadata": {},
   "source": [
    "### Section 1.a (SPECIAL)\n",
    "#### (9-26-2021)Creating/Exporting MEC position data DF that corresponds to whichever exported ClockAng CurrData DF\n",
    "* ALthough not useful in my context since I need both start and end-dates. Here's a quickhand way of creating sublist from a list, with a known array of desired indices \n",
    "    * https://stackoverflow.com/questions/22412509/getting-a-sublist-of-a-python-list-with-the-given-indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e325e6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rmag', 't', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "######### Acquiring corresponding dataframe for MEC position data #########\n",
    "\n",
    "print(sorted(yr5_MECposdata))\n",
    "#find index of current Bmag time(trim) element that corresponds to OG time array\n",
    "             #   mgs_in =  np.argwhere(ogtime == timetrim[n])\n",
    "#                    pos_avg = np.average(posmag[mgs_in[0,0]: mgs_in[0,0] +6]/R_e)\n",
    "\n",
    "\n",
    "def get_MEC_df(df_last10_noslash, yrX_MECposdata):\n",
    "    \"\"\"Create dataframe for MEC posdata using start-dates from last10m ClockAng Stable IMF Event Lists\"\"\"\n",
    "    #create empty dataframe with column names\n",
    "    df_MEC = pd.DataFrame(columns = ['Unix_start', 'Start_str','MECrmag_avg(Re)','MECx_avg(Re)',\n",
    "                                     'MECy_avg(Re)', 'MECz_avg(Re)','End_str'])\n",
    "    R_e = 6371 #km, Earth radius; as indicated by NRL Plasma Formularly\n",
    "    #Displaying/extracting copy of start-date column from last10min Stable IMF df\n",
    "    (display(df_last10_noslash))\n",
    "    last10_start = df_last10_noslash['Start_str'].to_numpy(copy=True)\n",
    "    #Extracting MEC radial position(km) and time(unix time) arrays\n",
    "    afMECtime = yrX_MECposdata['t']\n",
    "    afMECx = yrX_MECposdata['x']\n",
    "    afMECy = yrX_MECposdata['y']\n",
    "    afMECz = yrX_MECposdata['z']\n",
    "    afMEC_rmag = yrX_MECposdata['rmag']\n",
    "    print('\\nAnalyzing MEC data time frame:', time_string(afMECtime[1]),'->\\t', time_string(afMECtime[-1:]))\n",
    "    # Using loop to append rows to empty dataframe by finding index for corresponding MEC position data\n",
    "    count = 0 #initializing empty variable\n",
    "    achMECtime = (time_string(afMECtime))  #Convert MECtime to from unix to string dates \n",
    "    for i in range(len(last10_start)):\n",
    "        # Finding index of MECtime that corresponds to current last10_start element\n",
    "        ind = np.argwhere(time_double(last10_start[i]) == afMECtime)\n",
    "        # Defining variables for start/end-date and position(Re units)\n",
    "        startMEC = achMECtime[ind[0,0]]\n",
    "        endMEC = achMECtime[ind[0,0]+2] #MECtime array has 5min time cadence\n",
    "        rmag_avg = np.nanmean(afMEC_rmag[ind[0,0]: ind[0,0] +3]/R_e)\n",
    "        x_avg = np.nanmean(afMECx[ind[0,0]: ind[0,0] +3]/R_e)\n",
    "        y_avg = np.nanmean(afMECy[ind[0,0]: ind[0,0] +3]/R_e)\n",
    "        z_avg = np.nanmean(afMECz[ind[0,0]: ind[0,0] +3]/R_e)\n",
    "        #Appending rows to empty dataframes using a loop\n",
    "        if ( time_double(last10_start[i])==afMECtime[ind[0,0]] ):\n",
    "            count = count +1\n",
    "        #print(startMEC[:19])\n",
    "        #print('Element %d matches: '%(i), (time_double(last10_start[i])==afMECtime[ind[0,0]]))\n",
    "        if i < 1 or i > (len(last10_start)-2):\n",
    "            print('For element %d: '%(i), achMECtime[ind[0,0]: ind[0,0]+3], '\\n MECx(km):', afMECx[ind[0,0]: ind[0,0] +3])\n",
    "        df_MEC = df_MEC.append({'Unix_start': '%f'%(afMECtime[ind[0,0]]), 'Start_str': '%0.19s'%(startMEC),\n",
    "                                'MECrmag_avg(Re)': rmag_avg, 'MECx_avg(Re)': x_avg, 'MECy_avg(Re)': y_avg,\n",
    "                                'MECz_avg(Re)': z_avg, 'End_str': '%0.19s'%(endMEC)},ignore_index=True)\n",
    "    print('\\tWith a length of %d for last10_start, there were %d confirmed date matches with MECtime'%(len(last10_start), count))\n",
    "    display(df_MEC)    \n",
    "    return(df_MEC);\n",
    "\n",
    "\n",
    "def compare_mec_start_end(df_MECpos, df_last10m):\n",
    "#Compares columns for Start and End-dates between MEC and last10m dataframe. They should be the same\n",
    "    end_last10 = df_last10m['End_str'].to_numpy(copy=True)\n",
    "    MECend = df_MECpos['End_str'].to_numpy(copy=True)\n",
    "    MECstart = df_MECpos['Start_str'].to_numpy(copy=True)\n",
    "    start_last10 = df_last10m['Start_str'].to_numpy(copy=True)\n",
    "    print('MEC and Last10 minute Dataframes end-date columns are the same: ', (end_last10 == MECend).all())\n",
    "    print('MEC and Last10 minute Dataframes start-date columns are the same: ', (start_last10 == MECstart).all())\n",
    "    return;\n",
    "\n",
    "def checkin_MEC_dfs(df_NSL10_yr1, df_NSL10_yr2, df_NSL10_yr3, df_NSL10_yr4, df_NSL10_yr5):\n",
    "    \"\"\"Checking newly made MEC position dataframes by ensuring date column arrays match last10m Stable List. \n",
    "    Then compare the exported/imported dataframes\"\"\"\n",
    "    print('Inputs which are used to create MEC DFs:\\n', namestr(df_NSL10_yr1, globals()),\n",
    "          namestr(df_NSL10_yr2, globals()),namestr(df_NSL10_yr3, globals()), '\\n', \n",
    "          namestr(df_NSL10_yr4, globals()), namestr(df_NSL10_yr5, globals()))\n",
    "    \n",
    "    #Exporting yr1 MEC posdata for each last10min interval and comparing the exported/OG dataframe\n",
    "    #df_MECpos_yr1 = get_MEC_df(df_NSL10_yr1, yr1_MECposdata)\n",
    "    #compare_mec_start_end(df_MECpos_yr1, df_NSL10_yr1)\n",
    "    #df_MECpos_yr1.to_csv('pdFile_MECcurmatch_last10m_norBzdom_Yr1.txt', sep = '\\t', index = False)\n",
    "    #df_imp_MECpos_yr1 = pd.read_csv('pdFile_MECcurmatch_last10m_norBzdom_Yr1.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_MECpos_yr1, df_imp_MECpos_yr1)\n",
    "    \n",
    "    #Exporting yr2 MEC posdata for each last10min interval and comparing the exported/OG dataframe\n",
    "    #df_MECpos_yr2 = get_MEC_df(df_NSL10_yr2, yr2_MECposdata)\n",
    "    #compare_mec_start_end(df_MECpos_yr2, df_NSL10_yr2)\n",
    "    #For yr2_currdata(and mecdata): dropping NoData row\n",
    "    #df_mec_y2 = df_MECpos_yr2.drop([105]) #yr2 norBz drop\n",
    "    #df_mec_y2 = df_mec_y2.reset_index(drop=True)\n",
    "    '''\n",
    "    For norBz yr2_currdata\n",
    "    #df_curr = df_currdata.drop([105]) #yr2 norBz drop\n",
    "    \n",
    "    \n",
    "    #For posBy yr2_currdata(and mecdata): dropping NoData row\n",
    "    #df_mec_y2 = df_MECpos_yr2.drop([481, 482, 483, 484, 485, 486, 487, 488, 489, 490])# yr2 posBy drop\n",
    "    \n",
    "    #For negBy yr2_currdata(and mec data): dropping NoData row\n",
    "    #df_mec_y2 = df_MECpos_yr2.drop([234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244])# yr2 negBy drop\n",
    "    #df_mec_y2 = df_mec_y2.reset_index(drop=True)\n",
    "    \n",
    "    #matching to yr2 soBz current df\n",
    "    #df_mec2_yr2 = df_MECpos_yr2.drop([189, 190, 191, 192, 193, 194, 195]) #dropping NoData row for Yr2\n",
    "    #df_mec2_yr2 = df_mec2_yr2.reset_index(drop = True) #reset index# column for new DF\n",
    "    #print('\\n New drop DF')\n",
    "    #display(df_mec2_yr2)\n",
    "    '''\n",
    "    #df_mec_y2.to_csv('pdFile_MECcurmatch_last10m_norBzdom_Yr2.txt', sep = '\\t', index = False)\n",
    "    #df_imp_MECpos_yr2 = pd.read_csv('pdFile_MECcurmatch_last10m_norBzdom_Yr2.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_mec_y2, df_imp_MECpos_yr2)\n",
    "\n",
    "    #Exporting yr3 MEC posdata for each last10min interval and comparing the exported/OG dataframe\n",
    "    #df_MECpos_yr3 = get_MEC_df(df_NSL10_yr3, yr3_MECposdata)\n",
    "    #compare_mec_start_end(df_MECpos_yr3, df_NSL10_yr3)\n",
    "    #For yr3_currdata(and mecdata): dropping NoData row\n",
    "    #df_mec_y3 = df_MECpos_yr3.drop([113,114,115,272]) #yr3 norBz drop\n",
    "    #df_mec_y3 = df_mec_y3.reset_index(drop = True) #reset index# column for new DF\n",
    "    \n",
    "    '''\n",
    "    For norBz yr3_currdata\n",
    "      #df_curr = df_currdata([113,114,115,272]) #yr3 norBz drop\n",
    "    \n",
    "    #For posBy yr3_currdata(and mecdata): dropping NoData row\n",
    "    #df_mec_y3 = df_MECpos_yr3.drop([689, 690, 691, 692, 693, 694, 695, 696])# yr3 posBy drop\n",
    "    \n",
    "    #matching to soBz yr3 current df\n",
    "    #df_mec2_yr3 = df_MECpos_yr3.drop([393, 394]) #dropping NoData row for Yr3\n",
    "    #df_mec2_yr3 = df_mec2_yr3.reset_index(drop = True) #reset index# column for new DF\n",
    "    #print('\\n New Drop DF')\n",
    "    #display(df_mec2_yr3)\n",
    "    '''\n",
    "    #df_mec_y3.to_csv('pdFile_MECcurmatch_last10m_norBzdom_Yr3.txt', sep = '\\t', index = False)\n",
    "    #df_imp_MECpos_yr3 = pd.read_csv('pdFile_MECcurmatch_last10m_norBzdom_Yr3.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_mec_y3, df_imp_MECpos_yr3)\n",
    "\n",
    "    #Exporting yr4 MEC posdata for each last10min interval and comparing the exported/OG dataframe\n",
    "    #df_MECpos_yr4 = get_MEC_df(df_NSL10_yr4, yr4_MECposdata)\n",
    "    #compare_mec_start_end(df_MECpos_yr4, df_NSL10_yr4)\n",
    "    ''' \n",
    "    #For negBy yr4_currdata(and mecdata): dropping NoData row\n",
    "    #df_mec_yr4 = df_MECpos_yr4.drop([896]) #yr4 negBy drop\n",
    "    #df_mec_yr4 = df_mec_yr4.reset_index(drop = True) #reset index# column for new DF\n",
    "    ''';\n",
    "    #df_MECpos_yr4.to_csv('pdFile_MECcurmatch_last10m_norBzdom_Yr4.txt', sep = '\\t', index = False)\n",
    "    #df_imp_MECpos_yr4 = pd.read_csv('pdFile_MECcurmatch_last10m_norBzdom_Yr4.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_MECpos_yr4, df_imp_MECpos_yr4)\n",
    "\n",
    "    #Exporting yr5 MEC posdata for each last10min interval and comparing the exported/OG dataframe\n",
    "    #df_MECpos_noMECgap_yr5 = get_MEC_df(df_NSL10_yr5, yr5_MECposdata)\n",
    "    #compare_mec_start_end(df_MECpos_noMECgap_yr5, df_NSL10_yr5)\n",
    "    #For yr5_currdata(and mecdata): dropping NoData Row\n",
    "    #df_mec_yr5 = df_MECpos_noMECgap_yr5.drop([131]) # yr5 norBz drop\n",
    "    #df_mec_yr5 = df_mec_yr5.reset_index(drop = True) #reset index# column for new DF\n",
    "\n",
    "    '''\n",
    "    For norBz yr5_currdata\n",
    "    #df_curr = df_currdata.drop([131]) #yr5 norBz drop\n",
    "    \n",
    "      #For posBy yr5_currdata(and mecdata): dropping NoData Row\n",
    "    #df_mec_yr5 = df_MECpos_noMECgap.drop([251, 252, 253]) # yr5 posBy drop\n",
    "    \n",
    "    #For negBy yr5_currdata(and mecdata): dropping NoData row\n",
    "    df_mec_yr5 = df_MECpos_noMECgap_yr5.drop([232]) #yr5 negBy drop\n",
    "    df_mec_yr5 = df_mec_yr5.reset_index(drop = True) #reset index# column for new DF\n",
    "    ''';\n",
    "    #df_mec_yr5.to_csv('pdFile_MECcurmatch_last10m_noGAP_norBzdom_Yr5.txt', sep = '\\t', index = False)\n",
    "    #df_imp_MECpos_yr5 = pd.read_csv('pdFile_MECcurmatch_last10m_noGAP_norBzdom_Yr5.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_mec_yr5, df_imp_MECpos_yr5)\n",
    "   \n",
    "\n",
    "    return;\n",
    "\n",
    "#Creating corresponding MECpos DFs for negBy CurrPeak Data\n",
    "#checkin_MEC_dfs( df_nBy_noslash10m_yr1,  df_nBy_noslash10m_yr2,  df_nBy_noslash10m_yr3, \n",
    "#     df_nBy_noslash10m_yr4,  df_nBy_noslash10m_yr5)\n",
    "\n",
    "\n",
    "#Creating corresponding MECpos DFs for posBy CurrPeak Data\n",
    "#checkin_MEC_dfs( df_pBy_noslash10m_yr1,  df_pBy_noslash10m_yr2,  df_pBy_noslash10m_yr3, \n",
    " #    df_pBy_noslash10m_yr4,  df_pBy_noslash10m_yr5)\n",
    "\n",
    "\n",
    "#Creating corresponding MECpos DFs for norBz CurrPeak Data\n",
    "#checkin_MEC_dfs( df_noBz_noslash10m_yr1,  df_noBz_noslash10m_yr2,  df_noBz_noslash10m_yr3, \n",
    "#     df_noBz_noslash10m_yr4,  df_noBz_noslash10m_yr5)\n",
    "\n",
    "\n",
    "def checkin_MEC_dfs_NOalter(df_NSL10_yr1, df_NSL10_yr2, df_NSL10_yr3, df_NSL10_yr4, df_NSL10_yr5):\n",
    "    \"\"\"Checking newly made MEC position dataframes by ensuring date column arrays matches the\n",
    "    General last10m Stable List. Then compare the exported/imported dataframes\"\"\"\n",
    "    print('*General* Inputs which are used to create MEC DFs:\\n', namestr(df_NSL10_yr1, globals()),\n",
    "          namestr(df_NSL10_yr2, globals()),namestr(df_NSL10_yr3, globals()), '\\n', \n",
    "          namestr(df_NSL10_yr4, globals()), namestr(df_NSL10_yr5, globals()))\n",
    "    \n",
    "    #Exporting yr1 MEC posdata for each last10min interval and comparing the exported/OG dataframe\n",
    "    #df_MECpos_yr1 = get_MEC_df(df_NSL10_yr1, yr1_MECposdata)\n",
    "    #compare_mec_start_end(df_MECpos_yr1, df_NSL10_yr1)\n",
    "    #df_MECpos_yr1.to_csv('pdFile_MECmatch_last10m_general_Yr1.txt', sep = '\\t', index = False)\n",
    "    #df_imp_MECpos_yr1 = pd.read_csv('pdFile_MECmatch_last10m_general_Yr1.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_MECpos_yr1, df_imp_MECpos_yr1)\n",
    "    \n",
    "     #Exporting yr2 MEC posdata for each last10min interval and comparing the exported/OG dataframe\n",
    "    #df_MECpos_yr2 = get_MEC_df(df_NSL10_yr2, yr2_MECposdata)\n",
    "    #compare_mec_start_end(df_MECpos_yr2, df_NSL10_yr2)\n",
    "    #df_MECpos_yr2.to_csv('pdFile_MECmatch_last10m_general_Yr2.txt', sep = '\\t', index = False)\n",
    "    #df_imp_MECpos_yr2 = pd.read_csv('pdFile_MECmatch_last10m_general_Yr2.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_MECpos_yr2, df_imp_MECpos_yr2)\n",
    "    \n",
    "     #Exporting yr3 MEC posdata for each last10min interval and comparing the exported/OG dataframe\n",
    "    #df_MECpos_yr3 = get_MEC_df(df_NSL10_yr3, yr3_MECposdata)\n",
    "    #compare_mec_start_end(df_MECpos_yr3, df_NSL10_yr3)\n",
    "    #df_MECpos_yr3.to_csv('pdFile_MECmatch_last10m_general_Yr3.txt', sep = '\\t', index = False)\n",
    "    #df_imp_MECpos_yr3 = pd.read_csv('pdFile_MECmatch_last10m_general_Yr3.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_MECpos_yr3, df_imp_MECpos_yr3)\n",
    "    \n",
    "     #Exporting yr4 MEC posdata for each last10min interval and comparing the exported/OG dataframe\n",
    "    #df_MECpos_yr4 = get_MEC_df(df_NSL10_yr4, yr4_MECposdata)\n",
    "    #compare_mec_start_end(df_MECpos_yr4, df_NSL10_yr4)\n",
    "    #df_MECpos_yr4.to_csv('pdFile_MECmatch_last10m_general_Yr4.txt', sep = '\\t', index = False)\n",
    "    #df_imp_MECpos_yr4 = pd.read_csv('pdFile_MECmatch_last10m_general_Yr4.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_MECpos_yr4, df_imp_MECpos_yr4)\n",
    "    \n",
    "    \n",
    "     #Exporting yr5 MEC posdata for each last10min interval and comparing the exported/OG dataframe\n",
    "    #df_MECpos_yr5 = get_MEC_df(df_NSL10_yr5, yr5_MECposdata)\n",
    "    #compare_mec_start_end(df_MECpos_yr5, df_NSL10_yr5)\n",
    "    #df_MECpos_yr5.to_csv('pdFile_MECmatch_last10m_noGAP_general_Yr5.txt', sep = '\\t', index = False)\n",
    "    #df_imp_MECpos_yr5 = pd.read_csv('pdFile_MECmatch_last10m_noGAP_general_Yr5.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_MECpos_yr5, df_imp_MECpos_yr5)\n",
    "  \n",
    "\n",
    "    return;\n",
    "\n",
    "#Creating corresponding MECpos DFs from general Yrly Stable Lists\n",
    "#checkin_MEC_dfs_NOalter( df_gen_noslash10m_yr1,  df_gen_noslash10m_yr2,  df_gen_noslash10m_yr3, \n",
    "#     df_gen_noslash10m_yr4,  df_gen_noslash10m_yr5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28ca839",
   "metadata": {},
   "source": [
    "* (11-23-2021) Comments on how to match tranges of MEC DF's onto their corresponding Current DF:\n",
    "~~~\n",
    "    matching to yr2 soBz current df\n",
    "    #df_mec2_yr2 = df_MECpos_yr2.drop([189, 190, 191, 192, 193, 194, 195]) #dropping NoData row for Yr2\n",
    "    #df_mec2_yr2 = df_mec2_yr2.reset_index(drop = True) #reset index# column for new DF\n",
    "    #print('\\n New drop DF')\n",
    "    #display(df_mec2_yr2)\n",
    "\n",
    "    matching to soBz yr3 current df\n",
    "    #df_mec2_yr3 = df_MECpos_yr3.drop([393, 394]) #dropping NoData row for Yr3\n",
    "    #df_mec2_yr3 = df_mec2_yr3.reset_index(drop = True) #reset index# column for new DF\n",
    "    #print('\\n New Drop DF')\n",
    "    #display(df_mec2_yr3)\n",
    "~~~\n",
    "* From CurrentDF Export cell, *Comments about which tranges to drop for each Clockang Current Dataframe:*\n",
    "~~~\n",
    "'''\n",
    "    For norBz yr5_currdata\n",
    "    #df_curr = df_currdata.drop([131]) #yr5 norBz drop\n",
    "      DropList index: [131.]\n",
    "      ['2020-02-10/20:15:00', '2020-02-10/20:25:00']\n",
    "\n",
    "    For norBz yr3_currdata\n",
    "    #df_curr = df_currdata([113,114,115,272]) #yr3 norBz drop\n",
    "        DropList index: [113. 114. 115. 272.]\n",
    "        ['2018-05-27/04:50:00', '2018-05-27/05:00:00']\n",
    "        ['2018-05-27/05:20:00', '2018-05-27/05:30:00']\n",
    "        ['2018-05-27/21:40:00', '2018-05-27/21:50:00']\n",
    "        ['2018-05-27/22:30:00', '2018-05-27/22:40:00']\n",
    "\n",
    "\n",
    "\n",
    "    For norBz yr2_currdata\n",
    "    #df_curr = df_currdata.drop([105]) #yr2 norBz drop\n",
    "        DropList index: [105.]\n",
    "        ['2017-01-04/16:40:00', '2017-01-04/16:50:00']\n",
    "\n",
    "\n",
    "    For posBy yr5_currdata\n",
    "    #df_curr = df_currdata.drop([251, 252, 253]) # yr5 posBy drop\n",
    "        DropList index: [251. 252. 253.]\n",
    "\n",
    "    For posBy yr3_currdata\n",
    "    #df_curr = df_currdata.drop([689, 690, 691, 692, 693, 694, 695, 696])# yr3 posBy drop\n",
    "        DropList index: [689. 690. 691. 692. 693. 694. 695. 696.]\n",
    "\n",
    "\n",
    "    For posBy yr2_currdata\n",
    "    #df_curr = df_currdata.drop([481, 482, 483, 484, 485, 486, 487, 488, 489, 490])# yr2 posBy drop\n",
    "\n",
    "\n",
    "    For negBy yr5_currdata\n",
    "    #df_curr = df_currdata.drop([232]) #yr5 negBy drop\n",
    "        DropList index: [232.]\n",
    "        ['2020-02-10/17:40:00', '2020-02-10/17:50:00']\n",
    "    \n",
    "    For negBy yr4_currdata\n",
    "    #df_curr = df_currdata.drop([896]) #yr4 negBy drop\n",
    "    \n",
    "    For negBy yr2_currdata\n",
    "    #df_curr = df_currdata.drop([234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244])# yr2 negBy drop\n",
    "    #df_curr = df_curr.reset_index(drop=True)\n",
    "    \n",
    "    For SoBz yr2_currData\n",
    "    #df_curr2_yr2 = df_currdata_yr2.drop([189, 190, 191, 192, 193, 194, 195]) #dropping NoData row for Yr2\n",
    "    #df_curr2_yr2 = df_curr2_yr2.reset_index(drop = True) #reset index# column for new DF\n",
    "    \n",
    "    For SoBz yr3_currData\n",
    "    #df_curr2_yr3 = df_currdata_yr3.drop([393, 394]) #dropping NoData row for Yr3\n",
    "    #df_curr2_yr3 = df_curr2_yr3.reset_index(drop = True) #reset index# column for new DF\n",
    "''';\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e75852",
   "metadata": {},
   "source": [
    "### Section 1.2:\n",
    "* Re-Importing trange syntax appropriate last10min Stable IMF dataframes and converting said dataframes into suitable trange tuples for looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e7a43d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-imported posBy Stable tranges\n",
      "Re-imported negBy Stable tranges\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_trang</th>\n",
       "      <th>End_trang</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-09-01/00:25:00</td>\n",
       "      <td>2015-09-01/00:35:00</td>\n",
       "      <td>270.271</td>\n",
       "      <td>3.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-09-01/08:55:00</td>\n",
       "      <td>2015-09-01/09:05:00</td>\n",
       "      <td>284.483</td>\n",
       "      <td>1.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-09-01/10:50:00</td>\n",
       "      <td>2015-09-01/11:00:00</td>\n",
       "      <td>260.121</td>\n",
       "      <td>3.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-09-01/12:45:00</td>\n",
       "      <td>2015-09-01/12:55:00</td>\n",
       "      <td>299.448</td>\n",
       "      <td>3.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-09-01/19:30:00</td>\n",
       "      <td>2015-09-01/19:40:00</td>\n",
       "      <td>251.441</td>\n",
       "      <td>3.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>2016-05-30/09:20:00</td>\n",
       "      <td>2016-05-30/09:30:00</td>\n",
       "      <td>271.550</td>\n",
       "      <td>2.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>2016-05-30/09:50:00</td>\n",
       "      <td>2016-05-30/10:00:00</td>\n",
       "      <td>275.711</td>\n",
       "      <td>3.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>2016-05-30/10:20:00</td>\n",
       "      <td>2016-05-30/10:30:00</td>\n",
       "      <td>267.143</td>\n",
       "      <td>3.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>2016-05-30/13:20:00</td>\n",
       "      <td>2016-05-30/13:30:00</td>\n",
       "      <td>266.897</td>\n",
       "      <td>3.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>2016-05-30/14:30:00</td>\n",
       "      <td>2016-05-30/14:40:00</td>\n",
       "      <td>271.308</td>\n",
       "      <td>3.652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>665 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Start_trang            End_trang  Clang_avg  Bx_avg(nT)\n",
       "0    2015-09-01/00:25:00  2015-09-01/00:35:00    270.271       3.502\n",
       "1    2015-09-01/08:55:00  2015-09-01/09:05:00    284.483       1.962\n",
       "2    2015-09-01/10:50:00  2015-09-01/11:00:00    260.121       3.143\n",
       "3    2015-09-01/12:45:00  2015-09-01/12:55:00    299.448       3.513\n",
       "4    2015-09-01/19:30:00  2015-09-01/19:40:00    251.441       3.822\n",
       "..                   ...                  ...        ...         ...\n",
       "660  2016-05-30/09:20:00  2016-05-30/09:30:00    271.550       2.197\n",
       "661  2016-05-30/09:50:00  2016-05-30/10:00:00    275.711       3.940\n",
       "662  2016-05-30/10:20:00  2016-05-30/10:30:00    267.143       3.412\n",
       "663  2016-05-30/13:20:00  2016-05-30/13:30:00    266.897       3.228\n",
       "664  2016-05-30/14:30:00  2016-05-30/14:40:00    271.308       3.652\n",
       "\n",
       "[665 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_trang</th>\n",
       "      <th>End_trang</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-08/16:15:00</td>\n",
       "      <td>2016-09-08/16:25:00</td>\n",
       "      <td>254.787</td>\n",
       "      <td>-1.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-11/22:30:00</td>\n",
       "      <td>2016-09-11/22:40:00</td>\n",
       "      <td>240.055</td>\n",
       "      <td>-2.332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-11/23:00:00</td>\n",
       "      <td>2016-09-11/23:10:00</td>\n",
       "      <td>237.653</td>\n",
       "      <td>-4.373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-16/13:55:00</td>\n",
       "      <td>2016-09-16/14:05:00</td>\n",
       "      <td>305.148</td>\n",
       "      <td>2.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-17/17:40:00</td>\n",
       "      <td>2016-09-17/17:50:00</td>\n",
       "      <td>302.025</td>\n",
       "      <td>2.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>2017-05-27/10:45:00</td>\n",
       "      <td>2017-05-27/10:55:00</td>\n",
       "      <td>274.884</td>\n",
       "      <td>-0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>2017-05-27/11:15:00</td>\n",
       "      <td>2017-05-27/11:25:00</td>\n",
       "      <td>278.537</td>\n",
       "      <td>-0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>2017-05-27/11:45:00</td>\n",
       "      <td>2017-05-27/11:55:00</td>\n",
       "      <td>268.346</td>\n",
       "      <td>0.222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>2017-05-27/14:30:00</td>\n",
       "      <td>2017-05-27/14:40:00</td>\n",
       "      <td>264.697</td>\n",
       "      <td>-1.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>2017-05-30/07:40:00</td>\n",
       "      <td>2017-05-30/07:50:00</td>\n",
       "      <td>285.066</td>\n",
       "      <td>3.578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>613 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Start_trang            End_trang  Clang_avg  Bx_avg(nT)\n",
       "0    2016-09-08/16:15:00  2016-09-08/16:25:00    254.787      -1.043\n",
       "1    2016-09-11/22:30:00  2016-09-11/22:40:00    240.055      -2.332\n",
       "2    2016-09-11/23:00:00  2016-09-11/23:10:00    237.653      -4.373\n",
       "3    2016-09-16/13:55:00  2016-09-16/14:05:00    305.148       2.902\n",
       "4    2016-09-17/17:40:00  2016-09-17/17:50:00    302.025       2.752\n",
       "..                   ...                  ...        ...         ...\n",
       "608  2017-05-27/10:45:00  2017-05-27/10:55:00    274.884      -0.223\n",
       "609  2017-05-27/11:15:00  2017-05-27/11:25:00    278.537      -0.262\n",
       "610  2017-05-27/11:45:00  2017-05-27/11:55:00    268.346       0.222\n",
       "611  2017-05-27/14:30:00  2017-05-27/14:40:00    264.697      -1.552\n",
       "612  2017-05-30/07:40:00  2017-05-30/07:50:00    285.066       3.578\n",
       "\n",
       "[613 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_trang</th>\n",
       "      <th>End_trang</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-01/18:50:00</td>\n",
       "      <td>2017-09-01/19:00:00</td>\n",
       "      <td>311.273</td>\n",
       "      <td>-4.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-01/20:45:00</td>\n",
       "      <td>2017-09-01/20:55:00</td>\n",
       "      <td>279.942</td>\n",
       "      <td>-5.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-01/22:40:00</td>\n",
       "      <td>2017-09-01/22:50:00</td>\n",
       "      <td>310.823</td>\n",
       "      <td>-5.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-03/05:45:00</td>\n",
       "      <td>2017-09-03/05:55:00</td>\n",
       "      <td>309.260</td>\n",
       "      <td>-3.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-09-06/23:00:00</td>\n",
       "      <td>2017-09-06/23:10:00</td>\n",
       "      <td>295.288</td>\n",
       "      <td>-0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>2018-05-22/14:30:00</td>\n",
       "      <td>2018-05-22/14:40:00</td>\n",
       "      <td>265.307</td>\n",
       "      <td>4.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>2018-05-22/15:00:00</td>\n",
       "      <td>2018-05-22/15:10:00</td>\n",
       "      <td>265.247</td>\n",
       "      <td>4.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>2018-05-22/16:30:00</td>\n",
       "      <td>2018-05-22/16:40:00</td>\n",
       "      <td>271.157</td>\n",
       "      <td>4.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>2018-05-24/17:50:00</td>\n",
       "      <td>2018-05-24/18:00:00</td>\n",
       "      <td>263.469</td>\n",
       "      <td>-3.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>2018-05-29/19:30:00</td>\n",
       "      <td>2018-05-29/19:40:00</td>\n",
       "      <td>262.345</td>\n",
       "      <td>2.843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>822 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Start_trang            End_trang  Clang_avg  Bx_avg(nT)\n",
       "0    2017-09-01/18:50:00  2017-09-01/19:00:00    311.273      -4.432\n",
       "1    2017-09-01/20:45:00  2017-09-01/20:55:00    279.942      -5.642\n",
       "2    2017-09-01/22:40:00  2017-09-01/22:50:00    310.823      -5.735\n",
       "3    2017-09-03/05:45:00  2017-09-03/05:55:00    309.260      -3.452\n",
       "4    2017-09-06/23:00:00  2017-09-06/23:10:00    295.288      -0.320\n",
       "..                   ...                  ...        ...         ...\n",
       "817  2018-05-22/14:30:00  2018-05-22/14:40:00    265.307       4.483\n",
       "818  2018-05-22/15:00:00  2018-05-22/15:10:00    265.247       4.557\n",
       "819  2018-05-22/16:30:00  2018-05-22/16:40:00    271.157       4.250\n",
       "820  2018-05-24/17:50:00  2018-05-24/18:00:00    263.469      -3.033\n",
       "821  2018-05-29/19:30:00  2018-05-29/19:40:00    262.345       2.843\n",
       "\n",
       "[822 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_trang</th>\n",
       "      <th>End_trang</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-01/01:35:00</td>\n",
       "      <td>2018-09-01/01:45:00</td>\n",
       "      <td>284.177</td>\n",
       "      <td>-3.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-01/04:00:00</td>\n",
       "      <td>2018-09-01/04:10:00</td>\n",
       "      <td>312.375</td>\n",
       "      <td>-2.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-02/09:15:00</td>\n",
       "      <td>2018-09-02/09:25:00</td>\n",
       "      <td>308.625</td>\n",
       "      <td>1.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-02/09:45:00</td>\n",
       "      <td>2018-09-02/09:55:00</td>\n",
       "      <td>313.785</td>\n",
       "      <td>1.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-02/11:45:00</td>\n",
       "      <td>2018-09-02/11:55:00</td>\n",
       "      <td>302.135</td>\n",
       "      <td>1.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>2019-05-24/12:55:00</td>\n",
       "      <td>2019-05-24/13:05:00</td>\n",
       "      <td>278.693</td>\n",
       "      <td>1.618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>2019-05-24/13:25:00</td>\n",
       "      <td>2019-05-24/13:35:00</td>\n",
       "      <td>265.719</td>\n",
       "      <td>1.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2019-05-28/16:10:00</td>\n",
       "      <td>2019-05-28/16:20:00</td>\n",
       "      <td>299.266</td>\n",
       "      <td>0.162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>2019-05-28/20:45:00</td>\n",
       "      <td>2019-05-28/20:55:00</td>\n",
       "      <td>236.574</td>\n",
       "      <td>5.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>2019-05-29/05:20:00</td>\n",
       "      <td>2019-05-29/05:30:00</td>\n",
       "      <td>227.371</td>\n",
       "      <td>3.018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>897 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Start_trang            End_trang  Clang_avg  Bx_avg(nT)\n",
       "0    2018-09-01/01:35:00  2018-09-01/01:45:00    284.177      -3.255\n",
       "1    2018-09-01/04:00:00  2018-09-01/04:10:00    312.375      -2.530\n",
       "2    2018-09-02/09:15:00  2018-09-02/09:25:00    308.625       1.515\n",
       "3    2018-09-02/09:45:00  2018-09-02/09:55:00    313.785       1.790\n",
       "4    2018-09-02/11:45:00  2018-09-02/11:55:00    302.135       1.747\n",
       "..                   ...                  ...        ...         ...\n",
       "892  2019-05-24/12:55:00  2019-05-24/13:05:00    278.693       1.618\n",
       "893  2019-05-24/13:25:00  2019-05-24/13:35:00    265.719       1.315\n",
       "894  2019-05-28/16:10:00  2019-05-28/16:20:00    299.266       0.162\n",
       "895  2019-05-28/20:45:00  2019-05-28/20:55:00    236.574       5.833\n",
       "896  2019-05-29/05:20:00  2019-05-29/05:30:00    227.371       3.018\n",
       "\n",
       "[897 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_trang</th>\n",
       "      <th>End_trang</th>\n",
       "      <th>Clang_avg</th>\n",
       "      <th>Bx_avg(nT)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-17/07:30:00</td>\n",
       "      <td>2019-09-17/07:40:00</td>\n",
       "      <td>284.799</td>\n",
       "      <td>-0.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-17/15:15:00</td>\n",
       "      <td>2019-09-17/15:25:00</td>\n",
       "      <td>294.556</td>\n",
       "      <td>2.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-17/15:45:00</td>\n",
       "      <td>2019-09-17/15:55:00</td>\n",
       "      <td>294.403</td>\n",
       "      <td>2.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-17/16:40:00</td>\n",
       "      <td>2019-09-17/16:50:00</td>\n",
       "      <td>235.839</td>\n",
       "      <td>3.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-09-20/09:50:00</td>\n",
       "      <td>2019-09-20/10:00:00</td>\n",
       "      <td>251.279</td>\n",
       "      <td>-1.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>2020-05-30/10:50:00</td>\n",
       "      <td>2020-05-30/11:00:00</td>\n",
       "      <td>267.097</td>\n",
       "      <td>5.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>2020-05-30/11:20:00</td>\n",
       "      <td>2020-05-30/11:30:00</td>\n",
       "      <td>270.261</td>\n",
       "      <td>5.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>2020-05-30/12:15:00</td>\n",
       "      <td>2020-05-30/12:25:00</td>\n",
       "      <td>278.151</td>\n",
       "      <td>4.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>2020-05-30/13:35:00</td>\n",
       "      <td>2020-05-30/13:45:00</td>\n",
       "      <td>288.296</td>\n",
       "      <td>4.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>2020-05-30/14:05:00</td>\n",
       "      <td>2020-05-30/14:15:00</td>\n",
       "      <td>301.037</td>\n",
       "      <td>5.362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>523 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Start_trang            End_trang  Clang_avg  Bx_avg(nT)\n",
       "0    2019-09-17/07:30:00  2019-09-17/07:40:00    284.799      -0.280\n",
       "1    2019-09-17/15:15:00  2019-09-17/15:25:00    294.556       2.822\n",
       "2    2019-09-17/15:45:00  2019-09-17/15:55:00    294.403       2.950\n",
       "3    2019-09-17/16:40:00  2019-09-17/16:50:00    235.839       3.665\n",
       "4    2019-09-20/09:50:00  2019-09-20/10:00:00    251.279      -1.085\n",
       "..                   ...                  ...        ...         ...\n",
       "518  2020-05-30/10:50:00  2020-05-30/11:00:00    267.097       5.738\n",
       "519  2020-05-30/11:20:00  2020-05-30/11:30:00    270.261       5.477\n",
       "520  2020-05-30/12:15:00  2020-05-30/12:25:00    278.151       4.732\n",
       "521  2020-05-30/13:35:00  2020-05-30/13:45:00    288.296       4.653\n",
       "522  2020-05-30/14:05:00  2020-05-30/14:15:00    301.037       5.362\n",
       "\n",
       "[523 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Importing last10m soBz dataframes\n",
    "'''\n",
    "df_soBz_last10_yr1 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "         'Exported_trangeList_Last10min/Old_Exported_trange_Last10m/SoBz_trange_Last10m_v2/pdFile_Yr1_last10m_trange_soBzdom_v2.txt', sep = '\\t')\n",
    "df_soBz_last10_yr2 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "         'Exported_trangeList_Last10min/Old_Exported_trange_Last10m/SoBz_trange_Last10m_v2/pdFile_Yr2_last10m_trange_soBzdom_v2.txt', sep = '\\t')\n",
    "df_soBz_last10_yr3 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "         'Exported_trangeList_Last10min/Old_Exported_trange_Last10m/SoBz_trange_Last10m_v2/pdFile_Yr3_last10m_trange_soBzdom_v2.txt', sep = '\\t') \n",
    "df_soBz_last10_yr4 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "         'Exported_trangeList_Last10min/Old_Exported_trange_Last10m/SoBz_trange_Last10m_v2/pdFile_Yr4_last10m_trange_soBzdom_v2.txt', sep = '\\t')\n",
    "df_soBz_last10_yr5 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "         'Exported_trangeList_Last10min/Old_Exported_trange_Last10m/SoBz_trange_Last10m_v2/pdFile_Yr5_last10m_trange_noMECgap_soBzdom_v2.txt', sep = '\\t')\n",
    "\n",
    "print(sorted(df_soBz_last10_yr5))\n",
    "print('Re-imported soBz stable DFs')\n",
    "#show1to5DF(df_soBz_last10_yr1, df_soBz_last10_yr2, df_soBz_last10_yr3, df_soBz_last10_yr4, df_soBz_last10_yr5)\n",
    "\n",
    "\n",
    "#Importing last10m norBz dataframes\n",
    "df_norBz_last10_yr1 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "         'Exported_trangeList_Last10min/Old_Exported_trange_Last10m/NorBz_trange_Last10m/pdFile_Yr1_last10m_trange_norBzdom.txt', sep = '\\t')\n",
    "\n",
    "df_norBz_last10_yr2 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "         'Exported_trangeList_Last10min/Old_Exported_trange_Last10m/NorBz_trange_Last10m/pdFile_Yr2_last10m_trange_norBzdom.txt', sep = '\\t')\n",
    "df_norBz_last10_yr3 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "         'Exported_trangeList_Last10min/Old_Exported_trange_Last10m/NorBz_trange_Last10m/pdFile_Yr3_last10m_trange_norBzdom.txt', sep = '\\t')\n",
    "df_norBz_last10_yr4 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "         'Exported_trangeList_Last10min/Old_Exported_trange_Last10m/NorBz_trange_Last10m/pdFile_Yr4_last10m_trange_norBzdom.txt', sep = '\\t')\n",
    "df_norBz_last10_yr5 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "         'Exported_trangeList_Last10min/Old_Exported_trange_Last10m/NorBz_trange_Last10m/pdFile_Yr5_last10m_trange_noMECgap_norBzdom.txt', sep = '\\t')\n",
    "\n",
    "print('Re-imported norBz Stable DFs')\n",
    "#show1to5DF(df_norBz_last10_yr1, df_norBz_last10_yr2, df_norBz_last10_yr3, df_norBz_last10_yr4, df_norBz_last10_yr5)\n",
    "''';\n",
    "\n",
    "\n",
    "#Importing last10m posBy dataframes\n",
    "df_posBy_last10_yr1 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "         'Exported_trangeList_Last10min/PosBy_withBx_trange_Last10m/pdFile_Yr1_last10m_trange_posByled_withBx.txt', sep = '\\t')\n",
    "\n",
    "df_posBy_last10_yr2 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "     'Exported_trangeList_Last10min/PosBy_withBx_trange_Last10m/pdFile_Yr2_last10m_trange_posByled_withBx.txt', sep = '\\t')\n",
    "\n",
    "df_posBy_last10_yr3 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "     'Exported_trangeList_Last10min/PosBy_withBx_trange_Last10m/pdFile_Yr3_last10m_trange_posByled_withBx.txt', sep = '\\t')\n",
    "\n",
    "df_posBy_last10_yr4 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "     'Exported_trangeList_Last10min/PosBy_withBx_trange_Last10m/pdFile_Yr4_last10m_trange_posByled_withBx.txt', sep = '\\t')\n",
    "\n",
    "df_posBy_last10_yr5 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "     'Exported_trangeList_Last10min/PosBy_withBx_trange_Last10m//pdFile_Yr5_last10m_trange_noMECgap_posByled_withBx.txt', sep = '\\t')\n",
    "\n",
    "print('Re-imported posBy Stable tranges')\n",
    "#show1to5DF(df_posBy_last10_yr1, df_posBy_last10_yr2, df_posBy_last10_yr3, df_posBy_last10_yr4, df_posBy_last10_yr5)\n",
    "\n",
    "#'''\n",
    "#Importing last10m negBy dataframes\n",
    "df_negBy_last10_yr1 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "     'Exported_trangeList_Last10min/NegBy_withBx_trange_Last10m/pdFile_Yr1_last10m_trange_negByled_withBx.txt', sep = '\\t')\n",
    "\n",
    "df_negBy_last10_yr2 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "     'Exported_trangeList_Last10min/NegBy_withBx_trange_Last10m/pdFile_Yr2_last10m_trange_negByled_withBx.txt', sep = '\\t')\n",
    "\n",
    "df_negBy_last10_yr3 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "     'Exported_trangeList_Last10min/NegBy_withBx_trange_Last10m/pdFile_Yr3_last10m_trange_negByled_withBx.txt', sep = '\\t')\n",
    "\n",
    "df_negBy_last10_yr4 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "     'Exported_trangeList_Last10min/NegBy_withBx_trange_Last10m/pdFile_Yr4_last10m_trange_negByled_withBx.txt', sep = '\\t')\n",
    "\n",
    "df_negBy_last10_yr5 = pd.read_csv(r'/Users/salinasha/Desktop/MacBoo Codes/Space Physics Codes/Under pySPEDAS_venv/'\n",
    "     'Exported_trangeList_Last10min/NegBy_withBx_trange_Last10m/pdFile_Yr5_last10m_trange_noMECgap_negByled_withBx.txt', sep = '\\t')\n",
    "\n",
    "print('Re-imported negBy Stable tranges')\n",
    "show1to5DF(df_negBy_last10_yr1, df_negBy_last10_yr2, df_negBy_last10_yr3, df_negBy_last10_yr4, df_negBy_last10_yr5)\n",
    "\n",
    "#''';\n",
    "#delete previously loaded tplot variables\n",
    "pytplot.del_data() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e2e73d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "NegBy trange tuple:\n",
      "<class 'tuple'>\n",
      "['2015-09-01/00:25:00', '2015-09-01/00:35:00'] ---> ['2016-05-30/14:30:00', '2016-05-30/14:40:00']\n",
      "665\n",
      "<class 'tuple'>\n",
      "['2016-09-08/16:15:00', '2016-09-08/16:25:00'] ---> ['2017-05-30/07:40:00', '2017-05-30/07:50:00']\n",
      "613\n",
      "<class 'tuple'>\n",
      "['2017-09-01/18:50:00', '2017-09-01/19:00:00'] ---> ['2018-05-29/19:30:00', '2018-05-29/19:40:00']\n",
      "822\n",
      "<class 'tuple'>\n",
      "['2018-09-01/01:35:00', '2018-09-01/01:45:00'] ---> ['2019-05-29/05:20:00', '2019-05-29/05:30:00']\n",
      "897\n",
      "<class 'tuple'>\n",
      "['2019-09-17/07:30:00', '2019-09-17/07:40:00'] ---> ['2020-05-30/14:05:00', '2020-05-30/14:15:00']\n",
      "523\n",
      "----\n",
      "PosBy trange tuple:\n",
      "<class 'tuple'>\n",
      "['2015-09-03/00:00:00', '2015-09-03/00:10:00'] ---> ['2016-05-30/12:10:00', '2016-05-30/12:20:00']\n",
      "831\n",
      "<class 'tuple'>\n",
      "['2016-09-01/00:15:00', '2016-09-01/00:25:00'] ---> ['2017-05-27/18:00:00', '2017-05-27/18:10:00']\n",
      "813\n",
      "<class 'tuple'>\n",
      "['2017-09-01/11:15:00', '2017-09-01/11:25:00'] ---> ['2018-05-30/18:20:00', '2018-05-30/18:30:00']\n",
      "724\n",
      "<class 'tuple'>\n",
      "['2018-09-02/22:25:00', '2018-09-02/22:35:00'] ---> ['2019-05-25/16:15:00', '2019-05-25/16:25:00']\n",
      "440\n",
      "<class 'tuple'>\n",
      "['2019-09-03/18:45:00', '2019-09-03/18:55:00'] ---> ['2020-05-29/20:40:00', '2020-05-29/20:50:00']\n",
      "368\n"
     ]
    }
   ],
   "source": [
    "def convert_trange_tuple(df_yrX):\n",
    "#Converting last10 dataframes into suitable trange tuple lists\n",
    "    startSTR = df_yrX['Start_trang'].to_numpy(copy=True)\n",
    "    endSTR = df_yrX['End_trang'].to_numpy(copy=True)\n",
    "    test = tuple() #creating empty tuple\n",
    "    #appending list-items to empty tuple with for loop\n",
    "    for i in range(len(startSTR)):\n",
    "        tdate = [startSTR[i], endSTR[i]] #time intervals in proper trange syntax\n",
    "        test = test + (tdate,)\n",
    "    print(type(test)) #print(test[0])\n",
    "    print(test[0], '--->', test[-1])\n",
    "    print(len(test))\n",
    "    return(test);\n",
    "'''\n",
    "print('SoBz trange tuple:')\n",
    "trange_soBztuple_yr1 = convert_trange_tuple(df_soBz_last10_yr1)\n",
    "trange_soBztuple_yr2 = convert_trange_tuple(df_soBz_last10_yr2)\n",
    "trange_soBztuple_yr3 = convert_trange_tuple(df_soBz_last10_yr3)\n",
    "trange_soBztuple_yr4 = convert_trange_tuple(df_soBz_last10_yr4)\n",
    "trange_soBztuple_yr5 = convert_trange_tuple(df_soBz_last10_yr5)\n",
    "\n",
    "print('----\\nNorBz trange tuple:')\n",
    "trange_norBztuple_yr1 = convert_trange_tuple(df_norBz_last10_yr1)\n",
    "trange_norBztuple_yr2 = convert_trange_tuple(df_norBz_last10_yr2)\n",
    "trange_norBztuple_yr3 = convert_trange_tuple(df_norBz_last10_yr3)\n",
    "trange_norBztuple_yr4 = convert_trange_tuple(df_norBz_last10_yr4)\n",
    "trange_norBztuple_yr5 = convert_trange_tuple(df_norBz_last10_yr5)\n",
    "'''\n",
    "print('----\\nNegBy trange tuple:')\n",
    "trange_negBytuple_yr1 = convert_trange_tuple(df_negBy_last10_yr1)\n",
    "trange_negBytuple_yr2 = convert_trange_tuple(df_negBy_last10_yr2)\n",
    "trange_negBytuple_yr3 = convert_trange_tuple(df_negBy_last10_yr3)\n",
    "trange_negBytuple_yr4 = convert_trange_tuple(df_negBy_last10_yr4)\n",
    "trange_negBytuple_yr5 = convert_trange_tuple(df_negBy_last10_yr5)\n",
    "\n",
    "print('----\\nPosBy trange tuple:')\n",
    "trange_posBytuple_yr1 = convert_trange_tuple(df_posBy_last10_yr1)\n",
    "trange_posBytuple_yr2 = convert_trange_tuple(df_posBy_last10_yr2)\n",
    "trange_posBytuple_yr3 = convert_trange_tuple(df_posBy_last10_yr3)\n",
    "trange_posBytuple_yr4 = convert_trange_tuple(df_posBy_last10_yr4)\n",
    "trange_posBytuple_yr5 = convert_trange_tuple(df_posBy_last10_yr5)\n",
    "#''';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20afe0c",
   "metadata": {},
   "source": [
    "* Effective way of appending items no an empty tuple where the desired elements are lists\n",
    "    * https://stackoverflow.com/questions/16730339/python-add-item-to-the-tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b84e8d",
   "metadata": {},
   "source": [
    "# Section 2\n",
    "## Extracting Current Data by looping through FGM and CURL data throughout several 10min intervals\n",
    "* takes on avg ~32.7sec to load 10 min of FGM data and compute CURL params\n",
    "* To loop with pySPEDAS functions, the trange intervals must be placed in a tuple\n",
    "---\n",
    "## (10-28-2021)\n",
    "### Listing Currents from (ClockAng) Sorted Events Redux\n",
    "#### Taking mean, median, and std of current peaks instead of full data to filter our 'noisy' current\n",
    "* **Looks for peaks from the current magnitude then extrapolate those locations to the mean,med, and std values of the curlB components and divB**\n",
    "* also, name file that mentions what the peak prominence, or relative height, was. Which in this case was 0.1(or relative height >=0.1) or 0.08 orwhatever I decide on\n",
    "    * Potential idea: look for max curr_mag value in a dataset interval. If max > 0.1, set prominence to 0.09(record peaks whose rel height >=0.1). If max < 0.1, set prominence to 0.07(record peaks whose rel. height >= 0.08\n",
    "#### Excerpt from Birdwatchin 2 Script:\n",
    " * (10-14-2021) As discovered here[Birdwatchin 2] and discussed in great deal with Rick. The original current data I extracted from the SoBz STable intervals took the mean, median, and std of the interval's **entire** data set. Which caused those statistical parameters to center around the 'noisy' part of the data. To remedy this, I will modify the `Mapping Currents Pt1` to capture the time interval stat's of the **current peaks** instead of the entire data set using `scipy_find_peaks`\n",
    "     * height parameter: I search for peaks above the avg_value since the original algorithm's stat parameters captured the noise's location quite nicely. As verified in both the above plot[Birdwatchin 2] and currstat plots I made in `Mapping Currents pt2`\n",
    "     * prominence parameter: set minimum relative peak height to 0.1 since most current peaks(observations from old BirdWatchin script) in steady magsheath were usually around 0.3uA/m2\n",
    "***     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156515fc",
   "metadata": {},
   "source": [
    "### Section 2.1:\n",
    "#### Loading/Looping through  FGM and Curlometer Data(GSM Coord)\n",
    "* discovered FGM survey data points are made every 0.12 to 0.13seconds    \n",
    "* (9-18-2021) In plotting out individual time interval's curlB/mu0 data, I discovered that the current components contain nan-values which messes up average and median calculations. Luckily, `np.nanmedian` and `np.nanmean` exist to deter that issue\n",
    "    * https://stackoverflow.com/questions/36224066/average-of-a-numpy-array-returns-nan\n",
    "    \n",
    "* (1-13-2022)\n",
    "    * As discussed with Tony at AGU 2021, the standard deviation is a good way of capturing the location of noise\n",
    "    * For current peak extraction, I'm ensuring that peaks are recorded above 2_std\n",
    "        * I noticed in `Bird Watchin 2`, this 2_std was sometimes comparable too or higher than the avg_value. Which helps ensure that I'm capturing significant peaks well above the noisy part of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8d3bfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2015-09-01/10:05:00', '2015-09-01/10:15:00']\n",
      "2015-09-01/10:05:00\n",
      "<class 'str'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trange_soBztuple_yr1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yl/ld8jwz2d7dvcslpjc43t11p1tfdn27/T/ipykernel_3359/3636027812.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrange_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrange_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrange_soBztuple_yr1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trange_soBztuple_yr1' is not defined"
     ]
    }
   ],
   "source": [
    "trange_test = ['2015-09-01/10:05:00', '2015-09-01/10:15:00']\n",
    "trange_test2 = ['2015-09-01/10:00:00', '2015-09-01/10:15:00']\n",
    "\n",
    "print(trange_test)\n",
    "print(trange_test[0])\n",
    "print(type(trange_test[0]))\n",
    "print(trange_soBztuple_yr1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f11798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Loading up mec position, fgm B-field data, and Computing Curlometer Parameters#####################\n",
    "##Loading and plotting 'srvy' data is fine for all\n",
    "def getFGM_data(achDate):\n",
    "# Loading up fgm B-field and mec position data with string inputted date list in GSM coord\n",
    "    pytplot.del_data() #deleting previously loaded tplot variables\n",
    "    print('\\nInput date was: %s '%(achDate))\n",
    "    fgm_vars = fgm(probe=[1, 2, 3, 4], trange=achDate, time_clip=True, varformat='*_gsm_*')\n",
    "        #default data rate is 'srvy' for fgm routine    \n",
    "    mec_vars = mec(probe=[1, 2, 3, 4], trange = achDate, time_clip=True) \n",
    "    #e_tempar_time, e_tempar_vals = get_data('mms1_des_temppara_fast')\n",
    "    bgsm_time, bgsm_vals = get_data('mms1_fgm_b_gsm_srvy_l2')\n",
    "    #Defining string variables for FGM start/end time\n",
    "    achFGM_start = time_string(bgsm_time[0])\n",
    "    achFGM_end = time_string(bgsm_time[-1])\n",
    "    print('Confirming loaded FGM data range: %s to %s' %(achFGM_start[0:20], achFGM_end[0:20]))\n",
    "    return(bgsm_time);\n",
    "    # takes about ~27sec to load 10min of data\n",
    "\n",
    "#start = time.perf_counter()\n",
    "##getFGM_data(trange_test2)\n",
    "#end = time.perf_counter()\n",
    "#print('Time to load FGM an MEC data\" %0.2f s'%(end-start))\n",
    "\n",
    "\n",
    "def curl_params():\n",
    "# Computing CURL parameters with loaded fgm data in GSM coord\n",
    "    #defining curlometer inputs\n",
    "    mec_pos = ['mms1_mec_r_gsm', 'mms2_mec_r_gsm', 'mms3_mec_r_gsm', 'mms4_mec_r_gsm']\n",
    "    prob_fields = ['mms1_fgm_b_gsm_srvy_l2_bvec', 'mms2_fgm_b_gsm_srvy_l2_bvec', \n",
    "          'mms3_fgm_b_gsm_srvy_l2_bvec', 'mms4_fgm_b_gsm_srvy_l2_bvec']\n",
    "    #Computing curlometer parameters\n",
    "    curlometer_vars = curlometer(fields=prob_fields, positions=mec_pos)\n",
    "    #print('Time to load 10min of curlometer data: %0.2f s'%(end_curl-start_curl))\n",
    "    #takes ~20min for one day, ~4.49s for 10min, and ~6.64s for 15min of data\n",
    "        #curlometer params: tplot(['divB', 'curlB', 'jtotal', 'jperp', 'jpar', 'baryb'])\n",
    "        ##units of curlB and divB are in nT/km\n",
    "    #tplot_names()\n",
    "    return;\n",
    "\n",
    "def plot_fgm_curl():\n",
    "## Plotting fgm B-field and curlom parameters\n",
    "    #tplot(['mms1_fgm_b_gse_srvy_l2','mms1_fgm_b_gse_srvy_l2_bvec', 'mms1_fgm_b_gse_srvy_l2_btot'])\n",
    "    tplot(['mms1_fgm_b_gsm_srvy_l2_bvec','curlB', 'divB', 'jtotal'])\n",
    "    #tplot_names();\n",
    "    return;\n",
    "\n",
    "def get_curlndivB(mms1_fgm_bgsm_time):\n",
    "# Creating/extracting new tplot variables for curlB and divB in terms of current units#####\n",
    "    #defining constants from the NRL Plasma Foundry\n",
    "    R_e = 6371 #km, Earth radius\n",
    "    mu0 = 4e-7*np.pi #H/m == Tm/A, permeability of free space\n",
    "        #mu0*J == [Tm/A *A/m2] == [T/m] == curlB\n",
    "            #1km = 1000m and 1nT = 1e-9T\n",
    "        #mu0[Tm/A]*(1km/1000m)*(1nT/1e-9T) == mu0(nT*km/A)*1e+6\n",
    "    mu0_nT_km = mu0*1e+6 #nT*km/A\n",
    "    \n",
    "    #Extracting curlB/divB(unit = nT/km) data to create |curlB|/mu0 and divB/mu0(unit = A/km2 or uA/m2) tplot vars\n",
    "    curlb_time, curlb_vec = get_data('curlB')\n",
    "    divb_time, divb_vals = get_data('divB')\n",
    "    print('\\n', type(curlb_vec))\n",
    "    print('curlB shape:', np.shape(curlb_vec)) # or curlb_vec.shape)\n",
    "    curlb_mag = np.sqrt(curlb_vec[:,0]**2 + curlb_vec[:,1]**2 + curlb_vec[:,2]**2)\n",
    "        #print('Does curlb and divb time arrays match', np.array_equal(curlb_time, divb_time)) #they match\n",
    "        #store_data('curlB_mag_mu0', data={'x': curlb_time, 'y': curlb_mag/mu0_nT_km})\n",
    "        #store_data('divB_mu0', data={'x': divb_time, 'y': divb_vals/mu0_nT_km})\n",
    "        #Creating single tplot variable for |curlB|/mu0 and divB/mu0\n",
    "        #join_vec(['curlB_mag_mu0', 'divB_mu0'], new_tvar='curlB_divB_mu0')\n",
    "        #Displaying curlB start-end dates and confirming if it matches with prob1 fgm time array\n",
    "        #print('Curlb time:\\n', time_string(curlb_time[:5]), '\\n', time_string(curlb_time[-5:]))\n",
    "    print('FGM Bgsm Prob1 time and curlB time arrays match:', np.array_equal(curlb_time, mms1_fgm_bgsm_time))\n",
    "    # Plotting curlb and divb components to display statistical features\n",
    "    #plot_currents(curlb_time, curlb_vec[:,0], curlb_vec[:,1], curlb_vec[:,2], curlb_mag, divb_vals)\n",
    "    # Return single arrays vector of current stats for each component\n",
    "    current_stats = get_curr_stats(curlb_time, curlb_vec[:,0], curlb_vec[:,1], curlb_vec[:,2], curlb_mag, divb_vals)\n",
    "    return(current_stats);\n",
    "    #return (curlb_time, curlb_vec[:,0], curlb_vec[:,1], curlb_vec[:,2], curlb_mag, divb_vals);\n",
    "\n",
    "\n",
    "def plot_currents(curlb_utime, curlbx, curlby, curlbz, curlb_mag, divb):\n",
    "# Plots curlB/mu0 in proper units(uA/m2) and displays parameters like median, mean, and what not\n",
    "    mu0 = 4e-7*np.pi #H/m == Tm/A, permeability of free space\n",
    "    mu0_nT_km = mu0*1e+6 #nT*km/A\n",
    "    #Defining string variables for CURL start and end time\n",
    "    achStart = time_string(curlb_utime[0])\n",
    "    achEnd = time_string(curlb_utime[-1])\n",
    "    achTRange = 'from %s to %s' %(achStart[0:19], achEnd[0:19])\n",
    "    #Extract array of indices which yields Current_mag peak locations; whose relative height is >= 0.1\n",
    "    peakmag = get_currpeaks(curlb_mag/mu0_nT_km)\n",
    "\n",
    "    #Plotting curlb and divb components\n",
    "    BxTitle = 'curlB_x/mu0(uA/m2) vs Unix Time for %s' %(achTRange)\n",
    "    PlotCurr2(curlb_utime, curlbx/mu0_nT_km, peakmag, BxTitle)\n",
    "    \n",
    "    ByTitle = 'curlB_y/mu0(uA/m2) vs Unix Time for %s' %(achTRange)\n",
    "    PlotCurr2(curlb_utime, curlby/mu0_nT_km, peakmag, ByTitle)\n",
    "    \n",
    "    BzTitle = 'curlB_z/mu0(uA/m2) vs Unix Time for %s' %(achTRange)\n",
    "    PlotCurr2(curlb_utime, curlbz/mu0_nT_km, peakmag, BzTitle)\n",
    "    \n",
    "    BmagTitle = 'curlB_mag/mu0(uA/m2) vs Unix Time for %s' %(achTRange)\n",
    "    PlotCurr2(curlb_utime, curlb_mag/mu0_nT_km, peakmag, BmagTitle)\n",
    "    \n",
    "    BdivTitle = 'divB/mu0(uA/m2) vs Unix Time for %s' %(achTRange)\n",
    "    PlotCurr2(curlb_utime, divb/mu0_nT_km, peakmag, BdivTitle)\n",
    "    return;\n",
    "\n",
    "def get_curr_stats(curlb_utime, curlbx, curlby, curlbz, curlb_mag, divb):\n",
    "# Compute/return mean, median, and std for each parameter input in current units(uA/m2)\n",
    "    mu0 = 4e-7*np.pi #H/m == Tm/A, permeability of free space\n",
    "    mu0_nT_km = mu0*1e+6 #nT*km/A\n",
    "    #Defining string variables for CURL start and end time\n",
    "    achStart = time_string(curlb_utime[0])\n",
    "    achEnd = time_string(curlb_utime[-1])\n",
    "    #Extract array of indices which yields Current_mag peak(0.1 prominence) locations\n",
    "    peakmag = get_currpeaks(curlb_mag/mu0_nT_km)\n",
    "    #Current arrays contain nan-values\n",
    "    [Jx_avg, Jx_med, Jx_std] = get_stats(curlbx[peakmag]/mu0_nT_km)\n",
    "    [Jy_avg, Jy_med, Jy_std] = get_stats(curlby[peakmag]/mu0_nT_km)\n",
    "    [Jz_avg, Jz_med, Jz_std] = get_stats(curlbz[peakmag]/mu0_nT_km)\n",
    "    [Jmag_avg, Jmag_med, Jmag_std] = get_stats(curlb_mag[peakmag]/mu0_nT_km)\n",
    "    [divB_avg, divB_med, divB_std] = get_stats(divb[peakmag]/mu0_nT_km)\n",
    "    #defining row vector for current stat parameters\n",
    "    curr_stat_vec = [achStart[0:19], Jx_avg, Jy_avg, Jz_avg, Jmag_avg, divB_avg, Jx_med, Jy_med, Jz_med,\n",
    "                Jmag_med, divB_med, Jx_std, Jy_std, Jz_std, Jmag_std, divB_std, achEnd[0:19]]\n",
    "    return (curr_stat_vec);\n",
    "    \n",
    "    #['Cur_start','Jx_avg(uA/m2)', 'Jy_avg','Jz_avg','Jmag_avg','divB_avg',\n",
    "    #'Jx_med(uA/m2)', 'Jy_med', 'Jz_med', 'Jmag_med', 'divB_med', 'Jx_std(uA/m2)',\n",
    "     #'Jy_std', 'Jz_std', 'Jmag_std', 'divB_std','Cur_end']\n",
    "\n",
    "def get_stats(afData):\n",
    "# Return mean, median, and std of inputted data array\n",
    "    #Turns out current arrays contain nan-values\n",
    "    avg_value = np.nanmean(afData) #Computes average of inputted data array\n",
    "    med_value = np.nanmedian(afData) #Computes median of inputteed data array\n",
    "    std_value = np.nanstd(afData)\n",
    "    return(avg_value, med_value, std_value);\n",
    "\n",
    "def get_currpeaks(afCurrMag):\n",
    "    \"\"\" Extract current peaks location from (curlB/muo)_mag then extrapolate those peak locations to the\n",
    "    other current components after returning them\"\"\"\n",
    "    # Recall that current arrays contain nan-values\n",
    "    #avg_value = np.nanmean(afCurrMag) #Computes average of inputted data array\n",
    "    std_value = np.nanstd(afCurrMag) #Computes std of inputted data array\n",
    "     # find current peaks(excluding nan) above 2*std (old: avg_value) with a relative height >= 0.8\n",
    "    peaks, _ = find_peaks(afCurrMag[~np.isnan(afCurrMag)], height = 2*std_value, prominence = 0.07)\n",
    "    return(peaks);\n",
    "\n",
    "def PlotCurr2(aftime, afData, peakmag, title):\n",
    "    \"\"\"Plots particular current component vs time and displays statistical features alongside location\n",
    "    of peaks that correspond to current_mag peaks\"\"\"\n",
    "    # Turns out current arrays contain nan-values\n",
    "    avg_value = np.nanmean(afData) #Computes average of inputted data array\n",
    "    med_value = np.nanmedian(afData) #Computes median of inputteed data array\n",
    "    std_value = np.nanstd(afData)\n",
    "    # Display and plot current: mean, median, peak, and raw data\n",
    "    plt.figure(figsize = (7,7))\n",
    "    plt.plot(aftime/1e+9, afData, 'g.') #raw data\n",
    "    plt.plot(aftime[peakmag]/1e+9, afData[peakmag], 'ro', ms=6, label = 'Peak') #peak data\n",
    "    print('Med and avg peak amplitudes are respectively %0.4f and  %0.4f'%(np.nanmedian(afData[peakmag]),\n",
    "                                                                    np.nanmean(afData[peakmag])))\n",
    "    print('Med value is %0.5f and avg value is %0.5f'%(med_value, avg_value))\n",
    "    plt.axhline(avg_value,color = 'orange', linestyle = '--')\n",
    "    plt.axhline(med_value,color = 'purple', linestyle = '--')\n",
    "    plt.title('%s' %title, fontsize = 12)\n",
    "    plt.legend(labels=['Std = %0.6f' %std_value, 'Peak-Mag','Average = %0.6f' %avg_value, 'Median = %0.6f' %med_value],\n",
    "               loc = 'best', prop={'size': 10});\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1127c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################Function for Looping through FGM and CURL params#################\n",
    "#define test tuple whose elements are trange lists\n",
    "achInput_test = (['2015-09-01/10:05:00', '2015-09-01/10:15:00'],['2015-09-01/11:40:00','2015-09-01/11:50:00'],\n",
    "    ['2015-09-05/12:45:00','2015-09-05/12:55:00'], ['2015-09-07/18:00:00','2015-09-07/18:10:00'])\n",
    "    \n",
    "def current_single_date(trange):\n",
    "#Measures the time it takes to load FGM \n",
    "#and compute CURL parameters for the corresponding trange input\n",
    "    pytplot.del_data()\n",
    "    start = time.perf_counter()\n",
    "    mms1_fgm_bgsm_time = getFGM_data(trange)\n",
    "    curl_params()\n",
    "    curr_stat_vec = get_curlndivB(mms1_fgm_bgsm_time)\n",
    "        #curr_stat_vec = [achStart[0:19], Jx_avg, Jy_avg, Jz_avg, Jmag_avg, divB_avg, Jx_med, Jy_med, Jz_med,\n",
    "                #Jmag_med, divB_med, Jx_std, Jy_std, Jz_std, Jmag_std, divB_std, achEnd[0:19]]\n",
    "    #plot_fgm_curl()\n",
    "    end = time.perf_counter()\n",
    "    print('Time it took to load 10min of FGM data and compute CURL params: %0.2f s'%(end-start))\n",
    "    return((end-start), curr_stat_vec);\n",
    "\n",
    "#timing_function()\n",
    "#print(achInput_test[0])\n",
    "#print(len(achInput))\n",
    "\n",
    "def current_data_tuples(Date, error_vec):\n",
    "#Measures the avg and total time it takes to load/compute FGM data with CURL params using inputted\n",
    "#tuple of trange lists\n",
    "    #creating empty dataframe with column names and defined index length as # of date intervals\n",
    "    df_currdata = pd.DataFrame(columns = ['Cur_start','Jx_avg(uA/m2)', 'Jy_avg','Jz_avg','Jmag_avg','divB_avg',\n",
    "                                    'Jx_med(uA/m2)', 'Jy_med', 'Jz_med', 'Jmag_med', 'divB_med', 'Jx_std(uA/m2)',\n",
    "                                    'Jy_std', 'Jz_std', 'Jmag_std', 'divB_std','Cur_end'], index = np.arange(len(Date)))\n",
    "    # initialized empty array and variable\n",
    "    droplist = []\n",
    "    fSum = 0\n",
    "    for i in range(len(Date)):\n",
    "        try: #method of bypassing errors that may occur from CURL computations(no data available)\n",
    "            [com_time, curr_stat_vec] = current_single_date(Date[i]) #extracting runtime & current data from single trange\n",
    "            fSum = fSum + com_time\n",
    "        except: #add error_vec to DF row if error is detected\n",
    "            print('DataError occurred with CURL or some other routine')\n",
    "            df_currdata.iloc[i] = error_vec  # add error vector to DF row-index\n",
    "            droplist = np.append(droplist,i) #add error element-index to array\n",
    "        else:\n",
    "            df_currdata.iloc[i] = curr_stat_vec  #adding current data to DF row-index\n",
    "        #print(curr_stat_vec)\n",
    "    \n",
    "    display(df_currdata) #display current dataframe\n",
    "    #displaying tranges in which data errors occurred over \n",
    "    if len(droplist) > 0:\n",
    "        print('DropList index:', droplist)\n",
    "        for i in range(len(droplist)):\n",
    "            print(Date[int(droplist[i])])  # displays Drop tuple element index with index recorded by drop list\n",
    "                                           # int(droplist[i]) ensures input into Date is an integer to avoid error\n",
    "    else:\n",
    "        print('No data errors detected for any tranges this year')\n",
    "    print('\\nTotal time to load/compute %d 10min intervals of FGM data and CURL params: %0.2f'%(len(Date), fSum))\n",
    "    print('Avg time to load %d 10min intervals of FGM data and compute CURL params: %0.2f s'%(len(Date),fSum/len(Date)))\n",
    "    return(df_currdata, droplist);\n",
    "\n",
    "############################ Main Calling Functions Below #######################\n",
    "\n",
    "\n",
    "#Defining array of strings with same length as DF Current Data row in case of detected errors\n",
    "anList = np.array([])\n",
    "anTEST = np.zeros(17)\n",
    "print(len(anTEST), anTEST)\n",
    "for i in range(len(anTEST)):\n",
    "    anList = np.append(anList, 'NoData')\n",
    "print(anList)\n",
    "    \n",
    "\n",
    "#time_test(trange_tuple_yr1)\n",
    "print('Extracting CurrentData from negBy Stable tranges')\n",
    "#[love, hope] = current_single_date(trange_soBztuple_yr5[0])\n",
    "#[test_df, testdrop] = current_data_tuples(trange_soBztuple_yr5[:3], anList)\n",
    "\n",
    "## Extracting Current Data from Yr1 Last10min List\n",
    "#[df_negBycurrdata_yr1, drop_yr1] = current_data_tuples(trange_negBytuple_yr1, anList)\n",
    "\n",
    "## Extracting Current Data from Yr2 Last10min List\n",
    "#[df_negBycurrdata_yr2, drop_yr2] = current_data_tuples(trange_negBytuple_yr2, anList)\n",
    "\n",
    "## Extracting Current Data from Yr3 Last10min List\n",
    "#[df_negBycurrdata_yr3, drop_yr3] = current_data_tuples(trange_negBytuple_yr3, anList)\n",
    "\n",
    "## Extracting Current Data from Yr4 Last10min List\n",
    "#[df_negBycurrdata_yr4, drop_yr4] = current_data_tuples(trange_negBytuple_yr4, anList)\n",
    "\n",
    "## Extracting Current Data from Yr5 Last10min List\n",
    "#[df_negBycurrdata_yr5, drop_yr5] = current_data_tuples(trange_negBytuple_yr5, anList)\n",
    "\n",
    "\n",
    "\n",
    "#curlbx, curlby, curlbz, curlb_mag, divb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81412550",
   "metadata": {},
   "source": [
    "### Section 2.2:\n",
    "#### Testing and Exporting Newly Created Current Dataframes\n",
    "1. Checking if time arrays in currDF match onto inputted time intervals\n",
    "2. Removing rows whose elements contain 'NoData' due to the errors that were encountered in the extraction algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8384f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_currstart(df_curr, df_last10_noslash):\n",
    "#Compares dataframes columns for Start-dates between OG NO-slashlast10min and CurrData DFs\n",
    "#They should be the same\n",
    "    #Extracting and creating copies of DF start-date column arrays\n",
    "    currSTR_start = df_curr['Cur_start'].to_numpy(copy=True)\n",
    "    last10_start = df_last10_noslash['Start_str'].to_numpy(copy=True)\n",
    "    print('CurrData and Last10m Dataframes start-date columns are the same: ',(currSTR_start == last10_start).all()) \n",
    "          #np.array_equal(currSTR_start, last10_start))\n",
    "          #(currSTR_start == last10_start).all())\n",
    "    #print((currSTR_start == last10_start).all())\n",
    "    #print('Using np.array_equals, the start-date columns are theh same: ', np.array_equal(currSTR_start, last10_start))\n",
    "    display(df_curr.iloc[:3])\n",
    "    display(df_last10_noslash[:3])\n",
    "    #COmparing individual elements to check for specific non-matching elements\n",
    "    n = 0\n",
    "    for i in range(len(currSTR_start)):\n",
    "        if currSTR_start[i] == last10_start[i]:\n",
    "            n = n+1\n",
    "        else:\n",
    "            print(\"Element %d Didn't match: \"%i,currSTR_start[i], 'and', last10_start[i])\n",
    "    print('Witih a length of %d, %d start-date elements match between Currdata and Last10'%(len(last10_start),n))\n",
    "    return;\n",
    "\n",
    "def checking_curr_dfs(df_currdata, df_noslash10, anDrop, trange_tuple):\n",
    "    \"\"\"Analyzing the newly made current datafrane by ensuring that it's start-date column array matches\n",
    "    the trange input and lastly comparing the exported/imported dataframes\"\"\"\n",
    "    print(sorted(df_noslash10)) #display noSlash10 column names\n",
    "    print('DFs being analyzed:\\n', namestr(df_currdata, globals()),namestr(df_noslash10, globals()),\n",
    "         namestr(anDrop, globals()), namestr(trange_tuple, globals()))\n",
    "    #Displaying errors that occurred throughout any tranges\n",
    "    if len(anDrop) > 0:\n",
    "        print('DropList index:', anDrop)\n",
    "        for i in range(len(anDrop)):\n",
    "            print(trange_tuple[int(anDrop[i])])  \n",
    "            # displays Drop tuple element index with index recorded by drop list\n",
    "            # int(droplist[i]) ensures input into Date is an integer to avoid error\n",
    "    else:\n",
    "        print('No data errors detected for any tranges this year\\n')\n",
    "    #display(df_currdata)\n",
    "        #Checking yrX currData start-date columns\n",
    "    compare_currstart(df_currdata, df_noslash10)\n",
    "    #df_curr = df_currdata.drop([131]) #yr5 norBz drop\n",
    "\n",
    "    #df_curr = df_curr.reset_index(drop=True)\n",
    "    #display(df_curr)\n",
    "\n",
    "    #compare_start(df_curr, df_noslash10)\n",
    "        #Exporting yrX Current data for each last10min interval and comparing the exported/OG dataframe\n",
    "    #df_currdata.to_csv('pdFile_CurrPeak_norBzdom_prom07_Yr4.txt', sep = '\\t', index = False)\n",
    "    #df_imp_currdata = pd.read_csv('pdFile_CurrPeak_norBzdom_prom07_Yr4.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_currdata, df_imp_currdata)\n",
    "    '''\n",
    "    Exported currData DF file name template:\n",
    "        pdFile_CurrPeak_negByled_prom07_Yr3.txt\n",
    "        pdFile_CurrPeak_noMECgap_negByled_prom07_Yr5.txt\n",
    "    ''';  \n",
    "    #Exporting yr5 Current data for each last10min interval and comparing the exported/OG dataframe\n",
    "    #compare_start(df_currdata, df_noslash10)\n",
    "    #df_curr.to_csv('pdFile_CurrPeak_noMECgap_norBzdom_prom07_Yr5.txt', sep = '\\t', index = False)\n",
    "    #df_imp_currdata = pd.read_csv('pdFile_CurrPeak_noMECgap_norBzdom_prom07_Yr5.txt', sep = '\\t')\n",
    "    #compare_imp_df(df_curr, df_imp_currdata)\n",
    "    \n",
    "    '''\n",
    "      For norBz yr5_currdata\n",
    "      #df_curr = df_currdata.drop([131]) #yr5 norBz drop\n",
    "          DropList index: [131.]\n",
    "          ['2020-02-10/20:15:00', '2020-02-10/20:25:00']\n",
    "    \n",
    "    \n",
    "    For norBz yr3_currdata\n",
    "    #df_curr = df_currdata.drop([113,114,115,272]) #yr3 norBz drop\n",
    "          DropList index: [113. 114. 115. 272.]\n",
    "          ['2018-05-27/04:50:00', '2018-05-27/05:00:00']\n",
    "          ['2018-05-27/05:20:00', '2018-05-27/05:30:00']\n",
    "          ['2018-05-27/21:40:00', '2018-05-27/21:50:00']\n",
    "          ['2018-05-27/22:30:00', '2018-05-27/22:40:00']\n",
    "    \n",
    "    \n",
    "    For norBz yr2_currdata\n",
    "    #df_curr = df_currdata.drop([105]) #yr2 norBz drop\n",
    "        DropList index: [105.]\n",
    "        ['2017-01-04/16:40:00', '2017-01-04/16:50:00']\n",
    "    \n",
    "    \n",
    "    For posBy yr5_currdata\n",
    "    #df_curr = df_currdata.drop([251, 252, 253]) # yr5 posBy drop\n",
    "        DropList index: [251. 252. 253.]\n",
    "        ['2020-02-10/21:10:00', '2020-02-10/21:20:00']\n",
    "        ['2020-02-10/22:55:00', '2020-02-10/23:05:00']\n",
    "        ['2020-02-10/23:25:00', '2020-02-10/23:35:00']\n",
    "    \n",
    "    \n",
    "    For posBy yr3_currdata\n",
    "    #df_curr = df_currdata.drop([689, 690, 691, 692, 693, 694, 695, 696])# yr3 posBy drop\n",
    "        DropList index: [689. 690. 691. 692. 693. 694. 695. 696.]\n",
    "        ['2018-05-27/14:20:00', '2018-05-27/14:30:00']\n",
    "        ['2018-05-27/14:50:00', '2018-05-27/15:00:00']\n",
    "        ['2018-05-27/16:55:00', '2018-05-27/17:05:00']\n",
    "        ['2018-05-27/17:30:00', '2018-05-27/17:40:00']\n",
    "        ['2018-05-27/18:00:00', '2018-05-27/18:10:00']\n",
    "        ['2018-05-27/18:30:00', '2018-05-27/18:40:00']\n",
    "        ['2018-05-27/19:25:00', '2018-05-27/19:35:00']\n",
    "        ['2018-05-27/20:10:00', '2018-05-27/20:20:00']\n",
    "\n",
    "    For posBy yr2_currdata\n",
    "    #df_curr = df_currdata.drop([481, 482, 483, 484, 485, 486, 487, 488, 489, 490])# yr2 posBy drop\n",
    "    \n",
    "    For negBy yr5_currdata\n",
    "    #df_curr = df_currdata.drop([232]) #yr5 negBy drop\n",
    "        DropList index: [232.]\n",
    "        ['2020-02-10/17:40:00', '2020-02-10/17:50:00']\n",
    "    \n",
    "    For negBy yr4_currdata\n",
    "    #df_curr = df_currdata.drop([896]) #yr4 negBy drop\n",
    "    \n",
    "    For negBy yr2_currdata\n",
    "    #df_curr = df_currdata.drop([234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244])# yr2 negBy drop\n",
    "    #df_curr = df_curr.reset_index(drop=True)\n",
    "    \n",
    "    For SoBz yr2_currData\n",
    "    #df_curr2_yr2 = df_currdata_yr2.drop([189, 190, 191, 192, 193, 194, 195]) #dropping NoData row for Yr2\n",
    "    #df_curr2_yr2 = df_curr2_yr2.reset_index(drop = True) #reset index# column for new DF\n",
    "    \n",
    "    For SoBz yr3_currData\n",
    "    #df_curr2_yr3 = df_currdata_yr3.drop([393, 394]) #dropping NoData row for Yr3\n",
    "    #df_curr2_yr3 = df_curr2_yr3.reset_index(drop = True) #reset index# column for new DF\n",
    "    ''';\n",
    "    return;\n",
    "\n",
    "\n",
    "\n",
    "#checking_curr_dfs(df_noBzcurrdata_yr1, df_noBz_noslash10m_yr1, drop_yr1, trange_norBztuple_yr1)\n",
    "\n",
    "#checking_curr_dfs(df_noBzcurrdata_yr2, df_noBz_noslash10m_yr2, drop_yr2, trange_norBztuple_yr2)\n",
    "\n",
    "#checking_curr_dfs(df_noBzcurrdata_yr3, df_noBz_noslash10m_yr3, drop_yr3, trange_norBztuple_yr3)\n",
    "\n",
    "#checking_curr_dfs(df_noBzcurrdata_yr4, df_noBz_noslash10m_yr4, drop_yr4, trange_norBztuple_yr4)\n",
    "\n",
    "#checking_curr_dfs(df_noBzcurrdata_yr5, df_noBz_noslash10m_yr5, drop_yr5, trange_norBztuple_yr5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab8b5f7",
   "metadata": {},
   "source": [
    "* **(11-14-2021)The following comments apply to SoBz Current Data extracted way back when:** \n",
    "    * (9-21-2021) As resolved by Rick, the reason why an IndexError occurred for Extractin Yr2 current data on the trange `['2017-01-02/07:35:00', '2017-01-02/07:45:00']`, was that Probe 3 had to recorded data for that period\n",
    "        * As such, I will implement a `try-except` code to avoid my code from halting when an error occurs and have it record the time intervals in which such errors do occur\n",
    "            * Same no data error occurred for `Input date was: ['2018-05-27/09:30:00', '2018-05-27/09:40:00']`. Which sucks cause year 3 was almost done. This just re-enforces my need to implement a try-except feature.\n",
    "    * (9-23-2021) After implementing `try-except` code:\n",
    "        * Yr 3 Missing data trange Input date: `['2018-05-27/09:30:00', '2018-05-27/09:40:00']` and `['2018-05-27/10:40:00', '2018-05-27/10:50:00'] `, or droplist_ind = [393, 394]\n",
    "        * Yr 2 Missing data trange inputs, droplist_index =  [189. 190. 191. 192. 193. 194. 195.] or\n",
    "~~~\n",
    "        ['2017-01-02/07:35:00', '2017-01-02/07:45:00']\n",
    "        ['2017-01-02/08:05:00', '2017-01-02/08:15:00']\n",
    "        ['2017-01-02/10:35:00', '2017-01-02/10:45:00']\n",
    "        ['2017-01-02/11:55:00', '2017-01-02/12:05:00']\n",
    "        ['2017-01-02/13:45:00', '2017-01-02/13:55:00']\n",
    "        ['2017-01-02/14:20:00', '2017-01-02/14:30:00']\n",
    "        ['2017-01-03/09:50:00', '2017-01-03/10:00:00']\n",
    "~~~\n",
    "\n",
    "* **(11-23-2021)** Comments about which tranges to drop for each Clockang Current Dataframe:\n",
    "~~~\n",
    "    For norBz yr5_currdata\n",
    "    #df_curr = df_currdata.drop([131]) #yr5 norBz drop\n",
    "        DropList index: [131.]\n",
    "        ['2020-02-10/20:15:00', '2020-02-10/20:25:00']\n",
    "\n",
    "\n",
    "    For norBz yr3_currdata\n",
    "    #df_curr = df_currdata([113,114,115,272]) #yr3 norBz drop\n",
    "        DropList index: [113. 114. 115. 272.]\n",
    "        ['2018-05-27/04:50:00', '2018-05-27/05:00:00']\n",
    "        ['2018-05-27/05:20:00', '2018-05-27/05:30:00']\n",
    "        ['2018-05-27/21:40:00', '2018-05-27/21:50:00']\n",
    "        ['2018-05-27/22:30:00', '2018-05-27/22:40:00']\n",
    "    \n",
    "    \n",
    "    \n",
    "    For norBz yr2_currdata\n",
    "    #df_curr = df_currdata.drop([105]) #yr2 norBz drop\n",
    "    DropList index: [105.]\n",
    "    ['2017-01-04/16:40:00', '2017-01-04/16:50:00']\n",
    "    \n",
    "    \n",
    "    For posBy yr5_currdata\n",
    "    #df_curr = df_currdata.drop([251, 252, 253]) # yr5 posBy drop\n",
    "        DropList index: [251. 252. 253.]\n",
    "        ['2020-02-10/21:10:00', '2020-02-10/21:20:00']\n",
    "        ['2020-02-10/22:55:00', '2020-02-10/23:05:00']\n",
    "        ['2020-02-10/23:25:00', '2020-02-10/23:35:00']\n",
    "        \n",
    "        \n",
    "    For posBy yr3_currdata\n",
    "    #df_curr = df_currdata.drop([689, 690, 691, 692, 693, 694, 695, 696])# yr3 posBy drop\n",
    "        DropList index: [689. 690. 691. 692. 693. 694. 695. 696.]\n",
    "        ['2018-05-27/14:20:00', '2018-05-27/14:30:00']\n",
    "        ['2018-05-27/14:50:00', '2018-05-27/15:00:00']\n",
    "        ['2018-05-27/16:55:00', '2018-05-27/17:05:00']\n",
    "        ['2018-05-27/17:30:00', '2018-05-27/17:40:00']\n",
    "        ['2018-05-27/18:00:00', '2018-05-27/18:10:00']\n",
    "        ['2018-05-27/18:30:00', '2018-05-27/18:40:00']\n",
    "        ['2018-05-27/19:25:00', '2018-05-27/19:35:00']\n",
    "        ['2018-05-27/20:10:00', '2018-05-27/20:20:00']\n",
    "\n",
    "\n",
    "\n",
    "    For posBy yr2_currdata\n",
    "    #df_curr = df_currdata.drop([481, 482, 483, 484, 485, 486, 487, 488, 489, 490])# yr2 posBy drop\n",
    "        #DropList index: [481. 482. 483. 484. 485. 486. 487. 488. 489. 490.]\n",
    "        ['2017-01-02/14:55:00', '2017-01-02/15:05:00']\n",
    "        ['2017-01-02/15:25:00', '2017-01-02/15:35:00']\n",
    "        ['2017-01-02/16:50:00', '2017-01-02/17:00:00']\n",
    "        ['2017-01-02/17:20:00', '2017-01-02/17:30:00']\n",
    "        ['2017-01-02/23:50:00', '2017-01-03/00:00:00']\n",
    "        ['2017-01-03/01:20:00', '2017-01-03/01:30:00']\n",
    "        ['2017-01-03/01:55:00', '2017-01-03/02:05:00']\n",
    "        ['2017-01-03/02:25:00', '2017-01-03/02:35:00']\n",
    "        ['2017-01-03/03:05:00', '2017-01-03/03:15:00']\n",
    "        ['2017-01-03/05:05:00', '2017-01-03/05:15:00']\n",
    "\n",
    "    For negBy yr5_currdata\n",
    "    #df_curr = df_currdata.drop([232]) #yr5 negBy drop\n",
    "        DropList index: [232.]\n",
    "        ['2020-02-10/17:40:00', '2020-02-10/17:50:00']\n",
    "    \n",
    "    For negBy yr4_currdata\n",
    "    #df_curr = df_currdata.drop([896]) #yr4 negBy drop\n",
    "    \n",
    "    For negBy yr2_currdata\n",
    "    #df_curr = df_currdata.drop([234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244])# yr2 negBy drop\n",
    "    #df_curr = df_curr.reset_index(drop=True)\n",
    "    \n",
    "    For SoBz yr2_currData\n",
    "    #df_curr2_yr2 = df_currdata_yr2.drop([189, 190, 191, 192, 193, 194, 195]) #dropping NoData row for Yr2\n",
    "    #df_curr2_yr2 = df_curr2_yr2.reset_index(drop = True) #reset index# column for new DF\n",
    "    \n",
    "    For SoBz yr3_currData\n",
    "    #df_curr2_yr3 = df_currdata_yr3.drop([393, 394]) #dropping NoData row for Yr3\n",
    "    #df_curr2_yr3 = df_curr2_yr3.reset_index(drop = True) #reset index# column for new DF\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6b130b",
   "metadata": {},
   "source": [
    "### Section 2.2b: (1-13-2022)\n",
    "#### Testing/Exporting Newly Created Current DFs and creating Corresponding MEC DF\n",
    "\n",
    "1. Check if time arrays in currDF match onto inputted time intervals\n",
    "2. Create corresponding mecDF that matches currDF time intervals\n",
    "3. Removing currData rows(and corresponding mecData rows) whose elements contain 'NoData' due to the errors that were encountered in the extraction algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cbcf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_currmec_start(df_curr, df_mec):\n",
    "    \"\"\"Compares dataframes columns for Start-dates between MECposdata and CurrData DFs\n",
    "    They should be the same\"\"\"\n",
    "    #Extracting and creating copies of DF start-date column arrays\n",
    "    currSTR_start = df_curr['Cur_start'].to_numpy(copy=True)\n",
    "    mec_start = df_mec['Start_str'].to_numpy(copy=True)\n",
    "    print('CurrData and MECpos Dataframes start-date columns are the same: ', (mec_start == currSTR_start).all())\n",
    "    #print('Using np.array_equals, the start-date columns are the same: ', np.array_equal(currSTR_start, mec_start))\n",
    "    display(df_curr.iloc[:3])\n",
    "    display(df_mec[:3])\n",
    "    #Comparing individual elements to check for specific non-matching elements\n",
    "    n = 0\n",
    "    for i in range(len(mec_start)):\n",
    "        if currSTR_start[i] == mec_start[i]:\n",
    "            n = n+1\n",
    "        else:\n",
    "            print(\"MEC-ind %d Didn't match: \"%(i),currSTR_start[i], 'and', mec_start[i])\n",
    "    print('With a length of %d, %d start-date elements match between Currdata and MECpos'%(len(mec_start),n))\n",
    "    return; \n",
    "\n",
    "def check_currMEC_dfs(df_currdata, df_noslash10, yrX_mec, droplist, trange_tuple):\n",
    "    \"\"\"Creating MECpos DFs whose date columns arrays match the newly created currData DFs.\n",
    "    Ensure currData start-date column arrays match trange input and lastly compare exported/imported DFs\"\"\"\n",
    "    print('Data being analyzed:\\n', namestr(df_currdata, globals()),namestr(df_noslash10, globals()),\n",
    "         namestr(yrX_mec, globals()), namestr(droplist, globals()) ,namestr(trange_tuple, globals()))\n",
    "    #Creating mecDF from OG Last10m interval and comparing both start-end date column arrays\n",
    "    df_MECpos = get_MEC_df(df_noslash10, yrX_mec)\n",
    "    compare_mec_start_end(df_MECpos, df_noslash10)\n",
    "    #Display any 'NoData' errors that occured thorughout any tranges for currData extraction\n",
    "    anDrop = [int(item) for item in droplist]\n",
    "    #anDrop = int(droplist) #ensure droplist elements are integers\n",
    "    if len(anDrop) > 0:\n",
    "        print('DropList index:', anDrop)\n",
    "        for i in range(len(anDrop)):\n",
    "            print(trange_tuple[(anDrop[i])])  \n",
    "            # displays Drop tuple element index with index recorded by drop list\n",
    "            # int(droplist[i]) ensures input into Date is an integer to avoid error\n",
    "    else:\n",
    "        print('No data errors detected for any tranges this year\\n')\n",
    "    #Compare yrX currData and OG Last10m start-date columns\n",
    "    compare_currstart(df_currdata, df_noslash10)\n",
    "    #Based on droplist, either omit NoData rows or leave alone the mec and curDFs\n",
    "    #Create copies of inputted DFs\n",
    "    df_curcop = df_currdata.copy(deep = True) \n",
    "    df_meccop = df_MECpos.copy(deep=True) \n",
    "    if len(anDrop) >0: #omit NoData rows from both curr and mec DFs\n",
    "        #Drop NoData rows\n",
    "        print('\\n Omitting NoData row')\n",
    "        df_curcop = df_curcop.drop(anDrop)\n",
    "        df_meccop = df_meccop.drop(anDrop) \n",
    "        #Reset index# column for new DF\n",
    "        df_curcop = df_curcop.reset_index(drop=True) \n",
    "        df_meccop = df_meccop.reset_index(drop=True)\n",
    "        #compare_currstart(df_curcop, df_noslash10) #compared altered currDF to OG Last10m\n",
    "    # Compare unaltered/altered DFs datecolumns to OG Last10m and with each other\n",
    "    #Compare date-columns between mec and currDFs\n",
    "    compare_currmec_start(df_curcop, df_meccop) #they have matching start dates\n",
    "    \n",
    "    #Export yrX_MECcurmatch DF and compare to imported version\n",
    "    #df_meccop.to_csv('pdFile_MECmatch_noGAP_curr2std_L10m_negByled_Yr5.txt', sep = '\\t', index = False)\n",
    "    #df_imp_MECpos = pd.read_csv('pdFile_MECmatch_noGAP_curr2std_L10m_negByled_Yr5.txt', sep = '\\t') #mecmatch_noGAP\n",
    "    #compare_imp_df(df_meccop, df_imp_MECpos)\n",
    "    \n",
    "    #Export yrX_currData DF and compare to imported version\n",
    "    #df_curcop.to_csv('pdFile_CurrPeak_noMECgap_negByled_2stdprom07_Yr5.txt', sep = '\\t', index = False)\n",
    "    #df_imp_currdata = pd.read_csv('pdFile_CurrPeak_noMECgap_negByled_2stdprom07_Yr5.txt', sep = '\\t') #currpeak_noMECgap\n",
    "    #compare_imp_df(df_curcop, df_imp_currdata)\n",
    "\n",
    "    return;\n",
    "\n",
    "\n",
    "#check_curr_make_MEC_dfs(df_currdata, df_noslash10, yrX_mec, droplist, trange_tuple)\n",
    "\n",
    "#check_currMEC_dfs(df_negBycurrdata_yr1, df_nBy_noslash10m_yr1, yr1_MECposdata, drop_yr1, trange_negBytuple_yr1)\n",
    "\n",
    "#check_currMEC_dfs(df_negBycurrdata_yr2, df_nBy_noslash10m_yr2, yr2_MECposdata, drop_yr2, trange_negBytuple_yr2)\n",
    "\n",
    "#check_currMEC_dfs(df_negBycurrdata_yr3, df_nBy_noslash10m_yr3, yr3_MECposdata, drop_yr3, trange_negBytuple_yr3)\n",
    "\n",
    "#check_currMEC_dfs(df_negBycurrdata_yr4, df_nBy_noslash10m_yr4, yr4_MECposdata, drop_yr4, trange_negBytuple_yr4)\n",
    "\n",
    "#check_currMEC_dfs(df_negBycurrdata_yr5, df_nBy_noslash10m_yr5, yr5_MECposdata, drop_yr5, trange_negBytuple_yr5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eedde09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pySPEDAS)",
   "language": "python",
   "name": "pyspedas-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
